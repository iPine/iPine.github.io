<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>iPine&#39;s Blog</title>
  
  <subtitle>看似无意义的事，竟是有意义的</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://ipine.github.io/"/>
  <updated>2019-05-14T11:57:24.924Z</updated>
  <id>http://ipine.github.io/</id>
  
  <author>
    <name>iPine</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>探索性数据分析基本流程</title>
    <link href="http://ipine.github.io/2019-05-14/"/>
    <id>http://ipine.github.io/2019-05-14/</id>
    <published>2019-05-14T09:36:25.681Z</published>
    <updated>2019-05-14T11:57:24.924Z</updated>
    
    <content type="html"><![CDATA[<p>以分析数据集<code>未前往就诊的预约挂号</code>为例，总结一下探索性数据分析的基本流程。</p><h3 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h3><ul><br><li><a href="#intro">简介</a></li><br><li><a href="#wenti">提出问题</a></li><br><li><a href="#lijie">理解数据</a></li><br><li><a href="#qingxi">数据清洗</a></li><br><li><a href="#eda">探索性数据分析（建立指标模型与可视化）</a></li><br><li><a href="#conclusions">结论/交流</a></li><br></ul><p><a id="intro"></a></p><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><h4 id="数据集的简介"><a href="#数据集的简介" class="headerlink" title="数据集的简介"></a>数据集的简介</h4><p><a href="https://www.kaggle.com/joniarroba/noshowappointments" target="_blank" rel="noopener">数据来源kaggle</a>，<code>未前往就诊的挂号预约</code>指一个人预约了医生，收到了所有的指示却没有按约去医院就诊。该数据集包含11万条巴西病人预约挂号的求诊信息，每行数据包含有关患者特点的14个变量，具体有：</p><ul><li>PatientId：病人ID，</li><li>AppointmentID：预约流水号ID，</li><li>Gender：预约者的性别，</li><li>ScheduledDay：作出预约的具体时间，</li><li>AppointmentDay：预约的就诊日期，</li><li>Age：病人年龄，</li><li>Neighbourhood：医院所在位置，</li><li>Scholarship：是否参加巴西福利项目 <a href="https://en.wikipedia.org/wiki/Bolsa_Fam%C3%ADlia" target="_blank" rel="noopener">Bolsa Família</a> </li><li>Hipertension： 是否是高血压，</li><li>Diabetes：是否是糖尿病，</li><li>Alcoholism：是否是酗酒，</li><li>Handcap：是否是残障，</li><li>SMS_received：病人是否收到短信通知，</li><li>No-show：<code>no</code>表示病人如约就诊，<code>yes</code>表示病人没有前往就诊。</li></ul><p><a id="wenti"></a></p><h3 id="提出问题"><a href="#提出问题" class="headerlink" title="提出问题"></a>提出问题</h3><p>数据分析的目标就是解决问题，提出感兴趣的或是以业务为导向的问题。一般是两种情况：要么获取一批数据，然后根据它提问；要么先提问，然后根据问题收集数据。<br>这里提的问题如下：</p><ul><li>病人的年龄是如何分布的？哪个年龄段的病人更多？</li><li>未按约去就诊的病人有多少？占多大的比例？</li><li>人们一般会预约在一周的哪一天就诊？</li><li>一天中的哪个时段，预约的人最多？</li><li>一般会提前几天预约挂号，即病人等待就诊的时长是多久？</li><li>哪些重要因素会影响病人是否如约去就诊？例如，年龄，性别，是否参加福利项目，一周中的哪天就诊等。</li></ul><p><a id="lijie"></a></p><h3 id="理解数据"><a href="#理解数据" class="headerlink" title="理解数据"></a>理解数据</h3><p>理解数据背景，每个字段的实际含义。主要包括：导入数据和查看数据基本信息，比如，一些描述统计信息。</p><h4 id="导入必要的包和数据："><a href="#导入必要的包和数据：" class="headerlink" title="导入必要的包和数据："></a>导入必要的包和数据：</h4><pre><code>import pandas as pdimport numpy as npimport matplotlib.pyplot as pltimport seaborn as sns%matplotlib inlinedf = pd.read_csv(&apos;noshowappointments-kagglev2-may-2016.csv&apos;)</code></pre><h4 id="查看基本信息"><a href="#查看基本信息" class="headerlink" title="查看基本信息"></a>查看基本信息</h4><p>查看数据集中有哪些列</p><pre><code>df.head()</code></pre><p>查看数据集是否有缺失值、重复值以及每列的数据类型。共14列，每列都是110527个值，不存在缺失值，也不存在重复值。</p><pre><code>df.info()df.duplicated().sum()</code></pre><p>检查异常值，发现年龄的最小值有误。</p><pre><code>df.describe()df.Age.describe()</code></pre><p>输出如下：</p><pre><code>count    110527.000000mean         37.088874std          23.110205min          -1.00000025%          18.00000050%          37.00000075%          55.000000max         115.000000Name: Age, dtype: float64</code></pre><p><a id="qingxi"></a></p><h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><p>这一步主要是评估数据来识别数据质量或结构中的问题，并通过修改、替换或删除数据来清理数据，以确保数据集具有最高质量和尽可能结构化。</p><h4 id="1、将所有列名统一修改成小写并以下划线连接，便于操作。"><a href="#1、将所有列名统一修改成小写并以下划线连接，便于操作。" class="headerlink" title="1、将所有列名统一修改成小写并以下划线连接，便于操作。"></a>1、将所有列名统一修改成小写并以下划线连接，便于操作。</h4><pre><code>df.rename(columns=lambda x: x.strip().lower().replace(&apos;-&apos;,&apos;_&apos;), inplace=True )df.head(2)</code></pre><h4 id="2、删除与问题无关的列"><a href="#2、删除与问题无关的列" class="headerlink" title="2、删除与问题无关的列"></a>2、删除与问题无关的列</h4><p>要删除的列包括：</p><ul><li>PatientId：病人ID，</li><li>neighbourhood: 医院位置</li><li>Hipertension： 是否是高血压，</li><li>Diabetes：是否是糖尿病，</li><li>Alcoholism：是否是酗酒，</li><li>Handcap：是否是残障，</li><li>SMS_received：病人是否收到短信通知，</li></ul><pre><code>df.drop([&apos;patientid&apos;,&apos;hipertension&apos;,&apos;diabetes&apos;,&apos;alcoholism&apos;,&apos;handcap&apos;,&apos;sms_received&apos;,&apos;neighbourhood&apos;], axis=1, inplace= True)df.tail(2)</code></pre><h4 id="3、处理异常值。"><a href="#3、处理异常值。" class="headerlink" title="3、处理异常值。"></a>3、处理异常值。</h4><p>通过上面的观察发现<code>age</code>列的最小值为-1，最大值为115。最小值明显是错误值，而最大值不确定是否有误，但我觉得它可能是真实的，所以保留。</p><pre><code>df = df[df[&apos;age&apos;] &gt; 0]df.age.describe()</code></pre><h4 id="4、对age列进行分段，并创建新的列-age-group"><a href="#4、对age列进行分段，并创建新的列-age-group" class="headerlink" title="4、对age列进行分段，并创建新的列 age_group"></a>4、对<code>age</code>列进行分段，并创建新的列 <code>age_group</code></h4><pre><code>bin_labels = [&apos;Teenager&apos;,&apos;Young&apos;,&apos;Middle&apos;,&apos;Old&apos;]bin_edges = [0,19,38,56,116]df[&apos;age_group&apos;] = pd.cut(df[&apos;age&apos;], bin_edges, labels=bin_labels) df[&apos;age_group&apos;].isnull().sum()</code></pre><p><a id="eda"></a></p><h3 id="探索性数据分析（建立指标模型与可视化）"><a href="#探索性数据分析（建立指标模型与可视化）" class="headerlink" title="探索性数据分析（建立指标模型与可视化）"></a>探索性数据分析（建立指标模型与可视化）</h3><p>执行EDA，可以探索并扩充数据，以最大限度地发挥自己数据分析、可视化和模型构建的潜力。<br>探索数据涉及在数据中查找模式，可视化数据中的关系，并对正在使用的数据建立直觉。<br>经过探索后，可以删除异常值，并从数据中创建更好的特征。</p><h4 id="问题-1：病人的年龄是如何分布的？哪个年龄段的病人更多？"><a href="#问题-1：病人的年龄是如何分布的？哪个年龄段的病人更多？" class="headerlink" title="问题 1：病人的年龄是如何分布的？哪个年龄段的病人更多？"></a>问题 1：病人的年龄是如何分布的？哪个年龄段的病人更多？</h4><pre><code>plt.subplots(figsize=(6,4))df[&apos;age_group&apos;].value_counts().plot(kind=&apos;bar&apos;)plt.title(&apos;Age Distribution&apos;)plt.xlabel(&apos;Age&apos;)plt.ylabel(&apos;Frequence&apos;);</code></pre><p><img src="http://ipineimg.lijundong.com/output_19_0.png" alt="19"></p><p>可以看到发出预约挂号的病人中，青年人最多，其次是中年人和青少年，老年人最少。</p><h4 id="问题2：未按约去就诊的病人有多少？占多大的比例？"><a href="#问题2：未按约去就诊的病人有多少？占多大的比例？" class="headerlink" title="问题2：未按约去就诊的病人有多少？占多大的比例？"></a>问题2：未按约去就诊的病人有多少？占多大的比例？</h4><pre><code>x_vaule = df[&apos;no_show&apos;].value_counts()print(x_vaule)labels = &apos;Show up&apos;,&apos;No show&apos;explode = [0, 0.1]plt.subplots(figsize=(5,5))plt.axes(aspect=1)# 设置饼图样式，标签，突出显示，圆上文本格式，显示阴影，文本位置离圆心距离，起始角度，百分比的文本离圆心距离plt.pie(x=x_vaule, labels=labels,explode=explode,autopct=&apos;%.1f %%&apos;, shadow=True, labeldistance=1.1, startangle = 90,pctdistance = 0.6 )plt.title(&apos;The proportion of patients who did not go to the hospital as appointment &apos;);</code></pre><p><img src="http://ipineimg.lijundong.com/output_22_1.png" alt="22"></p><p>通过统计函数可以得出未按约定到医院就诊的病人有21680人，观察饼图可以知道，该人数占据总预约人数的20.3%。</p><h4 id="问题3：人们一般会预约在一周的哪一天就诊？"><a href="#问题3：人们一般会预约在一周的哪一天就诊？" class="headerlink" title="问题3：人们一般会预约在一周的哪一天就诊？"></a>问题3：人们一般会预约在一周的哪一天就诊？</h4><pre><code># 先将预约日期转换成日期类型，然后换成一周表示df[&apos;appointmentday&apos;] = pd.to_datetime(df[&apos;appointmentday&apos;], errors=&apos;coerce&apos;)df[&apos;appointment_weekday&apos;] =df[&apos;appointmentday&apos;].dt.weekday_name plt.subplots(figsize=(8,5))plt.plot(df[&apos;appointment_weekday&apos;].value_counts().keys(),df[&apos;appointment_weekday&apos;].value_counts().values)plt.title(&apos;Appointment Day Distribution&apos;)plt.xlabel(&apos;Appointment Day&apos;)plt.ylabel(&apos;Frequence&apos;);</code></pre><p><img src="http://ipineimg.lijundong.com/output_26_0.png" alt="26"></p><p>可以看到，人们更喜欢在星期三就诊，其次是星期二，星期四和星期五预约就诊的人相对少些，星期六的人最少。这里没有出现星期天，也许是因为星期天是休息日。</p><h4 id="问题4：一天中的哪个时段，预约的人最多？"><a href="#问题4：一天中的哪个时段，预约的人最多？" class="headerlink" title="问题4：一天中的哪个时段，预约的人最多？"></a>问题4：一天中的哪个时段，预约的人最多？</h4><pre><code>#先将scheduleday处理成日期类型，然后提取小时df[&apos;scheduledday&apos;] = pd.to_datetime(df[&apos;scheduledday&apos;], errors=&apos;coerce&apos;)df[&apos;scheduledhour&apos;] = df[&apos;scheduledday&apos;].dt.hour# df[&apos;scheduledhour&apos;].describe()#将一天的时间分成三个时段，上午，下午，晚上bin_labels = [&apos;Morning&apos;,&apos;Afternoon&apos;,&apos;Night&apos;]bin_edges = [5,12,18,22]df[&apos;scheduledhour_cut&apos;] = pd.cut(df[&apos;scheduledhour&apos;], bin_edges, labels=bin_labels) # df[&apos;scheduledhour_cut&apos;].isnull().sum()df[&apos;scheduledhour_cut&apos;].value_counts()plt.subplots(figsize=(6,4))df[&apos;scheduledhour_cut&apos;].value_counts().plot(kind=&apos;bar&apos;)plt.title(&apos;Scheduled Time Distribution&apos;)plt.xlabel(&apos;Scheduled Time&apos;)plt.ylabel(&apos;Frequence&apos;);</code></pre><p><img src="http://ipineimg.lijundong.com/output_30_0.png" alt="30"></p><p>可以看到，绝大多数的病人选择在上午预约，一部分病人选择在下午预约，极少病人选择在晚上预约。一般下午6点以后，医院的医生可能已经下班了，预约成功的几率会下降。</p><h4 id="问题5：一般会提前几天预约挂号，即病人等待就诊的时长是多久？"><a href="#问题5：一般会提前几天预约挂号，即病人等待就诊的时长是多久？" class="headerlink" title="问题5：一般会提前几天预约挂号，即病人等待就诊的时长是多久？"></a>问题5：一般会提前几天预约挂号，即病人等待就诊的时长是多久？</h4><pre><code>df[&apos;waittime&apos;] = df[&apos;appointmentday&apos;].dt.date - df[&apos;scheduledday&apos;].dt.datedf[&apos;waittime&apos;].describe()</code></pre><p><code>等待时长</code>的统计信息如下：</p><pre><code>count                     106987mean     10 days 04:00:04.710852std      15 days 06:19:27.050399min            -6 days +00:00:0025%              0 days 00:00:0050%              4 days 00:00:0075%             14 days 00:00:00max            179 days 00:00:00Name: waittime, dtype: object</code></pre><p>得到的<code>等待时长</code>出现了负数值，这些值应该是错误的。至于<code>等待时长</code>很大的数据，不确定是否是错误的。这里留下那些等待时长<code>大于等于0天</code>的数据。</p><pre><code>df = df[df[&apos;appointmentday&apos;].dt.date &gt;= df[&apos;scheduledday&apos;].dt.date]df[&apos;waittime&apos;] = (df[&apos;appointmentday&apos;].dt.date - df[&apos;scheduledday&apos;].dt.date)df[&apos;waittime&apos;].describe()</code></pre><p>处理后的结果：</p><pre><code>count                     106982mean     10 days 04:00:53.840833std      15 days 06:19:37.756884min              0 days 00:00:0025%              0 days 00:00:0050%              4 days 00:00:0075%             14 days 00:00:00max            179 days 00:00:00Name: waittime, dtype: object</code></pre><p>人们平均提前10天预约，大多数人提前一星期预约，等待时长最短是0天，即当天预约当天就诊，等待时长最久的是179天。</p><h4 id="问题6：哪些重要因素会影响病人是否如约去就诊？"><a href="#问题6：哪些重要因素会影响病人是否如约去就诊？" class="headerlink" title="问题6：哪些重要因素会影响病人是否如约去就诊？"></a>问题6：哪些重要因素会影响病人是否如约去就诊？</h4><p>例如，年龄，性别，是否参加福利项目，一周中的就诊时间等</p><p>计算去就诊和未去就诊的人数的比例函数</p><pre><code>def cal_proportion(col_name):    &quot;&quot;&quot;按传入的列与no-show分组，统计不同类的数量，并计算各类的比例    &quot;&quot;&quot;    counts = df.groupby([&apos;no_show&apos;,col_name]).count()[&apos;appointmentid&apos;]    total = df.groupby([&apos;no_show&apos;]).count()[&apos;appointmentid&apos;]    no_show_proportions = counts[&apos;Yes&apos;] / total[&apos;Yes&apos;]    show_proportions = counts[&apos;No&apos;]/ total[&apos;No&apos;]    return no_show_proportions,show_proportions</code></pre><p>绘制图形函数</p><pre><code>def double_bar(bar_data1,bar_data2,xlabels,xtick_label):    # 绘制条柱,先设置每个等级组的x坐标位置和每个条柱的宽度    ind = np.arange(len(bar_data1))    width = 0.35    red_bar = plt.bar(ind,bar_data1, width, color=&apos;r&apos;, alpha=0.7, label=&apos;No show&apos;)    blue_bar = plt.bar(ind+width, bar_data2, width, color=&apos;b&apos;,alpha=0.7, label=&apos;Show up&apos;)    # 标题和标签    plt.ylabel(&apos;Proportion&apos;)    plt.xlabel(xlabels)    plt.title(&apos;Proportion by &apos;+ xlabels + &apos; and No-Show&apos;)    locations = ind + width / 2  # x 坐标刻度位置    plt.xticks(locations, xtick_label)    # 图例    plt.legend()</code></pre><h5 id="6-1-不同年龄段的病人，如约去就诊的情况怎么样？"><a href="#6-1-不同年龄段的病人，如约去就诊的情况怎么样？" class="headerlink" title="6.1 不同年龄段的病人，如约去就诊的情况怎么样？"></a>6.1 不同年龄段的病人，如约去就诊的情况怎么样？</h5><p>计算各个年龄段，按约去就诊的比例和未按约去就诊的比例</p><pre><code>no_show = cal_proportion(&apos;age_group&apos;)[0]show_up = cal_proportion(&apos;age_group&apos;)[1]xtick_label =  [&apos;Teenager&apos;, &apos;Young&apos;, &apos;Middle&apos;, &apos;Old&apos;]double_bar(no_show,show_up,&apos;Age Group&apos;,xtick_label)</code></pre><p><img src="http://ipineimg.lijundong.com/output_45_0.png" alt="45"></p><p>通过上图可以看到，不同年龄段的病人如约去就诊的比例是不同的。年龄越高，去就诊的比例比未去就诊的比例就越高，而青少年和年轻人则是未去就诊的比例高于按约去就诊的比例。</p><h5 id="6-2-不同性别的病人，如约去就诊的情况怎么样？"><a href="#6-2-不同性别的病人，如约去就诊的情况怎么样？" class="headerlink" title="6.2 不同性别的病人，如约去就诊的情况怎么样？"></a>6.2 不同性别的病人，如约去就诊的情况怎么样？</h5><pre><code>no_show = cal_proportion(&apos;gender&apos;)[0]show_up = cal_proportion(&apos;gender&apos;)[1]xtick_label = [&apos;Female&apos;, &apos;Male&apos;] double_bar(no_show,show_up,&apos;Gender&apos;,xtick_label)</code></pre><p><img src="http://ipineimg.lijundong.com/output_48_0.png" alt="48"></p><p>看起来，男女患者去医院就诊的概率相似。但在所有患者里，女性预约患者更多。</p><h5 id="6-3-是否参加福利项目，影响患者如约去就诊吗？"><a href="#6-3-是否参加福利项目，影响患者如约去就诊吗？" class="headerlink" title="6.3 是否参加福利项目，影响患者如约去就诊吗？"></a>6.3 是否参加福利项目，影响患者如约去就诊吗？</h5><pre><code>no_show = cal_proportion(&apos;scholarship&apos;)[0]show_up = cal_proportion(&apos;scholarship&apos;)[1]xtick_label = [&apos;False&apos;, &apos;True&apos;]double_bar(no_show,show_up,&apos;Scholarship&apos;,xtick_label)</code></pre><p><img src="http://ipineimg.lijundong.com/output_51_0.png" alt="51"></p><p>可以看到，未参加巴西福利项目的病人更倾向于按约就诊；而参加了巴西福利项目的病人按约就诊的比例低于未按约就诊的比例。还可以清楚地看到，绝大多数的病人并没有参加福利项目。</p><h5 id="6-4-在一周的哪天就诊，是否会影响病人如约去就诊？"><a href="#6-4-在一周的哪天就诊，是否会影响病人如约去就诊？" class="headerlink" title="6.4 在一周的哪天就诊，是否会影响病人如约去就诊？"></a>6.4 在一周的哪天就诊，是否会影响病人如约去就诊？</h5><pre><code>no_show = cal_proportion(&apos;appointment_weekday&apos;)[0]show_up = cal_proportion(&apos;appointment_weekday&apos;)[1]xtick_label = [&apos;Friday&apos;, &apos;Monday&apos;, &apos;Saturday&apos;, &apos;Thursday&apos;, &apos;Tuesday&apos;, &apos;Wednesday&apos;]double_bar(no_show,show_up,&apos;Appointment Weekday&apos;,xtick_label)</code></pre><p><img src="http://ipineimg.lijundong.com/output_54_0.png" alt="54"></p><p>除开星期六外，病人更喜欢在星期四、星期二和星期三如约去就诊；而约在星期五和星期一的病人，未去就诊的比例更高。同时也可以知道，更多的病人选择在星期二和星期三就诊。</p><p><a id="conclusions"></a></p><h3 id="结论-交流"><a href="#结论-交流" class="headerlink" title="结论/交流"></a>结论/交流</h3><p>得出结论这一步通常使用机器学习或推理性统计来完成，本文的重点是使用描述性统计得出结论。<br>与他人交流结果，要证明发现的见解。如果最终目标是构建系统，那么需要分享构建的结果，解释得出设计结论的方式，并报告该系统的性能。</p><ul><li>交流结果的方法有多种：报告、幻灯片、博客帖子、电子邮件、演示文稿，甚至对话。</li><li>数据可视化在这个过程中可以发挥很大的价值。</li></ul><blockquote><p><strong>实验结果</strong>：在所有这些病人中，女性病人和中老年病人更关注身体健康，年龄越大，更愿意按约去就诊。人们一般倾向于在星期二和星期三的上午去就诊，有的病人会提前很久就预约医生，而大多数的病人会在预约当天去就诊。病人的年龄、病人是否参加福利项目以及在一周的哪天去就医这几个因素会影响病人是否按约去医院就诊。</p></blockquote><blockquote><p><strong>数据本身的局限性</strong>：数据中还提供了病人患的几种病，例如，高血压，酗酒，糖尿病等，还提供了医院的地理位置，病人是否患这些病和医院的位置可能也会影响他们能否按约去医院就诊。此外，病人等待的时间长短，可能也会影响他是否按约去就诊。目前，暂时未作这三方面的探究，只对目前感兴趣的问题做了分析。</p></blockquote><blockquote><p><strong>探索方式局限性</strong>：此次探索分析使用的只是一些简单的统计计算和可视化分析。这样得出的结论只能是暂时的，还有进一步验证的需要（使用统计检验或者机器学习建模等）。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;以分析数据集&lt;code&gt;未前往就诊的预约挂号&lt;/code&gt;为例，总结一下探索性数据分析的基本流程。&lt;/p&gt;
&lt;h3 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h3&gt;&lt;ul&gt;&lt;br&gt;&lt;li&gt;&lt;a h
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="python" scheme="http://ipine.github.io/tags/python/"/>
    
      <category term="data_analysis" scheme="http://ipine.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>淘宝婴儿用品销售数据探索分析之遇到的问题</title>
    <link href="http://ipine.github.io/2019-05-09/"/>
    <id>http://ipine.github.io/2019-05-09/</id>
    <published>2019-05-09T10:15:03.765Z</published>
    <updated>2019-05-09T14:02:02.573Z</updated>
    
    <content type="html"><![CDATA[<p>在阿里天池下载的<a href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=45" target="_blank" rel="noopener">淘宝天猫婴儿用品销量数据集</a>，数据的背景介绍可参见数据出处或者<a href="https://zhuanlan.zhihu.com/p/64058259" target="_blank" rel="noopener">这里</a>。<br>在用Python对该数据进行初步业务指标分析后，我遇到了一些问题，这里做下总结。<br>本文主要内容，包含以下两方面：<br>1 . 在数据清洗过程，遇到了什么问题？有什么需要注意的？<br>2 . 模型构建过程，即分析了哪些业务指标，需要注意什么问题？</p><h3 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h3><h4 id="选择子集"><a href="#选择子集" class="headerlink" title="选择子集"></a>选择子集</h4><p>对于要分析的业务指标，不需要用到交易记录数据中的<code>auction_id</code>，<code>property</code>等字段信息。<br>选择子集的方式，有不同方法：可以将不需要的字段删除，也可以选择只保留要使用的字段。</p><pre><code># 方式一，删除不用的sub_trade_data = trade_data.drop(columns=[&apos;auction_id&apos;,&apos;property&apos;])# 方式二，保留需要的sub_trade_data = trade_data.loc[:, [&apos;user_id&apos;,&apos;cat_id&apos;,&apos;cat1&apos;,&apos;buy_mount&apos;,&apos;day&apos;]]</code></pre><h4 id="规范列名-重命名"><a href="#规范列名-重命名" class="headerlink" title="规范列名-重命名"></a>规范列名-重命名</h4><p>原始数据中所有字段名为英文缩写，为了在分析时便于查看和获取指标计算要使用的字段，将所有列名改为中文形式。原始数据集包含两个数据文件，没合并，一开始我以为需要为每个数据集单独定义一个列名字典来进行列名修改，但其实只需要定义一个，直接应用在两个数据集上。</p><pre><code>newColName = {&apos;user_id&apos;:&apos;用户编号&apos;,&apos;cat_id&apos;:&apos;商品编号&apos;,&apos;cat1&apos;:&apos;商品种类&apos;,&apos;buy_mount&apos;:&apos;销售数量&apos;,&apos;day&apos;:&apos;销售时间&apos;,&apos;birthday&apos;:&apos;出生日期&apos;,&apos;gender&apos;:&apos;性别&apos;}sub_trade_data.rename(columns=newColName,inplace=True)baby_data.rename(columns=newColName,inplace=True)</code></pre><h4 id="缺失值查看"><a href="#缺失值查看" class="headerlink" title="缺失值查看"></a>缺失值查看</h4><p>先查看两个数据集是否存在缺失值，若存在，需要进行处理。对缺失值的处理，要么删除，要么用其它统计值填补。这两个数据集比较好，未存在任何缺失值。<br>查看数据集是否存在缺失值的方式可以使用<code>isnull()</code>函数，后面加<code>any()</code>查看列是否存在缺失，若存在会返回<code>True</code>；也可以使用<code>info()函数</code>，这个函数会显示数据有哪些列，每列有多少项，是否有缺失等信息。</p><pre><code># 方式一，使用isnull()sub_trade_data.isnull().any()#方式二，使用info()sub_trade_data.info()</code></pre><h4 id="数据类型转换"><a href="#数据类型转换" class="headerlink" title="数据类型转换"></a>数据类型转换</h4><p>使用<code>.dtypes</code>查看数据字段类型时，发现都是<code>int64</code>类型，这对于<code>销售时间</code>和<code>出生日期</code>两个字段很明显是不合理的。需要将这两个字段转换为<code>日期类型</code>。<br>下面说下我在这个过程中经历的几个阶段：</p><ul><li>第一阶段</li></ul><p>一开始，我直接使用Pandas的<code>to_datetime()</code>函数将字段进行格式转换，程序不报错，如下：</p><pre><code>sub_trade_data[&apos;销售时间&apos;] = pd.to_datetime(sub_trade_data[&apos;销售时间&apos;],format=&apos;%Y-%m-%d&apos;)</code></pre><p>得到结果：<br><img src="http://ipineimg.lijundong.com/%E6%B7%98%E5%AE%9D%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93%E5%9B%BE%E7%89%87Image1.png" alt="图1"></p><p>图中展示的都是同一个时间，有点奇怪。第一时间查看原始表格中销售时间字段，发现并不是如图中那样，原始数据表中的销售时间是8位数字表示的时间：<br><img src="http://ipineimg.lijundong.com/%E6%B7%98%E5%AE%9D%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93%E5%9B%BE%E7%89%87Image2.png" alt="图2"></p><p>那么就是时间函数解析的问题，网上查了一下，发现如果直接将一串数字作为参数传入<code>to_datetime()</code>函数，它会将这串数字当作<code>unix时间戳</code>，并把unix时间戳默认转为GMT标准时间。而北京时间比GMT标准时间要加8小时，所以如果是unix时间戳形式的时间，转换时还需要自己处理时区问题，具体解决方案可<a href="https://blog.csdn.net/u013243986/article/details/79739316" target="_blank" rel="noopener">参考这里</a>。<br>回到这里的问题，看了原始表格的时间发现它并不是unix时间戳形式，所以转换结果不对。</p><ul><li>第二阶段</li></ul><p>重新开始排查问题，查了Pandas的<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html" target="_blank" rel="noopener">to_datetime文档</a>，第一个参数的类型可以是整型，字符串型，也可以是日期型。既然直接传入数字转换结果不对，那么就想着传入正确格式（想要转换成的日期格式是年-月-日这种）的字符串试试。<br>所以就有了以下步骤：</p><p>1 . 先将原始表格里日期字段的 数字类型转成字符串类型</p><pre><code>sub_trade_data[&apos;销售时间&apos;] = sub_trade_data[&apos;销售时间&apos;].astype(&apos;str&apos;)</code></pre><p>2 . 定义函数：将字符串类型的日期转成<code>年-月-日</code>格式</p><pre><code>def dateStrFormat(timeCol):&apos;&apos;&apos;输入：timeCol销售时间列，Series类型输出：转成&apos;y-m-d&apos;字符串形式，返回也是Series类型&apos;&apos;&apos;    timeList = []    for time in timeCol:        year = time[:4]        month = time[4:6]        day = time[6:]        timeFormat = str(year) + &apos;-&apos; + str(month) + &apos;-&apos; + str(day)        timeList.append(timeFormat)    timeColSer = pd.Series(timeList)    return timeColSer# 获取销售时间字段timeCol_sale = sub_trade_data[&apos;销售时间&apos;]# 调用函数将数字日期转成字符串日期dateSer_sale = dateStrFormat(timeCol_sale)# 修改销售时间这一列的值sub_trade_data[&apos;销售时间&apos;] = dateSer_sale</code></pre><p>3 . 将格式调整后的字符串传入<code>to_datetime</code>函数，转成时间类型</p><pre><code>sub_trade_data[&apos;销售时间&apos;] = pd.to_datetime(sub_trade_data[&apos;销售时间&apos;])</code></pre><p>最终得到了正确结果：<br><img src="http://ipineimg.lijundong.com/%E6%B7%98%E5%AE%9D%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93%E5%9B%BE%E7%89%87Image3.png" alt="图3"></p><ul><li>第三阶段</li></ul><p>调用函数调整格式后再作为参数这种做法，效果挺好的，但是缺点就是太繁琐。其实上面第二步中转换字符串格式的步骤，pandas的<code>to_datetime()</code>会自动完成的，后来我将转换成string类型的那串数字直接传入函数，发现也能得到正确的结果&gt;.&lt; 。大道至简，所以还是不用费时间写一个格式转换函数了。<br>去掉上面的第二个步骤，得到同样的结果：</p><pre><code>sub_trade_data[&apos;销售时间&apos;] = sub_trade_data[&apos;销售时间&apos;].astype(&apos;str&apos;)sub_trade_data[&apos;销售时间&apos;] = pd.to_datetime(sub_trade_data[&apos;销售时间&apos;], format=&apos;%Y-%m-%d&apos;) #第二个参数可选</code></pre><h4 id="数据排序"><a href="#数据排序" class="headerlink" title="数据排序"></a>数据排序</h4><p>这个步骤，没什么问题，按照时间字段对数据集排序就好。注意排序后，要重新设置行索引值。</p><pre><code>sub_trade_data = sub_trade_data.sort_values(by=&apos;销售时间&apos;,ascending=True)sub_trade_data = sub_trade_data.reset_index(drop=True)</code></pre><h4 id="查看-处理异常值"><a href="#查看-处理异常值" class="headerlink" title="查看/处理异常值"></a>查看/处理异常值</h4><p>对于交易数据集，使用<code>describe()</code>函数查看统计信息，发现<code>销售数量</code>字段的值都为正数，没问题。<br>对于婴儿信息数据集，需要查看婴儿<code>性别</code>字段的值是否正常，发现除了<code>0（男）</code>，<code>1（女）</code>两个值外，还存在<code>2</code>这个值， 应该是用户不愿意透露婴儿的性别信息，这部分值只有26个 ，故删除这部分数据，并将0和1分别替换成男和女。</p><pre><code>baby_data[&apos;性别&apos;].value_counts() #查看性别字段的各个值及对应数量baby_data = baby_data[baby_data[&apos;性别&apos;]&lt;2] #保留0,1两个值#将0和1分别替换成男和女baby_data[&apos;性别&apos;] = baby_data[&apos;性别&apos;].map({0:&apos;男&apos;,1:&apos;女&apos;}) #将原来的int64类型转成string字符串类型baby_data[&apos;性别&apos;] = baby_data[&apos;性别&apos;].astype(&apos;str&apos;) </code></pre><h3 id="模型构建"><a href="#模型构建" class="headerlink" title="模型构建"></a>模型构建</h3><p>总共分析了6个业务指标，包括：<br>1 . 月均购买次数<br>2 . 最畅销的10个商品<br>3 . 每类商品的月均销量<br>4 . 每类商品的月销量趋势<br>5 . 每类商品的销量峰值是在哪个月<br>6 . 每类商品的用户画像（年龄段，性别）</p><h4 id="业务指标1：月均购买次数-总消费次数-月份数"><a href="#业务指标1：月均购买次数-总消费次数-月份数" class="headerlink" title="业务指标1：月均购买次数 = 总消费次数/月份数"></a>业务指标1：月均购买次数 = 总消费次数/月份数</h4><p>第一个需要注意的是：总消费次数的计算要排除同一天内，同一个用户的重复消费。</p><pre><code>&apos;&apos;&apos;根据字段（用户编号，销售时间），如果两列值同时相同，只保留1条，将重复的数据删除&apos;&apos;&apos;kpi1_df = sub_trade_data.drop_duplicates(subset= [&apos;用户编号&apos;,&apos;销售时间&apos;])total_times = kpi1_df.shape[0]</code></pre><p>第二个需要注意的是：计算月份数，通过<code>(销售时间的最大值-销售时间的最小值).days</code>得到天数，再用天数整除30得到月份数。<br>销售时间的最值可以在排序数据后获取第一个和最后一个销售时间，也可以对销售时间列应用<code>max()</code>和<code>min()</code>函数得到。</p><pre><code>#方法一，先排序再获取最值# startTime = kpi1_df.loc[0,&apos;销售时间&apos;]# endTime = kpi1_df.loc[total_times-1,&apos;销售时间&apos;]# 方法二，使用函数startTime = min(kpi1_df[&apos;销售时间&apos;])endTime = max(kpi1_df[&apos;销售时间&apos;])days = (endTime - startTime).daystotal_months = days // 30</code></pre><h4 id="业务指标2：最畅销的10个商品"><a href="#业务指标2：最畅销的10个商品" class="headerlink" title="业务指标2：最畅销的10个商品"></a>业务指标2：最畅销的10个商品</h4><p>计算步骤：<br>    1 . 根据<code>商品编号</code>进行分组，统计不同商品的销量<br>    2 . 根据销量排序，找出销量前10的商品</p><p>在步骤一中需要注意，统计的是商品的总销量，而不是销量次数，所以应该应用<code>sum()</code>函数，而不是<code>count()</code>函数</p><pre><code>&apos;&apos;&apos;不同商品的销售量：按商品编号分组，统计每个商品的销售数量&apos;&apos;&apos;item_total_times = sub_trade_data.groupby([&apos;商品编号&apos;]).sum()[&apos;销售数量&apos;]</code></pre><p>在步骤二中注意，在排序前，需要将分组后的数据转成<code>dataframe</code>结构，否则用<code>sort_values()</code>排序要报错。</p><pre><code>&apos;&apos;&apos;降序排序，取销售数量前10&apos;&apos;&apos;item_total_times = pd.DataFrame(item_total_times)item_total_times = item_total_times.sort_values(by=[&apos;销售数量&apos;],ascending=False)[:10]</code></pre><h4 id="业务指标3：每类商品的月均销量-各类别商品的销售总量-月份数"><a href="#业务指标3：每类商品的月均销量-各类别商品的销售总量-月份数" class="headerlink" title="业务指标3：每类商品的月均销量 = 各类别商品的销售总量 / 月份数"></a>业务指标3：每类商品的月均销量 = 各类别商品的销售总量 / 月份数</h4><p>计算步骤：<br>    1 . 先求各个类别商品的消费总次数：按<code>商品种类</code>字段分组，统计每个类别的销售总量<br>    2 . 月份数在业务指标1中已计算，根据公式求每类商品的月均销量</p><p>同样，在步骤一中注意，统计的是每种类别商品的总销量，不是销售次数。</p><h4 id="业务指标4：每类商品的月销量趋势"><a href="#业务指标4：每类商品的月销量趋势" class="headerlink" title="业务指标4：每类商品的月销量趋势"></a>业务指标4：每类商品的月销量趋势</h4><p>计算步骤：<br>    1 . 先利用销售时间字段创建一个新的销售月份字段<br>    2 . 再按<code>商品种类</code>和<code>销售月份</code>进行分组，统计各个商品种类的月销量<br>    3 . 根据月销量值绘制每类商品的月销量趋势折线图 </p><p>在步骤一中注意，创建销售时间的月份字段时，直接使用<code>.month</code>属性来提取月份，会报错<code>AttributeError: ‘Series’ object has no attribute &#39;month&#39;</code>；<br>如果运行的是最新版本的pandas，那么解决办法是，可使用datetime属性<code>dt</code>来访问datetime组件</p><pre><code>&apos;&apos;&apos;创建销售月份字段&apos;&apos;&apos;sub_trade_data[&apos;销售月份&apos;] = sub_trade_data[&apos;销售时间&apos;].dt.month</code></pre><p>如果运行的是旧版本pandas，可以用以下办法：</p><pre><code>sub_trade_data[&apos;销售月份&apos;] = sub_trade_data[&apos;销售时间&apos;].apply(lambda x: x.month)</code></pre><p>步骤二中，是按<code>商品种类</code>和<code>销售月份</code>两个字段进行分组，并且统计的也是总销量。</p><pre><code>cate_sale_month = sub_trade_data.groupby([&apos;商品种类&apos;,&apos;销售月份&apos;]).sum()[&apos;销售数量&apos;]</code></pre><p>这个指标是观察销量趋势，需要可视化每种类别商品的月销量折线图，这里暂不提可视化内容，放在后续。</p><h4 id="业务指标5：每类商品的销量峰值是在哪个月"><a href="#业务指标5：每类商品的销量峰值是在哪个月" class="headerlink" title="业务指标5：每类商品的销量峰值是在哪个月"></a>业务指标5：每类商品的销量峰值是在哪个月</h4><p>每个商品种类的月销量已由上个业务指标4得到，所以指标5的分析只需排序后提取销量峰值和对应的月份即可。<br>需要注意：<br>1 . 在排序前将数据转成<code>dataframe</code>格式<br>2 . 使用<code>sort_values()</code>函数排序，排序的目标是每种类别的月销量按从高到底排，那么<code>by</code>参数需要传入两个，一个是<code>商品种类</code>，另一个是<code>销售数量</code>。对于<code>销售数量</code>字段可直接传入，但是<code>商品种类</code>字段，不是<code>cate_sale_month</code>数据中的字段，而是<code>index</code>，因为之前按照<code>商品种类</code>进行的分组。所以这里需要使用<code>cate_sale_month.index.names[0]</code>来获取<code>商品种类</code>字段，并作为参数传入排序函数。</p><pre><code>cate_sale_month = pd.DataFrame(cate_sale_month)cate_sale_sort = cate_sale_month.sort_values(by=[cate_sale_month.index.names[0],&apos;销售数量&apos;],ascending=False)</code></pre><p>3 . 因为每个类别都有12个月份的销量信息，所以排序后，每隔12行提取一个销量，即为每个类别的销量峰值。</p><pre><code># 提取每个类别的销量峰值cate_max_sales = []for i in range(0,len(cate_sale_sort),12):    cate_max_sales.append(cate_sale_sort.iloc[i,0])# 根据销量峰值查询峰值对应的商品种类和月份top_month = cate_sale_sort.query(&apos;销售数量 == {}&apos;.format(cate_max_sales))</code></pre><h4 id="业务指标6：每类商品的用户画像（年龄段，性别）"><a href="#业务指标6：每类商品的用户画像（年龄段，性别）" class="headerlink" title="业务指标6：每类商品的用户画像（年龄段，性别）"></a>业务指标6：每类商品的用户画像（年龄段，性别）</h4><p>分析步骤：<br>    1 . 先将交易数据表和婴儿信息数据表合并<br>    2 . 分析购买每类商品的用户性别分布情况<br>    3 . 分析购买每类商品的用户年龄分布情况</p><p>步骤一，合并数据集，注意交易数据集有两万多条，而婴儿信息数据只有930条，所以合并时主要以婴儿信息数据表为主。</p><pre><code>combined_data = pd.merge(sub_trade_data,baby_data,how=&apos;right&apos;)</code></pre><p>步骤二，分析购买每类商品的婴儿性别分布情况，先根据<code>商品种类</code>和<code>性别</code>字段对数据进行分组，并使用<code>sum()</code>函数统计总销售数量。</p><pre><code>cate_baby_sex = combined_data.groupby([&apos;商品种类&apos;,&apos;性别&apos;]).sum()[&apos;销售数量&apos;]</code></pre><p>第二步就是排序问题，与业务指标5中相同，需要注意排序传入的参数。这里排序目标是每种类别下不同用户性别的购买量按从高到底排，那么<code>by</code>参数需要传入两个，一个是<code>商品种类</code>，另一个是<code>销售数量</code>。对于<code>销售数量</code>字段可直接传入，但是<code>商品种类</code>字段，不是<code>cate_baby_sex</code>数据中的字段，而是<code>index</code>，因为之前按照<code>商品种类</code>进行的分组。所以这里需要使用<code>cate_baby_sex.index.names[0]</code>来获取<code>商品种类</code>字段，并作为参数传入排序函数。</p><pre><code>cate_baby_sex = pd.DataFrame(cate_baby_sex)cate_baby_sex = cate_baby_sex.sort_values(by=[cate_baby_sex.index.names[0],&apos;销售数量&apos;], ascending=False)</code></pre><p>步骤三，分析购买每类商品的用户年龄分布情况<br>计算步骤：<br>    1 . 首先计算婴儿的年龄,增加<code>婴儿年龄</code>列<br>    2 . 将年龄进行分段，增加<code>年龄区间</code>列<br>    3 . 统计不同类商品在不同年龄段的销售情况</p><p>步骤一，计算婴儿的年龄：由<code>购买日期（销售时间）- 婴儿出生日期</code>得到年份差值，从而得到购买商品时婴儿的年龄。<br>这里要注意的问题与业务指标4相同，即从时间中提取年份，直接使用<code>.year</code>属性来提取年份，会报错。这里使用datetime属性<code>dt</code>来访问datetime组件</p><pre><code>combined_data[&apos;婴儿年龄&apos;] = (combined_data[&apos;销售时间&apos;].dt.year - combined_data[&apos;出生日期&apos;].dt.year)</code></pre><p>通过<code>describe()</code>查看 <code>婴儿年龄</code>字段的统计信息，发现最大年龄为28岁，这明显不合理，是个异常值，所以删去。分析到这里也从侧面反映了，在数据分析流程中数据清洗的工作无处不在。</p><pre><code>combined_data = combined_data[combined_data[&apos;婴儿年龄&apos;] != 28]</code></pre><p>步骤二，对年龄进行分段，并增加<code>年龄区间</code>列。注意区间临界值，可以根据<code>婴儿年龄</code>字段的5个分位数（最小值，3个分位数，最大值）来定，例如通过<code>describe()</code>查看到婴儿年龄分位数信息如下：<br><img src="http://ipineimg.lijundong.com/%E6%B7%98%E5%AE%9D%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%80%BB%E7%BB%93%E5%9B%BE%E7%89%87Image4.png" alt="图4"></p><p>那么，分段临界值就可取<code>bin_edges = [-3,0,1,2,3,4,5,12]</code>，同时指明每个年龄段的区间名<code>bin_labels = [&#39;未出生&#39;,&#39;1岁&#39;,&#39;2岁&#39;,&#39;3岁&#39;,&#39;4岁&#39;,&#39;5岁&#39;,&#39;5岁以上&#39;]</code>，之后再用pandas的<code>cut</code>函数进行分段：</p><pre><code>combined_data[&apos;年龄区间&apos;] = pd.cut(combined_data[&apos;婴儿年龄&apos;], bin_edges, labels=bin_labels)# 确认所有年龄都被分到正确区间combined_data[&apos;年龄区间&apos;].isnull().sum() # 0</code></pre><p>最后一步，统计每种商品的用户年龄分布情况。除了需要注意传入排序函数的参数外，还需要注意，按照<code>商品种类</code>和<code>年龄区间</code>分组后，可能存在某些年龄段，销售数量为空的情况，所以需要对空值进行填充。</p><pre><code>cate_baby_age = combined_data.groupby([&apos;商品种类&apos;,&apos;年龄区间&apos;]).sum()[&apos;销售数量&apos;]# 存在某些年龄段，销售数量为空，将其填充为0cate_baby_age = cate_baby_age.fillna(0)# 排序得到，各类商品在哪个年龄段最畅销cate_baby_age = pd.DataFrame(cate_baby_age)cate_baby_age = cate_baby_age.sort_values(by=[cate_baby_age.index.names[0],&apos;销售数量&apos;],ascending=False)</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在阿里天池下载的&lt;a href=&quot;https://tianchi.aliyun.com/dataset/dataDetail?dataId=45&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;淘宝天猫婴儿用品销量数据集&lt;/a&gt;，数据的背景介绍可参见数据出处
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="python" scheme="http://ipine.github.io/tags/python/"/>
    
      <category term="data_analysis" scheme="http://ipine.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>NumPy与Pandas的查漏补缺</title>
    <link href="http://ipine.github.io/2019-05-07/"/>
    <id>http://ipine.github.io/2019-05-07/</id>
    <published>2019-05-07T03:02:23.652Z</published>
    <updated>2019-05-07T06:45:35.821Z</updated>
    
    <content type="html"><![CDATA[<h4 id="使用-NumPy-而不是列表的原因"><a href="#使用-NumPy-而不是列表的原因" class="headerlink" title="使用 NumPy 而不是列表的原因"></a>使用 NumPy 而不是列表的原因</h4><p>NumPy是Scipy，Pandas的基础库，它提供的数据结构是Python数据分析的基础。<br>在Python本身的列表中，保存的是对象的指针。<br>比如，存一个简单数组<code>[0,1,2]</code>，就需要3个指针和3个整数对象，比较费内存和计算时间。且因为<code>list</code>的元素在系统内存中是 <strong>分散</strong>的，而<code>NumPy</code>数组存储在一个 <strong>均匀连续</strong>的内存块中。当遍历所有数组元素时，list需要对内存地址进行查找，NumPy不需要，就节省了计算资源。</p><ul><li>NumPy 更简洁</li><li>在 NumPy 中读写元素更快</li><li>NumPy使用起来更方便，可以自由使用很多向量和矩阵运算—&gt;可采用多线程的方式，充分利用多核CPU计算资源</li><li>NumPy可以更高效地工作，因为它们的实现更高效。</li></ul><p>这里顺便提一个提升内存和提高计算资源利用率的技巧：<br><strong>避免采用隐式拷贝，而采用就地操作方式</strong>。<br>比如：让 <code>x</code> 的值为原来的两倍，直接写成 <code>x *= 2</code>，而不要写成 <code>y = x*2</code></p><h4 id="NumPy"><a href="#NumPy" class="headerlink" title="NumPy"></a>NumPy</h4><p>NumPy中的<code>ndarray</code>对象数组的维数称为<code>秩rank</code>，一维数组的秩为1，二维数组的秩为2，以此类推。每一个线性的数组称为一个<code>轴axes</code>，秩描述的就是轴的数量。</p><h5 id="初始化NumPy-数组"><a href="#初始化NumPy-数组" class="headerlink" title="初始化NumPy 数组"></a>初始化NumPy 数组</h5><p>若只是想创建一个空数组：</p><pre><code>import numpynumpy.array([])</code></pre><p>若想初始化一个数组，以下几种方式：</p><pre><code>numpy.zeros(shape=(4,2))numpy.ones(3)numpy.empty(shape=(0,0))</code></pre><p>其他初始化 NumPy 数组的方法可<a href="https://docs.scipy.org/doc/numpy/reference/routines.array-creation.html" target="_blank" rel="noopener">参考这里</a></p><h5 id="查看数组的大小"><a href="#查看数组的大小" class="headerlink" title="查看数组的大小"></a>查看数组的大小</h5><p>用<code>.shape</code>，它返回一个元组，元组元素的数量表示数组的秩（维度），元组元素的值表示在该维度上数组的元素个数。</p><h5 id="查看元素的属性"><a href="#查看元素的属性" class="headerlink" title="查看元素的属性"></a>查看元素的属性</h5><p><code>.dtype</code>，可利用dtype来创建 <strong>结构数组</strong>：</p><pre><code>import numpy as nppersontype = np.dtype({ &apos;names&apos;: [&apos;name&apos;,&apos;site&apos;], &apos;formats&apos;: [&apos;S32&apos;,&apos;S32&apos;] })person = np.array([(&apos;ipine&apos;,&apos;https://ipine.me/&apos;)], dtype=persontype)name = person[:][&apos;name&apos;]print(name)  # [b&apos;ipine&apos;]</code></pre><h5 id="访问数组元素"><a href="#访问数组元素" class="headerlink" title="访问数组元素"></a>访问数组元素</h5><ul><li>对于一维数组，可以通过三种方式，一是用<code>索引</code>；二是用<code>切片</code>，切片要注意<code>含前不含后</code>原则；三是利用<code>循环遍历</code>数组的每个元素。</li><li>对于二维数组，有三种情况，一是查看具体的某一个元素，使用行列号，如<code>a[1,2]</code>；二是查看某一行的元素，如<code>a[0,:]</code>；三是查看某一列的元素，如<code>a[:,0]</code></li></ul><h5 id="Universal-Function运算"><a href="#Universal-Function运算" class="headerlink" title="Universal Function运算"></a>Universal Function运算</h5><p>NumPy方便快捷的原因就是它提供了很多ufunc函数，这些函数都是采用C语言实现，计算速度非常快。</p><p>1 . 统计函数<br>在数据分析中，理解数据，查看数据的统计信息至关重要。通过对数据进行描述性统计分析，能够对数据有更清晰的认识。<br>一些常见的统计函数如下：</p><ul><li>计算数组或者矩阵中的最大值，用<code>amax()</code>；最小值用<code>amin()</code>；第二个可选参数指定轴，<code>0</code>代表<code>行</code>，<code>1</code>代表<code>列</code>；即统计行或者列的最值。</li><li>统计最大值与最小值之差，用<code>ptp()</code>；第二个可选参数指定轴，<code>0</code>代表<code>行</code>，<code>1</code>代表<code>列</code>；即统计行或者列的最值之差。</li><li>统计数组的百分位数，用<code>percentile()</code>，可指定第p个百分位数，p取值范围为<code>0-100</code>，<code>p=0</code>求最小值，<code>p=100</code>求最大值；同样也可指定轴。</li><li>统计数组中的中位数，用<code>median()</code>；平均数，用<code>mean()</code>。</li><li>统计数组中的加权平均值，用<code>average(arr, weights)</code>，传入一个权重设置参数。</li><li>统计数组中的标准差，用<code>std()</code>，方差用<code>var()</code>；方差是每个数值与平均值之差的平方和的均值，标准差是方差的算术平方根，表示的是一组数据的离散程度。</li></ul><p><strong>一个栗子</strong>：计算列表分位数<br>分位数对于数据集的summary是必不可少的，临近数据集的最小值和最大值。包括第25、50和75百分位数，它们也被称为第一分位数、中位数和第三分位数。这意味着总共需要5个数字来总结整个数据集：最小值、最大值、中值和两个四分位数（第一和第三）。<br>假设有25个元素，那么第一个四分位为：<code>0.25*25 = 6.25</code>，四舍五入到7；即第一分位数就是列表排序后的第7个元素</p><pre><code>import numpy as npa = np.array([1,2,3,4,5])p = np.percentile(a, 50) # 求中位数</code></pre><p>2 . 创建连续数组<br>使用 <code>arange()</code> 和 <code>linspace()</code>可以很方便地创建连续数组：</p><pre><code>x1 = np.arange(1,11,2)  # 不包含终值，第三个参数指定步长x2 = np.linspace(1,9,5) # 包含终值，第三个参数指定元素个数；在指定间隔返回均匀间隔的数字</code></pre><p>3 . 算术运算<br>包括<code>加add</code>，<code>减subtract</code>，<code>乘multiply</code>，<code>除divide</code>，求<code>幂power</code>，<code>取余remainder/mod</code>等</p><pre><code>x1 = np.arange(1,11,2)x2 = np.linspace(1,9,5)print(np.add(x1, x2))print(np.subtract(x1, x2))print(np.multiply(x1, x2))print(np.divide(x1, x2))print(np.power(x1, x2))print(np.remainder(x1, x2))</code></pre><p>4 . 排序<br>排序算法使用频率高，在数据分析中也常用。在 NumPy中，实现排序算法非常容易。<br>只需使用 <code>sort()</code>这一条语句：</p><blockquote><p>语法说明：sort(a, axis = -1, kind=’quicksort’, order=None)；</p></blockquote><p><code>axis</code>默认值为-1，沿着数组的最后一个轴进行排序，为0表示按列排，为1表示按行排，若为<code>None</code>则是采用扁平化方式排序。默认使用<code>快排quicksort</code>，<code>kind</code>的值还可以为<code>合并排序mergesort</code>，<code>堆排序heapsort</code>。对于结构化的数组，<code>order</code>字段可以指定按照某个字段进行排序。</p><pre><code>a = np.array([[4,3,2],[2,4,1]])print(np.sort(a))print(np.sort(a, axis=None))print(np.sort(a, axis=0))  print(np.sort(a, axis=1))  </code></pre><h4 id="Pandas"><a href="#Pandas" class="headerlink" title="Pandas"></a>Pandas</h4><p>Pandas的使用频率非常高，是数据分析的利器。<br>一方面，Pandas提供的<code>DataFrame</code>与<code>json</code>契合度高，且相比于<code>NumPy</code>的二维数组，<code>DataFrame</code>更利于表示像<code>Excel</code>中的数据，每一列都可以是不同的类型；<br>另一方面，当数据清理工作不是特别复杂时，几句Pandas代码就可以对数据进行规整。</p><h5 id="数据结构Series和DataFrame"><a href="#数据结构Series和DataFrame" class="headerlink" title="数据结构Series和DataFrame"></a>数据结构Series和DataFrame</h5><p>Pandas的一维数组<code>series</code>比<code>NumPy</code>的一维数组<code>array</code>功能更多，<code>series</code>是建立在<code>NumPy</code>基础之上的。 它们的主要区别在于series有索引，可以在定义时使用<code>index</code>来指定。<br><strong>栗子</strong>，定义：</p><pre><code>import pandas as pddata1 = pd.Series(data=[1,2,3,4], index=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])# 或者d = {&apos;a&apos;:1, &apos;b&apos;:2, &apos;c&apos;:3, &apos;d&apos;:4}data2 = pd.Series(d)</code></pre><p>NumPy数组中每个元素都是同一个类型，虽然在科学计算中很快，但是不利于表示像excel中的数据。<br>Pandas的二维数组DataFrame，类似于数据库表， 具有一维数组series中的<code>index（行）索引</code>功能，此外也有<code>columns（列）索引</code>值。<br><strong>栗子</strong>，定义：</p><pre><code>d = {&apos;Chinese&apos;: [68, 88, 90], &apos;Math&apos;: [70, 66, 89]}df1 = pd.DataFrame(d)#或者df2 = pd.DataFrame(d, index=[&apos;ipine&apos;,&apos;Alex&apos;,&apos;Bob&apos;], columns=[&apos;Chinese&apos;, &apos;Math&apos;])</code></pre><p>直接在数据框中传入定义的字典，产生的结果与定义的字典顺序不一致，因为字典是无序的数据结构。<br>可以在将字典传入数据框之前，定义一个有序字典，使字典输出顺序与定义时一样：</p><pre><code>from collections import OrderedDictorderedd = OrderedDict(d)df3 = pd.DataFrame(orderedd)</code></pre><h5 id="查看值"><a href="#查看值" class="headerlink" title="查看值"></a>查看值</h5><p>两种方式，根据位置获取值，<code>iloc</code>，根据索引获取值，<code>loc</code>：</p><pre><code># 对于一维数组data2data2.iloc[0] # 1data2.iloc[&apos;a&apos;]  # 1# 对于二维数组 df3df3.iloc[0,1] #查询第1行第2列的元素，70df3.iloc[0,:] #查询第1行所有元素，68,70df3.iloc[:,1] #查询第1列所有元素，68,88,90df3.loc[0,&apos;Math&apos;] #查询第1行第2列的元素，70df3.loc[0,:] #查询第1行所有元素，这里index没有指定所以默认为从0开始的数字，68,70df3.loc[:,&apos;Math&apos;] #查询Math列所有元素，68,88,90# 简单方法df3[&apos;Math&apos;]</code></pre><h5 id="数据框DataFrame还涉及到复杂查询"><a href="#数据框DataFrame还涉及到复杂查询" class="headerlink" title="数据框DataFrame还涉及到复杂查询"></a>数据框DataFrame还涉及到复杂查询</h5><p>利用切片功能和条件判断</p><p>通过列表选择某几列的数据</p><pre><code>df3[[&apos;Chinese&apos;,&apos;Math&apos;]]</code></pre><p>通过切片功能，获取指定范围的列</p><pre><code>df3.loc[:, &apos;Chinese&apos;:]</code></pre><p>通过条件判断筛选，首先构建查询条件(得到布尔值)，然后利用布尔索引筛选：</p><pre><code>querydf = df3.loc[:, &apos;Math&apos;] &gt;= 70df3.loc[querydf, [&apos;Math&apos;]] # 70 89</code></pre><h5 id="数据统计"><a href="#数据统计" class="headerlink" title="数据统计"></a>数据统计</h5><p>Pandas也有许多统计函数可调用。常用的包括但不限于：</p><ul><li>计算数据量的<code>count()</code>，空值和<code>NaN</code>不计</li><li>查看数据的前几行或后几行，<code>head()</code>和 <code>tail()</code></li><li>查看某一列的数据类型，<code>dtype</code></li><li>查看行列数，<code>shape</code></li><li>获取多个统计指标的<code>describe()</code></li><li>获取最大最小值的<code>max()</code>与<code>min()</code>，</li><li>求和，<code>sum()</code></li><li>求中值和均值，<code>median()</code>和<code>mean()</code></li><li>求标准差和方差，<code>std()</code>和<code>var</code></li><li>统计最小最大值的索引位置，<code>argmin()</code> 和 <code>argmax()</code></li><li>统计最小最大值的索引值，<code>idxmin()</code> 和 <code>idxmax()</code></li></ul><p>如果是数据框，Pandas会自动按列计算。</p><h5 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h5><ul><li>删除列或者行：<code>df.drop(columns=[&#39;Chinese&#39;])</code></li><li>重命名列：<code>df.rename(columns={&#39;Chinese&#39;: &#39;Yuwen&#39;}, inplace=True)</code></li><li>去重：<code>df.drop_duplicates()</code></li><li>格式问题,常见的包括：<br>1 . 更改数据列格式，<code>df[&#39;Chinese&#39;].astype(&#39;str&#39;)</code><br>2 . 数据间空格的删除，转成<code>str</code>类型的格式，便于操作，<code>df[&#39;Chinese&#39;] = df[&#39;Chinese&#39;].map(str.strip)</code><br>3 . 删除特殊符号，同样使用 <code>strip</code>函数；例如<code>Math</code>字段有<code>#</code>，删除它，<code>df[&#39;Math&#39;] = df[&#39;Math&#39;].str.strip(&#39;#&#39;)</code><br>4 . 格式转换，经常需要将字段名统一大小写，可直接使用<code>upper()</code>，<code>lower()</code>，<code>title()</code>等函数；例如，转成大写，<code>df.columns = df.columns.str.upper()</code><br>5 . 查找空值和对空值的处理，经常有字段存在<code>空值</code>，通过<code>isnull()</code>函数查找空值，<code>fillna(value)</code>函数将空值替换成其他值，<code>dropna()</code>函数删除空值；例如，<code>df.isnull()</code> 查找整个表的空值；<code>df.isnull().any()</code>查看哪些列存在空值</li></ul><blockquote><p>注：在pandas更新到最新版本0.24.2时，慎用<code>fillna()</code>填充缺失值，尤其是填充一些字符串时，虽然这一列不是<code>dtype=&#39;category&#39;</code>，但是也可能会出现<em>ValueError: fill value must be in categories</em>的问题。如果项目在pandas的0.24.2版本中，报这个错误，最简单的方法是将<code>fillna()</code>更换为<code>inplace()</code>函数。</p></blockquote><h5 id="应用apply函数"><a href="#应用apply函数" class="headerlink" title="应用apply函数"></a>应用apply函数</h5><p>若想将字段名格式统一，也可以应用apply函数：</p><pre><code>df[&apos;name&apos;] = df[&apos;name&apos;].apply(str.upper)</code></pre><p>当然，最常用的是定义一个函数，在apply中使用，例如：</p><pre><code>def double(x):        return x*2df[&apos;Math&apos;] = df[&apos;Math&apos;].apply(double)</code></pre><p>还可以定义更复杂的函数，比如，在df中新增1列new，为语文和数学成绩之和的n倍：</p><pre><code>def plusMathChinese(df,n):        df[&apos;new&apos;] = (df[&apos;Chinese&apos;] + df[&apos;Math&apos;]) * n        return dfdf = df.apply(plusMathChinese, axis=1, args=(2,)) #axis=1指明按照列为轴进行操作；args是传递参数</code></pre><h5 id="数据表的合并"><a href="#数据表的合并" class="headerlink" title="数据表的合并"></a>数据表的合并</h5><p>两个<code>DataFrame</code>数据框的合并，就像两张数据表的合并，使用的是 <code>merge()</code>函数；<br>与SQL中表连接类似，包含以下5种形式：<br>1 . 按指定列进行连接</p><pre><code>df3 = pd.merge(df1, df2, on=&apos;name&apos;)</code></pre><p>2 . inner内连接，求两个数据框的交集，是合并时的默认选择</p><pre><code>df3 = pd.merge(df1, df2, how=&apos;inner&apos;)</code></pre><p>3 . 左连接，以第一个数据框为主</p><pre><code>df3 = pd.merge(df1, df2, on=&apos;left&apos;)</code></pre><p>4 . 右连接，以第二个数据框为主</p><pre><code>df3 = pd.merge(df1, df2, on=&apos;right&apos;)</code></pre><p>5 . 外连接，求两个数据框的并集</p><pre><code>df3 = pd.merge(df1, df2, on=&apos;outer&apos;)</code></pre><h4 id="用SQL方式打开Pandas"><a href="#用SQL方式打开Pandas" class="headerlink" title="用SQL方式打开Pandas"></a>用SQL方式打开Pandas</h4><p>在Python中可以直接用SQL语句来操作Pandas。<br>利用工具 <code>pandasql</code>，它的主要函数是 <code>sqldf</code>，该函数包含两个参数：<br>一是，SQL查询语句。<br>二是，一组环境变量 <code>globals()</code> 或 <code>locals()</code>。<br><strong>举个栗子</strong>：<br>先在anaconda环境下安装pandasql包：<code>conda install pandasql</code>，然后在jupyter notebook上运行：</p><pre><code>import pandas as pdfrom pandasql import sqldf, load_meat, load_birthsdf1 = pd.DataFrame({&apos;name&apos;:[&apos;ZhangFei&apos;, &apos;GuanYu&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;], &apos;data1&apos;:range(5)})sql = &quot;select * from df1 where name =&apos;ZhangFei&apos;&quot;pysqldf = lambda sql: sqldf(sql, globals())print(pysqldf(sql)) # 查询到`ZhangFei`的data1为0</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;使用-NumPy-而不是列表的原因&quot;&gt;&lt;a href=&quot;#使用-NumPy-而不是列表的原因&quot; class=&quot;headerlink&quot; title=&quot;使用 NumPy 而不是列表的原因&quot;&gt;&lt;/a&gt;使用 NumPy 而不是列表的原因&lt;/h4&gt;&lt;p&gt;NumPy是Scip
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="python" scheme="http://ipine.github.io/tags/python/"/>
    
      <category term="data_analysis" scheme="http://ipine.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>易忘易忽略的Python入门知识点-续(二)</title>
    <link href="http://ipine.github.io/2019-05-06/"/>
    <id>http://ipine.github.io/2019-05-06/</id>
    <published>2019-05-06T12:04:44.620Z</published>
    <updated>2019-05-06T12:55:47.157Z</updated>
    
    <content type="html"><![CDATA[<h4 id="模块与包"><a href="#模块与包" class="headerlink" title="模块与包"></a>模块与包</h4><h5 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h5><p>模块是一个包含所有你定义的函数和变量的文件，其后缀名是<code>.py</code>。 可以被别的程序引入，以使用该模块中的函数等功能。这也是使用 python 标准库的方法。<br><strong>一个模块只会被导入一次，不管你执行了多少次import。</strong></p><p>Python的搜索路径，搜索路径是由一系列目录名组成的，Python解释器就依次从这些目录中去寻找所引入的模块。<br>搜索路径被存储在<code>sys</code>模块中的<code>path</code>变量</p><pre><code>import sysprint(sys.path) #输出是一个列表，其中第一项是当前目录</code></pre><ul><li><code>import</code>语句：导入整个模块</li><li><p><code>from... import</code>语句：从模块中导入指定的部分到当前命名空间中。这种导入方法不会把被导入的模块的名称放在当前的字符表中。</p><blockquote><p>from fibo import fib, fib2  # fibo这个名称在当前命名空间中没有定义</p></blockquote></li><li><p><code>from...import *</code>语句：从模块中导入所有项目，不推荐使用。这种方法会导入所有名字（除了单一下划线开头的），这很可能会覆盖当前文件中已有的定义。</p></li></ul><p>每个模块都有一个<code>__name__</code>属性，当其值是<code>__main__</code>时，表明该模块自身在运行，否则是被引入。</p><p>内置的函数 <code>dir()</code>可以找到模块内定义的所有名称。以一个字符串列表的形式返回：</p><pre><code>import fiboa = [1, 2, 3, 4, 5]fib = fibo.fibdir() # 得到当前模块中定义的属性列表 [&apos;__builtins__&apos;, &apos;__name__&apos;, &apos;a&apos;, &apos;fib&apos;, &apos;fibo&apos;, &apos;sys&apos;]</code></pre><h5 id="包"><a href="#包" class="headerlink" title="包"></a>包</h5><p>包实际是从一个目录中引用模块，目录结构中必须带有一个 <code>__init__.py</code>文件。<br>可以采用<code>from package import item</code>方式，item可以是包的子模块，或者包里的其他名称，如函数，类，变量名；<br>也可以采用 <code>import item.subitem.subsubitem</code>这种方式，除了最后一项可以是模块或者包外（不能是函数，类，变量名），其余都必须是包。</p><p>导入语句遵循如下规则：</p><ul><li>如果包定义文件 <code>__init__.py</code> 存在一个叫做 <code>__all__</code> 的列表变量，那么在使用 <code>from package import *</code>的时候就把这个列表中的所有名字作为包内容导入。</li><li>如果<code>__all__</code>没有定义，那么使用<code>from sound.effects import *</code>这种语法的时候，就不会导入包<code>sound.effects</code>里的任何子模块。他只是把包<code>sound.effects</code>和它里面定义的所有内容导入进来（可能运行<code>__init__.py</code>里定义的初始化代码）。这会把 <code>__init__.py</code>里面定义的所有名字导入进来。</li></ul><h4 id="输入与输出"><a href="#输入与输出" class="headerlink" title="输入与输出"></a>输入与输出</h4><h5 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h5><p>1 . 想将输出的值转成字符串，可以使用 <code>repr()</code> 或 <code>str()</code> 函数来实现。</p><pre><code>x = 10 * 3.25y = 200 * 200s = &apos;x 的值为： &apos; + repr(x) + &apos;,  y 的值为：&apos; + repr(y) + &apos;...&apos;print(s)  # x 的值为： 32.5,  y 的值为：40000...</code></pre><p>2 . 字符串对象的 <code>rjust()</code> 方法, 它可以将字符串靠右, 并在左边填充空格。还有类似的方法, 如 <code>ljust()</code> 和 <code>center()</code>。<br>3 . 另一个方法 <code>zfill()</code>, 它会在数字的左边填充 0</p><pre><code>print(&apos;12&apos;.zfill(5)) # 00012</code></pre><p>4 . <code>str.format()</code>的基本使用</p><pre><code>print(&apos;{0} site： &quot;{1}&quot;&apos;.format(&apos;ipine&apos;, &apos;https://ipine.me/&apos;))</code></pre><p>在括号中的数字用于指向传入对象在 <code>format()</code>中的位置；</p><p>也可以使用关键字参数：</p><pre><code>print(&apos;{name} site： &quot;{site}&quot;&apos;.format(name=&apos;ipine&apos;, site=&apos;https://ipine.me/&apos;))</code></pre><p><code>!a</code> (使用 ascii()), <code>!s</code> (使用 str()) 和 <code>!r</code> (使用 repr()) 可以用于在格式化某个值之前对其进行转化:</p><pre><code>import mathprint(&apos;常量 PI 的值近似为： {!r}。&apos;.format(math.pi))</code></pre><p>对值进行更好的格式化，可使用可选项 <code>:</code> 和格式标识符（如<code>f</code>, <code>d</code>等）</p><pre><code>import mathprint(&apos;常量 PI 的值近似为 {0:.3f}。&apos;.format(math.pi)) # 常量 PI 的值近似为 3.142。</code></pre><p>在 <code>:</code> 后传入一个整数, 可以保证该域至少有这么多的宽度。</p><h5 id="读写文件"><a href="#读写文件" class="headerlink" title="读写文件"></a>读写文件</h5><p>假设有一个叫做f的文件：</p><pre><code>f = open(&quot;filepath&quot;, &quot;r&quot;)</code></pre><p>1 . 调用 <code>f.read(size)</code>读取一定数目的数据，当 <code>size</code> 被忽略了或者为负, 那么该文件的所有内容都将被读取并且返回。</p><pre><code>str = f.read()print(str)</code></pre><p>2 . <code>f.readlines()</code> 将返回该文件中包含的所有行。也可以通过迭代文件对象来读取每行：</p><pre><code># 打开一个文件f = open(&quot;filepath&quot;, &quot;r&quot;)for line in f:    print(line, end=&apos;&apos;)# 关闭打开的文件f.close()</code></pre><p>更好的打开文件的方式是使用<code>with</code>语句，它可以保证文件<code>f</code>总是会关闭，即使在处理过程中出问题了。</p><pre><code>with open(&quot;myfile.txt&quot;) as f:     for line in f:         print(line, end=&quot;&quot;)</code></pre><p>3 . <code>f.write(string)</code>将 string 写入到文件中, 然后返回写入的字符数。<br>如果要写入一些不是字符串的东西, 那么需要用 <code>str()</code>进行转换后再写入。</p><p>4 . <code>f.tell()</code>返回文件对象当前所处的位置, 它是从文件开头开始算起的字节数。</p><p>5 . 如果要改变文件当前的位置, 可以使用 <code>f.seek(offset, from_what)</code>函数。<br>第二个参数<code>from_what</code>如果是 0 表示开头(默认情况), 如果是 1 表示当前位置, 2 表示文件的结尾，例如：</p><ul><li>seek(x,0) ： 从起始位置即文件首行首字符开始移动 x 个字符</li><li>seek(x,1) ： 表示从当前位置往后移动x个字符</li><li>seek(-x,2)： 表示从文件的结尾往前移动x个字符</li></ul><p>6 . Python<code>open()</code>方法用于打开一个文件，使用该方法一定要保证关闭文件对象，即调用<code>close()</code>方法。<br>其完整语法格式为：</p><pre><code>open(file, mode=&apos;r&apos;, buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)</code></pre><h5 id="经常会遇到的读文件错误"><a href="#经常会遇到的读文件错误" class="headerlink" title="经常会遇到的读文件错误"></a>经常会遇到的读文件错误</h5><p>Python3读CSV文件，出现 <em>UnicodeDecodeError: ‘utf-8’ codec cant’t decode byte 0xd0 in position 0: invalid continuation byte</em><br>出现该错误原因：系统默认为UTF8编码，但文件不是UTF8编码。</p><p><strong>解决方法：</strong><br>一：修改文件对应的编码方式，以记事本打开CSV文件，在<code>文件</code>菜单中选择<code>另存为</code>，可以看到文件原来的保存类型是<code>ASCII</code>，在下拉框中选择<code>UTF8</code>编码。</p><p>二：从文件打开方式上解决</p><pre><code>open(&quot;filename&quot;, encoding=&apos;ascii&apos;, errors=&apos;ignore&apos;)</code></pre><h4 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h4><p><code>try... except</code>语句工作方式：先执行<code>try</code>后面的子句，若没有异常发生，该子句执行后就结束（若有<code>else</code>子句，会执行完它后面的语句才结束），忽略except。若执行时发生异常，异常之后的<code>try</code>子句被忽略，将异常与<code>except</code>后的名称进行匹配，匹配成功后执行<code>except</code>后面的子句，最后执行<code>try</code>子句剩余的代码。若有<code>finally</code>子句，无论是否发生异常，该子句都会被执行。</p><p>一个 try 语句可能包含多个except子句，分别来处理不同的特定的异常。<br>最后一个except子句可以忽略异常的名称，它将被当作通配符使用。可使用它打印错误信息，并把异常抛出：</p><pre><code>import sys try:     f = open(&apos;myfile.txt&apos;)     s = f.readline()     i = int(s.strip()) except OSError as err:     print(&quot;OS error: {0}&quot;.format(err)) except ValueError:     print(&quot;Could not convert data to an integer.&quot;) except:     print(&quot;Unexpected error:&quot;, sys.exc_info()[0])     raise</code></pre><p>抛出异常，使用<code>raise</code>语句，后面的参数指明要抛出的异常，该异常必须是一个异常的实例或者是<code>Exception</code>的子类</p><h4 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h4><p>1 . 类有一个名为 <code>__init__()</code>的特殊方法（<strong>构造方法</strong>），该方法 <em>在类实例化时会自动调用</em>。<br>2 . 类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的第一个参数名称, 按照惯例它的名称是<code>self</code>。</p><blockquote><p><code>self</code> 代表的是类的实例，代表当前对象的地址，而 <code>self.class</code> 则指向类。</p></blockquote><pre><code>class Test:     def prt(self):         print(self)  # &lt;__main__.Test instance at 0x100771878&gt;        print(self.__class__) # __main__.Testt = Test() t.prt()</code></pre><p>3 . 单继承与多继承时，基类必须与派生类定义在一个作用域内。<br>除了类，还可以用表达式，基类定义在另一个模块中时这一点非常有用</p><pre><code>class DerivedClassName(modname.BaseClassName):</code></pre><p>4 . 多继承时需要注意圆括号中父类的顺序，若是父类中有相同的方法名，而在子类使用时未指定，python从左至右搜索 — 即方法在子类中未找到时，从左到右查找父类中是否包含方法。</p><p>5 . 继承时，若子类对父类的方法重写了，子类实例化，调用该方法时是调用重写方法；若想用子类对象调用父类已被覆盖的方法，使用 <code>super()</code>函数</p><p>6 . 类的私有变量和私有方法都是以两个下划线开头，类的实例 <strong>不能访问</strong>类的私有变量也 <strong>不能调用</strong>类的私有方法。</p><h4 id="标准库"><a href="#标准库" class="headerlink" title="标准库"></a>标准库</h4><p>1 . <code>os</code>（操作系统）模块与<code>sys</code>（命令行参数）模块的不同：<br><code>os</code>模块负责程序与操作系统的交互，提供了访问操作系统底层的接口；<br><code>sys</code>模块负责程序与Python解释器的交互，提供了一系列的函数和变量供用户操作Python运行时的环境。</p><p>2 . <code>timeit</code>模块，可以查看不同方法的性能差异。<br>例如：使用元组封装和拆封来交换元素看起来要比使用传统的方法要诱人的多,<code>timeit</code> 证明了现代的方法更快一些。</p><pre><code>from timeit import Timerprint(Timer(&apos;t=a; a=b; b=t&apos;, &apos;a=1; b=2&apos;).timeit()) # 0.20183640400000002print(Timer(&apos;a,b = b,a&apos;, &apos;a=1; b=2&apos;).timeit()) # 0.15459948599999995</code></pre><p>3 . 此外还有：</p><ul><li>文件通配符模块<code>glob</code>，用于从目录通配符搜索中生成文件列表；</li><li>字符串正则匹配模块<code>re</code>，为复杂的匹配和处理提供简介的方法；</li><li>数学模块<code>math</code>，调用一些底层C数学函数方便运算；常用的<code>random</code>模块，用于生成随机数；</li><li>访问互联网的模块，最常见的是处理从urls接收的数据的 <code>urllib.request</code>，以及用于发送电子邮件的 <code>smtplib</code>；</li><li>日期和时间模块 <code>datetime</code>，可以更有效地处理和格式化输出；</li><li>数据压缩模块，<code>zlib</code>， <code>gzip</code>， <code>bz2</code>， <code>zipfile</code>等；</li><li>测试模块<code>doctest</code>， 扫描模块并根据程序中内嵌的文档字符串执行测试；</li></ul><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p><a href="https://www.runoob.com/python3/python3-stdlib.html" target="_blank" rel="noopener">Python菜鸟教程</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;模块与包&quot;&gt;&lt;a href=&quot;#模块与包&quot; class=&quot;headerlink&quot; title=&quot;模块与包&quot;&gt;&lt;/a&gt;模块与包&lt;/h4&gt;&lt;h5 id=&quot;模块&quot;&gt;&lt;a href=&quot;#模块&quot; class=&quot;headerlink&quot; title=&quot;模块&quot;&gt;&lt;/a&gt;模块&lt;/h
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="python" scheme="http://ipine.github.io/tags/python/"/>
    
      <category term="data_analysis" scheme="http://ipine.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>易忘易忽略的Python入门知识点-续(一)</title>
    <link href="http://ipine.github.io/2019-05-05/"/>
    <id>http://ipine.github.io/2019-05-05/</id>
    <published>2019-05-05T08:53:47.908Z</published>
    <updated>2019-05-06T12:41:00.025Z</updated>
    
    <content type="html"><![CDATA[<h4 id="迭代器与生成器"><a href="#迭代器与生成器" class="headerlink" title="迭代器与生成器"></a>迭代器与生成器</h4><h5 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h5><p>迭代是Python最强大的功能之一，是访问集合元素的一种方式。<br>迭代器是一个可以记住遍历位置的对象。迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束，它只能往前不会后退。</p><p>迭代器，常用的两个方法<code>iter()</code>和<code>next()</code>；</p><pre><code>import oslist1 = [1,2,3,4]myiter = iter(list1) # 生成迭代器对象# for ele in myiter:#    print(next(ele))while True:    try:        print(next(ele))    except StopIteration:        os._exit(1)</code></pre><blockquote><p>当抛出StopIteration异常时，调用模块<code>sys</code>的<code>exit()</code>方法，会出现 <em>SystemExit exception raised from sys.exit()</em>；解决方法是使用调用 os._exit() ,它直接退出，不会抛出异常。参数是进程返回的退出码。</p></blockquote><p><strong>应用栗子</strong>：如何将列表分隔成大小均匀的块？<br>一个方法是结合使用 <code>zip()</code>和 <code>iter()</code>函数：</p><pre><code>x = [1,2,3,4,5,6,7,8,9]y = zip(*[iter(x)]*2)  # 2是表示每个块的大小list(y)   # [(1, 2), (3, 4), (5, 6), (7, 8)]</code></pre><p><strong>过程理解</strong>：</p><ol><li><code>iter()</code>是序列上的迭代器</li><li><code>[iter(x)] * 2</code>生成一个包含2个listiterator对象的列表：每个列表迭代器都是x的一个迭代器。</li><li>在将序列解压缩为参数之前传递给<code>zip()</code>函数的<code>*</code>，是为了将相同的迭代器传递给<code>zip()</code>函数4次，每次从迭代器中提取一个项。</li></ol><p><strong>具体步骤</strong>：<br>首先，会有2个列表迭代对象，就是原来相同的2个列表：[1,2,3,4,5,6,7,8,9]，[1,2,3,4,5,6,7,8,9]<br>然后， 第一次，<code>zip()</code>将按顺序接受列表中的一个元素，[1][2]</p><blockquote><p>注意：迭代对象会保留迭代器中下一个元素的位置</p></blockquote><p>第二次，元素将被添加到刚刚创建的2个列表中，最终将得到：[1, 3], [2,4]<br>第三次，执行相同的过程，最终得到：[1, 3, 5], [2, 4, 6]<br>第四次，执行相同的过程，最终得到：[1, 3, 5, 7], [2, 4, 6, 8]<br>最后，zip 将这三个列表压缩在一起，得到：(1, 2), (3, 4), (5, 6), (7, 8)</p><p>可以自己创建迭代器，将一个类作为一个迭代器，需要实现两个方法:</p><pre><code>class MyNumbers:    def __iter__(self):        self.a = 1        return self    def __next__(self):        if self.a &lt;= 5:            x = self.a            self.a += 1            return x        else:            raise StopIteration #StopIteration 异常用于标识迭代的完成，防止出现无限循环的情况myclass = MyNumbers()myiter = iter(myclass)for x in myiter:    print(x)</code></pre><h5 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h5><p>在 Python 中，使用了 <code>yield</code>的函数被称为<code>生成器（generator）</code>。 生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。<br>在调用生成器运行的过程中，每次遇到 <code>yield</code>时函数会暂停并保存当前所有的运行信息，返回 <code>yield</code>的值, 并在下一次执行<code>next()</code>方法时从当前位置继续运行。<br>调用一个生成器函数，返回一个迭代器对象</p><p><strong>应用栗子1</strong>：用yield实现斐波那契数列</p><pre><code>import osdef fibonacci(n):    a,b,count = 0,1,0    while True:        if count &gt; n:            return        yield a        a,b = b, a+b        count += 1f = fibonacci(10)while True:    try:        print(next(f), end=&apos; &apos;)    except StopIteration:        os._exit(1)</code></pre><p><strong>应用栗子2</strong>：用yield实现将列表分隔成大小均匀的块</p><pre><code>def chunks(list, chunkSize):    for i in range(0, len(list), chunkSize):        yield list[i:i + chunkSize]</code></pre><h4 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h4><p>1 . 函数参数传递<br>在 python 中，类型属于对象，变量是没有类型的，例如：</p><pre><code>a=[1,2,3]a=&quot;ipine&quot;</code></pre><p>以上代码中，[1,2,3] 是<code>List</code>类型，”ipine” 是 <code>String</code> 类型，而变量 a 是没有类型，它仅仅是一个 <strong>对象的引用（一个指针）</strong>，可以是指向 List 类型对象，也可以是指向 String 类型对象。</p><p>再次提到 可变 VS 不可变对象<br>strings，tuples和numbers不可变；list，dict等可变</p><ul><li>不可变类型：变量赋值 <code>a=5</code> 后再赋值 <code>a=10</code>，这里实际是新生成一个 <code>int</code> 值对象 10，再让<code>a</code>指向它，而 5 被丢弃，不是改变<code>a</code>的值，相当于 <em>新生成了a</em>。</li><li>可变类型：变量赋值 <code>la=[1,2,3,4]</code> 后再赋值 <code>la[2]=5</code> 则是将 list <code>la</code> 的第三个元素值更改，<em>本身la没有动，只是其内部的一部分值被修改了</em>。</li></ul><p>函数的参数传递分为 <strong>可变与不可变类型</strong></p><ul><li>不可变类型：类似 c++ 的值传递，如 整数、字符串、元组。如fun（a），传递的只是a的值，没有影响a对象本身。比如在 fun（a）内部修改 a 的值，只是修改另一个复制的对象，不会影响 a 本身。</li><li>可变类型：类似 c++ 的引用传递，如 列表，字典。如 fun（la），则是将 la 真正的传过去，修改后fun外部的la也会受影响。</li></ul><p>2 . 参数的类型</p><ul><li>必需（位置）参数，必需参数强调参数顺序。调用时的数量和位置必须和声明时的一样。</li><li>关键字参数，使用关键字参数来确定传入的参数值，对参数顺序不敏感，通过参数名匹配参数值。</li><li>默认参数，若调用没有传递参数，则使用默认参数。</li><li>不定长参数，不确定调用时传入几个参数，那声明参数时不命名。两种形式，一个星号的参数和两个星号的参数：</li></ul><blockquote><p>*args: 表示参数个数不确定，且想传入元组或列表形式的参数时使用；一个星号将序列或集合解包成位置参数</p></blockquote><blockquote><p>**kwargs: 表示参数个数不确定，且想传入字典的值作为关键字参数时使用；两个星号把字典解包成关键字参数</p></blockquote><p>声明函数时，参数中星号<code>*</code>可以单独出现，但是星号后面的参数，必须用 <em>关键字</em>传入。例如：</p><pre><code>def f(a,b,*,c):    return a+b+cf(1,2,3) #报错f(1,2, c=3) #正确</code></pre><p>3 . 匿名函数 <code>lambda</code>是一个表达式，不是一个代码块。它不能访问 自己参数列表之外或全局命名空间里的参数。<br>4 . 不带参数值的<code>return</code>语句返回的是<code>None</code>；如果函数没有使用 return 语句，则函数返回 <code>None</code>。<br>5 . 变量作用域<br>Python的作用域有4种，分别是：</p><blockquote><p>L （Local） 局部作用域<br>E （Enclosing） 闭包函数外的函数中<br>G （Global） 全局作用域<br>B （Built-in） 内置作用域（内置函数所在模块的范围）</p></blockquote><p>查找的规则是：在局部找不到，去局部外的局部找（闭包），再找不到就全局找，最后再去内置找。</p><pre><code>g_count = 0  # 全局作用域def outer():    o_count = 1  # 闭包函数外的函数中    def inner():        i_count = 2  # 局部作用域</code></pre><p>内置作用域是通过一个名为<code>builtins</code> 的标准模块来实现的, 必须导入这个文件才能够使用它。</p><pre><code>import builtinsprint(dir(builtins))</code></pre><blockquote><p>模块、类、函数（包括lambda表达式）会引入新的作用域，其他代码块不会。</p></blockquote><p>6 . global和nonlocal关键字<br>当内部作用域想修改外部作用域的变量时，需要用global和nonlocal关键字。</p><p><code>global</code>关键字用于修改全局作用域的变量，例如：</p><pre><code>num = 1 def fun1():     global num # 需要使用 global 关键字声明     print(num)  # 1    num = 123     print(num)  # 123fun1() print(num) # 123，已经将全局变量的值修改了</code></pre><p><code>nonlocal</code>关键字用于修改嵌套（enclosing）作用域，例如：</p><pre><code>def outer():     num = 10     def inner():         nonlocal num # nonlocal关键字声明         num = 100         print(num)  # 100    inner()     print(num)  # 100outer()</code></pre><p>一种特殊情况，函数使用全局作用域的变量，如下一段代码：</p><pre><code>a = 10def test():    a = a + 1    print(a)test(a)</code></pre><p>会抛出 <em>局部作用域引用错误</em>，因为test 函数中的<code>a</code> 使用的是局部变量，未定义，无法修改。<br>正确应该是：</p><pre><code>a = 10def test(a):    a = a + 1    print(a)test(a) # 11print(a) # 10，传递参数类型是不可变类型，所以只是值传递</code></pre><h4 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h4><p>1 . 列表的<code>clear()</code>方法，用于移除列表中的所有项，等于<code>del a[:]</code>。 使用 <code>del</code> 语句可以从一个列表中依索引而不是值来删除一个元素；也可以使用它传入<code>key</code>来删除字典元素。<br>2 . 可以用花括号<code>{}</code>创建集合。注意：如果要创建一个空集合，你必须用 <code>set()</code> 而不是<code>{}</code>；后者创建一个空的字典。集合的功能包括 <strong>成员关系检查</strong>和 <strong>消除重复元素</strong>。<br>3 . 选择正确的内置功能。<br>当遍历列表既要访问索引又要访问值时，使用<code>enumerate()</code>而不是<code>range()</code>进行迭代。<br>对于每个元素，<code>enumerate()</code>返回一个计数器和元素值。计数器默认为0，也是元素的索引。不想在0开始计数，只需使用可选的<code>start</code>参数来设置偏移量：</p><pre><code>numbers = [45, 22, 14]for i, num in enumerate(numbers, start=52):    print(i, num) </code></pre><p>当遍历字典时，使用 <code>items()</code> 将关键字和对应的值同时解读出来：</p><pre><code>knights = {&apos;gallahad&apos;: &apos;the pure&apos;, &apos;robin&apos;: &apos;the brave&apos;}for k, v in knights.items():    print(k, v)</code></pre><p>同时遍历两个或更多的序列，使用 <code>zip()</code> 组合：</p><pre><code>questions = [&apos;name&apos;, &apos;favorite color&apos;]answers = [&apos;ipine&apos;, &apos;red&apos;]for q, a in zip(questions, answers):    print(f&apos;What is your {q}? It is {a}.&apos;)    # print(&apos;What is your {0}?  It is {1}.&apos;.format(q, a))</code></pre><p>按顺序遍历序列，使用 <code>sorted()</code>函数返回有序序列，不改变原序列：</p><pre><code>basket = [&apos;apple&apos;, &apos;orange&apos;, &apos;apple&apos;, &apos;pear&apos;, &apos;orange&apos;, &apos;banana&apos;]for f in sorted(set(basket)):    print(f)print(basket)</code></pre><p>反向遍历一个序列，首先指定序列，然后调用<code>reversed()</code>函数：</p><pre><code>for i in reversed(range(1, 10, 2)):    print(i,end=&apos; &apos;) # 9 7 5 3 1</code></pre><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p><a href="https://www.runoob.com/python3/python3-stdlib.html" target="_blank" rel="noopener">Python菜鸟教程</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;迭代器与生成器&quot;&gt;&lt;a href=&quot;#迭代器与生成器&quot; class=&quot;headerlink&quot; title=&quot;迭代器与生成器&quot;&gt;&lt;/a&gt;迭代器与生成器&lt;/h4&gt;&lt;h5 id=&quot;迭代器&quot;&gt;&lt;a href=&quot;#迭代器&quot; class=&quot;headerlink&quot; title=
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="python" scheme="http://ipine.github.io/tags/python/"/>
    
      <category term="data_analysis" scheme="http://ipine.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>实习碰壁之后-正式入坑数据分析</title>
    <link href="http://ipine.github.io/2019-04-28/"/>
    <id>http://ipine.github.io/2019-04-28/</id>
    <published>2019-05-04T13:36:35.858Z</published>
    <updated>2019-05-04T13:49:40.223Z</updated>
    
    <content type="html"><![CDATA[<h3 id="目前的状态"><a href="#目前的状态" class="headerlink" title="目前的状态"></a>目前的状态</h3><p>我是一名计算机专业的在读研究生，研究方向是数据可视化，可视分析。从实验室以及研究方向来看，周边大部分同学选择了前端开发，少部分也有做后台的。而我个人并不是特别愿意去做前端开发，我想做数据分析，数据挖掘相关的工作。目前，正是找实习的时候，但是我找数据分析的岗并不顺利，迟迟没有拿到实习offer，而周围那些找前端开发的同学早已盆满钵满。说不羡慕那是假的，但是能怎么样呢？路是自己选的，再哭也得走下去呀！有句话说，要做难且正确的事，我想我现在是在这条路上。<br>早在一年前就定了数据分析这个方向，但是自己平时学习就是看一些书籍，没有数据挖掘相关的实践项目，苦于没有带路人，也不知道岗位的具体要求。找实习的时候才发现，不同公司对数据分析、挖掘岗的要求都不一样，但大部分都要求对业务有了解，对挖掘算法熟悉，做过相关项目；所以尽管我投了很多简历，但是都石沉大海，我也像一个无头苍蝇，摸不到门道，到处碰壁。我之前做科研项目，写JavaScript比较多，后来自学数据分析课程，学习了Python，SQL和基本算法的知识，算是入门了数据分析。但是我想多做一些实践项目，更深入地学习某一个细分行业的数据分析和挖掘流程，为秋招求职助力。</p><h3 id="未来想从事的具体行业"><a href="#未来想从事的具体行业" class="headerlink" title="未来想从事的具体行业"></a>未来想从事的具体行业</h3><p>入门之后，选择一个方向，深入学习研究才可能成功，这跟做科研是一个道理。我在反思自己为什么找实习不顺时，发现一点就是自己的专业技能不够突出，前端会一点，数据分析刚入门，学习太过宽泛而都不够精专。公司更想招聘的一定是某一技能方面的“专家”，而不是什么都懂一点，什么都做不了的员工。所以有了这两个月找实习的经历，我意识到自己不能再这样一边焦虑未来，一边漫无目的地学习，更好的方式就是找到自己感兴趣的具体行业，然后实践。 虽然做过一个关于区块链加密货币交易数据的科研项目，但是我对金融行业的背景和业务知识知之甚少，没有系统学习过。与金融行业相比，互联网+电商行业的实践更为容易，我也有兴趣。所以，刚开始想从互联网+电商行业的数据分析、数据挖掘实践入手。从本科到研究生都是计算机专业的学生，读研期间学习的是数据分析流程中必不可少的一环—数据可视化，所以对自己从事这个方向的工作还是有信心的，不足的地方仍然是对行业的背景知识和业务知识了解不深入，这方面现在可以慢慢接触，在工作中积攒更多经验。</p><h3 id="如何更近距离接触相关行业"><a href="#如何更近距离接触相关行业" class="headerlink" title="如何更近距离接触相关行业"></a>如何更近距离接触相关行业</h3><p>找到兴趣行业，如何迈出了解行业的第一步呢？<br>其实最简单的方式，就是去找一个这个行业的数据集，自己尝试着去探索数据。我从阿里天池下载了一个数据集，是<a href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=45" target="_blank" rel="noopener">用户在淘宝和天猫上购买婴儿用品的数据集</a>，该数据包含两个文件，分别是淘宝会员历史婴儿用品交易样本数据文件，和婴儿信息样本数据文件。历史婴儿用品交易样本数据文件包含29971条数据，有以下7个字段：</p><pre><code>* user_id: 用户id* auction_id: 购买行为编号* cat_id: 商品种类ID* cat1: 商品属于哪个类别* property: 商品属性* buy_mount: 购买数量</code></pre><p>婴儿信息样本数据文件，包含953条，有以下3个字段：</p><pre><code>* user_id:用户id* birthday:出生日期* gender:性别（0 男性；1 女性）</code></pre><p>官方提供的典型分析主题包括：</p><ol><li>根据父母的购买行为预测孩子的年龄；</li><li>根据孩子的信息(年龄、性别等)预测用户会购买什么样的商品。</li></ol><p>在之后的文章中我会对这个数据集进行分析和探索。</p><h3 id="学习规划"><a href="#学习规划" class="headerlink" title="学习规划"></a>学习规划</h3><p>有了目标，自然少不了学习规划。有计划地学习，每完成一个阶段任务，都能获得一些学习成就感，激励自己继续向前。计划如下：</p><ul><li>复习及巩固Python语言知识</li><li>使用Python的NumPy和Pandas包进行数据分析练习</li><li>机器学习算法相关的实践</li><li>学习如何撰写Python数据可视化和分析报告</li><li>推论统计相关的实践</li><li>完善简历，丰富项目经验，不定期</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;目前的状态&quot;&gt;&lt;a href=&quot;#目前的状态&quot; class=&quot;headerlink&quot; title=&quot;目前的状态&quot;&gt;&lt;/a&gt;目前的状态&lt;/h3&gt;&lt;p&gt;我是一名计算机专业的在读研究生，研究方向是数据可视化，可视分析。从实验室以及研究方向来看，周边大部分同学选择了前端开
      
    
    </summary>
    
      <category term="method" scheme="http://ipine.github.io/categories/method/"/>
    
    
      <category term="data_analysis" scheme="http://ipine.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>易忘易忽略的Python入门知识点</title>
    <link href="http://ipine.github.io/2019-05-04/"/>
    <id>http://ipine.github.io/2019-05-04/</id>
    <published>2019-05-04T12:17:10.537Z</published>
    <updated>2019-05-04T13:12:54.123Z</updated>
    
    <content type="html"><![CDATA[<p>最近在复习Python的基础知识，发现一些易忽略和忘记的点，这里做一些总结。</p><h4 id="可改变-VS-不可改变"><a href="#可改变-VS-不可改变" class="headerlink" title="可改变 VS 不可改变"></a>可改变 VS 不可改变</h4><p>不可改变的数据类型包括：数值、字符串和元组；而可改变的数据类型包括：列表、字典、集合。需要注意字典的key必须为不可变类型；集合虽然是可变的但是它要求包含的元素是不可变类型。不可变类型换一种更官方的说法叫可<code>Hashable</code>，利用可<code>Hashable</code>的元素，检查成员关系时速度会更快。可通过<code>collections</code>模块的<code>Hashable</code>属性查看数据类型是否是不可变的：</p><pre><code>import collections print(isinstance({}, collections.Hashable))  # False</code></pre><p>此处引出另外一个点，即<code>isinstance()</code>和<code>type()</code>的区别。<code>type()</code>常用于查看数据类型，<code>isinstance()</code>常用于判断数据类型；两者对于类的判断会稍有不同，<code>isinstance()</code>会将子类当作与父类一样的类型，而<code>type()</code>则认为子类与父类是不同的。</p><h4 id="有序-VS-无序"><a href="#有序-VS-无序" class="headerlink" title="有序 VS 无序"></a>有序 VS 无序</h4><p>有序的容器：元组、列表；无序的容器：字典、集合。<br>元组是不可变的有序列表，没有<code>append()</code>或<code>extend()</code>方法，也没有<code>remove()</code>或<code>pop()</code>方法；字典以键值对的形式存在，而列表只包含值；集合要求元素唯一不可变，列表可重复且可变。<br>提到<code>append()</code>或<code>extend()</code>方法，不得不说下它们之间的区别：<code>extend()</code>接受一个迭代器（列表、元组、集合、字符串等），一次一个地将迭代器中元素添加到列表中；而<code>append()</code>直接将迭代器当作一个对象。</p><h4 id="容器的定义"><a href="#容器的定义" class="headerlink" title="容器的定义"></a>容器的定义</h4><p>列表的定义，元素类型可不同，可嵌套。创建方式：</p><pre><code># 创建空列表list1 = []# 创建简单列表list2 = [&apos;ipine&apos;, 7, &apos;https://ipine.me/&apos;]</code></pre><p>元组的定义，需要注意空元组和只有一个值的情况：</p><pre><code>tup1 = ()tup2 = (1,)</code></pre><p>字典的定义，键唯一且不可变，值不必唯一可取任何数据类型。创建方式如下：</p><pre><code># 创建空字典dict1 = {}# 创建简单字典dict2 = {&apos;name&apos;: &apos;ipine&apos;, &apos;site&apos;: &apos;https://ipine.me/&apos;}# 使用构造函数 dict()dict3 = dict([(&apos;name&apos;,&apos;ipine&apos;),(&apos;site&apos;,&apos;https://ipine.me/&apos;)])# 或者dict4 = dict(name = &apos;ipine&apos;, site = &apos;https://ipine.me/&apos;)</code></pre><p>集合的定义，集合的基本功能是删除重复元素和检查成员关系。创建方式如下：</p><pre><code># 创建空集合,不能直接用空花括号，那是创建空字典set1 = set()# 创建简单集合set2 = {&apos;ipine&apos;, &apos;Alex&apos;}# 或者set3 = set(&apos;ipine&apos;, &apos;Alex&apos;)</code></pre><h4 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h4><p>1.<code>+</code>用于连接字符串；<code>*</code>用于重复输出字符串；字符串在行尾使用反斜杠 <code>\</code> ，表示续行；字符串前面加上字母 <code>r/R</code>，表示输出原始字符串。<br>2.<code>is</code>用于判断两个变量引用的是否是同一个对象，类似于 <code>id(x) == id(y)</code>，<code>id</code>用于获取对象内存地址; 而<code>==</code> 用于判断引用变量的值是否相等。</p><pre><code>a = [1, 2, 3]b = a[:]print(b is a)  # Falseprint(b == a)  # True</code></pre><p>3.普通的格式化字符串，使用<code>%s</code>；若Python 3.6+，更好的格式化方法是使用<code>f-strings</code></p><pre><code>def get_name_and_decades(name, age):        return f&quot;My name is {name} and I&apos;m {age / 10:.5f} decades old.&quot;</code></pre><p>但要注意，如果是输出用户生成的值这种情况下，模板字符串可能是更安全的选择。</p><pre><code>from string import Templatedef get_name_and_decades(name, age):        a = Template(&quot;My name is ${key1} and I&apos;m ${key2 / 10:.5f} decades old.&quot;)        a.substitute(key1 = name, key2 = age)        return a</code></pre><h4 id="从列表中选择元素"><a href="#从列表中选择元素" class="headerlink" title="从列表中选择元素"></a>从列表中选择元素</h4><p>可以使用索引操作符 <code>[]</code> , 索引下标从0开始；获取最后一个元素，传入 -1；切片取多个值，遵循 <strong>含前不含后</strong>原则：</p><pre><code>a[start: end : step]  # step默认取1，不会跳过任何元素a[start : ]  a[ : end]   a[ : ]  # 复制列表</code></pre><p>从列表中任意选择一个元素</p><pre><code>from random import choicelist = [&apos;a&apos;,&apos;b&apos;,&apos;c&apos;,&apos;d&apos;]print(choice(list))</code></pre><p>利用索引任意选择一个元素</p><pre><code>from random import randrangerandomLetters = [&apos;a&apos;,&apos;b&apos;, &apos;c&apos;, &apos;d&apos;]randomIndex = randrange(0,len(randomLetters))print(randomLetters[randomIndex])</code></pre><h4 id="列表转其他数据结构"><a href="#列表转其他数据结构" class="headerlink" title="列表转其他数据结构"></a>列表转其他数据结构</h4><p>1.将列表转换成字符串： <code>&#39;&#39;.join()</code></p><pre><code>listOfNumbers = [1, 2, 3]strOfNumbers = &apos;&apos;.join(str(n) for n in listOfNumbers)  #对于数字要先转换成strprint(strOfNumbers)</code></pre><p>2.列表转元组：<code>tuple()</code> ; 列表转集合：<code>set()</code><br>3.列表转字典：<code>zip()</code></p><pre><code>helloWorld = [&apos;hello&apos;,&apos;world&apos;,&apos;1&apos;,&apos;2&apos;] # 转成字典helloWorldDictionary = dict(zip(helloWorld[0::2], helloWorld[1::2]))print(helloWorldDictionary)   # {&apos;1&apos;: &apos;2&apos;, &apos;hello&apos;: &apos;world&apos;}# 解析成元组对后以列表形式输出list(zip(helloWorld))   # [(&apos;hello&apos;,), (&apos;world&apos;,), (&apos;1&apos;,), (&apos;2&apos;,)]</code></pre><h4 id="复制列表"><a href="#复制列表" class="headerlink" title="复制列表"></a>复制列表</h4><p>方式很多，最常见的是切片方式：<code>newList = oldList[ : ]</code> ；使用内置函数：<code>newList = list(oldList)</code>；也可以使用库函数，这会涉及到浅拷贝和深拷贝的区分。浅拷贝：<code>newList = copy.copy(oldList)</code>；对于包含对象的列表，若想将这些对象也完全复制，用深拷贝：<code>copy.deepcopy(oldList)</code>。</p><blockquote><p>注意：切片方式是浅拷贝。对于浅拷贝，改变对象，原来的列表也会改变</p></blockquote><pre><code>objectList = [&apos;a&apos;,&apos;b&apos;,[&apos;ab&apos;,&apos;ba&apos;]]copiedList = objectList[:]copiedList[0] = &apos;c&apos; copiedList[2][1] = &apos;d&apos;print(objectList)   # [&apos;a&apos;, &apos;b&apos;, [&apos;ab&apos;, &apos;d&apos;]] </code></pre><h4 id="列表解析的理解"><a href="#列表解析的理解" class="headerlink" title="列表解析的理解"></a>列表解析的理解</h4><p>列表解析是一种构建列表的优雅方法，它包含两种形式。<br>形式一：</p><pre><code>[i for i in range(k) if condition]</code></pre><p>此时 <code>if</code> 起条件判断作用，满足条件的，将被返回成为最终生成的列表的一员。</p><p>形式二：</p><pre><code>[i if condition else exp for exp]</code></pre><p>此时 <code>if...else</code> 被用来赋值，满足条件的 <code>i</code> 以及 <code>else</code> 被用来生成最终的列表。<br>举个栗子：</p><pre><code>print([i for i in range(10) if i%2 == 0])  # [0, 2, 4, 6, 8]print([i if i == 0 else 100 for i in range(10)])   # [0, 100, 100, 100, 100, 100, 100, 100, 100, 100]</code></pre><h4 id="列表排序"><a href="#列表排序" class="headerlink" title="列表排序"></a>列表排序</h4><p>排序会改变原始列表，建议在原始列表不再使用的情况下使用此功能。列表排序有两种方式，一种是列表调用<code>sort</code>函数，<code>list.sort()</code>；另一种是往<code>sorted</code>函数传入列表，<code>sorted(list)</code> 。使用<code>sorted</code>对复杂列表排序，除了<code>reverse</code>参数外，还有个<code>key</code>参数，用于指定按哪个属性值排序，如下示例：</p><pre><code>sorted(animals, key=lambda animal: animal[&apos;age&apos;]) # animals是字典列表</code></pre><h4 id="有效利用数据结构"><a href="#有效利用数据结构" class="headerlink" title="有效利用数据结构"></a>有效利用数据结构</h4><p>1.移除任何迭代器中的重复值，只需将其传递给内置的 <code>set()</code> 函数。迭代器可以是列表、字典等，查看一个变量是否是迭代器可以应用 <code>.__iter__</code>。 如果以后需要一个真正的列表，也可以类似地将 set 传递给 <code>list()</code> 函数。</p><pre><code>duplicates = [1, 2, 3, 1, 2, 5, 6, 7, 8]print(list(set(duplicates))) # [1, 2, 3, 5, 6, 7, 8]</code></pre><blockquote><p>注意：使用了 <code>set()</code> 函数后，列表元素的顺序丢失。如果元素的顺序很重要，那么需要使用其他的机制：<a href="https://www.peterbe.com/plog/uniqifiers-benchmark" target="_blank" rel="noopener">可参考这个博文</a></p></blockquote><p>2.使用set存储唯一值。<br>举个栗子：假装你有一个名为<code>get_random_word()</code>的函数。 重复调用它以获取1000个随机单词，然后返回包含每个唯一单词的数据结构。</p><pre><code>import randomdef get_random_word(words):        return random.choice(words)</code></pre><p>好的做法：</p><pre><code>def get_unique_words(words):        words_set = set()        for _ in range(1000):                words_set.add(get_random_word(words))        return words_set</code></pre><p>差的做法：</p><pre><code>def get_unique_words(words):        words_set = []        for _ in range(1000):                word = get_random_word(words)                if word not in words_set:                        words_set.append(word)        return words_set</code></pre><p>这种不好的做法，必须将每个新单词与列表中已有的每个单词进行比较，时间复杂度<code>O(n^2)</code>；且在列表中检索元素比在集合中慢，集合元素是可 <strong>hashable</strong> 。<em>集合存储元素的方式允许接近恒定时间检查值是否在集合中，而不像需要线性时间查找的列表。</em></p><p>3.使用 <code>.get()</code> 和 <code>.setdefault()</code> 在字典中定义默认值。<br>当需要添加，修改或检索可能在字典中或可能不在字典中的项:</p><pre><code>name = names.get(&apos;name&apos;, &apos;The Man with No Name&apos;)  # 获取name的值，若name没值就返回后面参数的默认内容如果key存在，则返回对应的值。否则，返回设置的默认值。</code></pre><p>但是，如果你仍想在访问<code>name</code>键时使用默认值更新字典，还是需要再次显式检查该值：</p><pre><code>if &apos;name&apos; not in names:        names[&apos;name&apos;] = &apos;The Man with No Name&apos;</code></pre><p>更简洁的做法是使用<code>.setdefault()</code>，完成以上两个步骤。</p><pre><code>name = names.setdefault(&apos;name&apos;, &apos;The Man with No Name&apos;) # 获取name的值，若name没值就将name的值设置为后面参数的默认内容</code></pre><h4 id="标准库的使用"><a href="#标准库的使用" class="headerlink" title="标准库的使用"></a>标准库的使用</h4><p>1.使用collections包的 <code>defaultdict()</code> 处理缺少的字典键。为单个键设置默认值时，<code>.get()</code> 和 <code>.setdefault()</code> 可以正常工作，但通常需要为所有可能的未设置键设置默认值，这两种方式比较麻烦。更简洁的方法是使用<code>defaultdict()</code>方法。</p><p><strong>举个栗子</strong>：统计字符串中字母出现的次数，数字或是其他符号不算。<br>常规做法：迭代字符串s，并检查字符是否已经是字典的key，如果不是，则将其添加到字典中，并将1作为默认值；如果是，则key对应值加1：</p><pre><code>def count_letter(s):        dic = {}        for ele in s:                if ele.isalpha():                        if ele in dic:                                dic[ele] +=1                        else:                                dic[ele] = 1        return dic</code></pre><p>更简洁做法：</p><pre><code>from collections import defaultdictdef count_letter(s):        dic = defaultdict(int) # int对应值为0        for ele in s:                if ele.isalpha():                        dic[ele] += 1      return dic</code></pre><blockquote><p>语法说明，<code>dict =defaultdict(factory_function)</code>，factory_function可以是list、set、str等等，作用是当key不存在时，返回的是工厂函数的默认值，比如list对应<code>[ ]</code>，str对应的是<code>空字符串</code>，set对应<code>set( )</code>，int对应<code>0</code>；</p></blockquote><p>若想设置为某个value；那么可以传入<code>lambda</code>函数</p><pre><code>dic = defaultdict(lambda: 1)</code></pre><p>当然，统计迭代器中每个项出现的次数，可以直接使用 <code>Counter()</code> 函数；<br>若好奇最常见的一个项是什么，只需使用 <code>.most_common()</code>：</p><pre><code>from collections import Counterlist = [&quot;a&quot;,&quot;b&quot;,&quot;b&quot;]counts = Counter(list)  # Counter({&apos;a&apos;: 1, &apos;b&apos;: 2})counts.most_common(1)  # b</code></pre><p>2.使用collections包的<code>deque()</code>方法创建队列和栈数据结构。队列，先入先出的结构；栈，后入先出的结构，类似于浏览器的“后退”按钮。</p><p>定义队列，入队和出队操作：</p><pre><code>from collections import dequequeue = deque([1, 3, 4, 7, 0])queue.append(10) queue.popleft() </code></pre><p>定义栈，入栈和出栈操作：</p><pre><code>stack = deque([&apos;1st webpage&apos;,&apos;2nd webpage&apos;,&apos;3rd webpage&apos;])stack.append(&apos;4th webpage&apos;)stack.pop()</code></pre><p>3.使用collections包的排序字典方法 <code>OrderedDict()</code> ，使输出的字典顺序与key的输入顺序一致。</p><pre><code>from collections import OrderedDictorder_dict = OrderedDict({&apos;first&apos;:1, &apos;second&apos;:2, &apos;third&apos;: 3})</code></pre><p>4.使用 itertool 生成排列和组合： <code>itertools.permutations()</code> 和 <code>itertools.combinations()</code>。<br>排列是考虑了顺序的，(A,B)和(B,A)不一样；组合是没考虑顺序，(A,B)和(B,A)一样。</p><pre><code>import itertoolsfriends = [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;]list(itertools.permutations(friends, r=2)) # r指定每个分组有几个值list(itertools.combinations(friends, r=2))</code></pre><p>5.使用operator模块中的 <code>add()</code> 方法，更机智地对列表元素求和。</p><pre><code>from operator import addlist(map(add, list1, list2)) # map每个元素；最后记得使用 list()打印 map()函数的结果</code></pre><p>对两个列表的元素求和，也可以在列表解析中使用 <code>zip()</code> 函数</p><pre><code>[sum(x) for x in zip(list1, list2)]</code></pre><p>6.使用functools包的 <code>reduce()</code> 方法，将嵌套列表变成flat list。</p><pre><code>from functools import reducelistOfList = [[1,2], [3,4], [5,6]]print(reduce(lambda x,y: x+y,listOfLists)) # reduce需传入两个参数，前一个是lambda表达式，后一个是列表； +操作符是连接列表的符号</code></pre><p>也可以使用 <code>sum()</code> 函数：</p><pre><code>list = [[1,2],[3,4],[5,6]]sum(list, [])    # [1, 2, 3, 4, 5, 6]</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近在复习Python的基础知识，发现一些易忽略和忘记的点，这里做一些总结。&lt;/p&gt;
&lt;h4 id=&quot;可改变-VS-不可改变&quot;&gt;&lt;a href=&quot;#可改变-VS-不可改变&quot; class=&quot;headerlink&quot; title=&quot;可改变 VS 不可改变&quot;&gt;&lt;/a&gt;可改变 VS 
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="python" scheme="http://ipine.github.io/tags/python/"/>
    
      <category term="data_analysis" scheme="http://ipine.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>散列表</title>
    <link href="http://ipine.github.io/2018-12-18/"/>
    <id>http://ipine.github.io/2018-12-18/</id>
    <published>2018-12-18T11:30:10.894Z</published>
    <updated>2019-02-22T11:26:25.452Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h3 id="散列表效率"><a href="#散列表效率" class="headerlink" title="散列表效率"></a>散列表效率</h3><p>之前讲到散列表的查询效率并不能笼统地说成是 <code>O(1)</code> 。它跟散列函数、装载因子、散列冲突都有关系。在极端情况下，恶意攻击者，通过精心构造的数据，使得所有数据经过散列函数后，都散列到同一个槽里。若我们使用的是基于链表的冲突解决办法，那这个时候，散列表就会退化为链表，查询时间度也退化为 <code>O(n)</code>。</p><h3 id="开篇问题"><a href="#开篇问题" class="headerlink" title="开篇问题"></a>开篇问题</h3><p>如何设计一个可以应对各种异常情况的工业级散列表？在散列冲突的情况下，能够避免散列表性能的急剧下降。</p><h3 id="散列函数"><a href="#散列函数" class="headerlink" title="散列函数"></a>散列函数</h3><ul><li>设计不能太复杂 ：避免消耗很多计算时间</li><li>生成的值要尽可能随机并且均匀分布：避免或者最小化散列冲突</li></ul><h3 id="装载因子过大怎么办？"><a href="#装载因子过大怎么办？" class="headerlink" title="装载因子过大怎么办？"></a>装载因子过大怎么办？</h3><p>装载因子越大，说明散列表中的元素越多，空闲位置越少，散列冲突的概率就越大。<br>不仅插入数据的过程要多次寻址或者拉很长的链，查找的过程也会因此变得很慢。</p><h4 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h4><p>使用动态扩容，重新申请一个更大的散列表，将数据搬移到这个新散列表中。</p><p><img src="http://ipineimg.lijundong.com/18-12-18/9130606.jpg" alt="动态扩容"></p><blockquote><p>存在问题：数据搬移操作很复杂，需要通过散列函数重新计算每个数据的存储位置。</p></blockquote><h4 id="插入数据时间复杂度"><a href="#插入数据时间复杂度" class="headerlink" title="插入数据时间复杂度"></a>插入数据时间复杂度</h4><ul><li>最好情况：不需要扩容，复杂度为 <code>O(1)</code></li><li>最坏情况：散列表装载因子过高，需扩容，重新申请内存，重新计算哈希位置，并搬移位置，复杂度为 <code>O(n)</code></li><li>平均情况：摊还分析，时间复杂度接近最好情况，为 <code>O(1)</code></li></ul><h4 id="平衡空间与时间的消耗"><a href="#平衡空间与时间的消耗" class="headerlink" title="平衡空间与时间的消耗"></a>平衡空间与时间的消耗</h4><p>若对空间消耗非常敏感，可以为装载因子设置阈值，当装载因子小于阈值之后，启动动态缩容。</p><p>若更在意执行效率，能够容忍多消耗一点内存空间，就不需要缩容。</p><p>装载因子阈值需要选择得当。如果太大，会导致冲突过多；如果太小，会导致内存浪费严重。<br>阈值的设置要权衡时间、空间复杂度。<br>如果内存空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；</p><p>相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值，甚至可以大于 1。</p><h3 id="避免低效扩容"><a href="#避免低效扩容" class="headerlink" title="避免低效扩容"></a>避免低效扩容</h3><p>为解决一次性扩容耗时过多的情况，可以将扩容操作穿插在插入操作的过程中，分批完成。</p><h4 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h4><ul><li>当装载因子触达阈值之后，只申请新空间，并不将老的数据搬移到新的散列表中。</li><li>每当有新数据插入，将新数据插入新散列表，并从旧散列表拿一个数据放入新散列表。</li></ul><p><img src="http://ipineimg.lijundong.com/18-12-18/95492788.jpg" alt="高效扩容"></p><h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><p>通过以上均摊方法，将一次扩容的代价，均摊到多次插入操作中。这种实现方式，在任何情况下，插入一个数据的时间复杂度都是 <code>O(1)</code></p><h4 id="查询操作"><a href="#查询操作" class="headerlink" title="查询操作"></a>查询操作</h4><ul><li>先在新散列表中查询</li><li>未查询到，再到旧散列表中查找</li></ul><h3 id="冲突解决方法"><a href="#冲突解决方法" class="headerlink" title="冲突解决方法"></a>冲突解决方法</h3><h4 id="开放寻址法"><a href="#开放寻址法" class="headerlink" title="开放寻址法"></a>开放寻址法</h4><p><strong>优点</strong></p><ul><li>数据存储在数组中，有效利用CPU缓存加快查询速度</li><li>方便序列化</li><li>不需要额外空间</li></ul><p><strong>缺点</strong></p><ul><li>查找、删除数据时，涉及到<code>delete</code>标记，比较麻烦</li><li>所有数据存储在一个数组中，冲突代价比较高</li><li>装载因子的上限不能太大，更浪费空间</li></ul><h4 id="链表法"><a href="#链表法" class="headerlink" title="链表法"></a>链表法</h4><p><strong>优点</strong></p><ul><li>对内存的利用率更高</li><li>对装载因子的容忍度更高；即便装载因子变成10，也只是链表的长度变长</li></ul><p><strong>缺点</strong></p><ul><li>需要额外的空间来保存指针</li><li>结点零散分布在内存中，不连续，对CPU缓存不友好</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>当数据量比较小、装载因子小的时候，适合采用开放寻址法；</p><p>面对大对象、大数据量的散列表时，适合采用基于链表的散列冲突处理方法。<br>而且，比起开放寻址法，链表法更加灵活，支持更多的优化策略，比如用红黑树代替链表。</p><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><h4 id="工业级的散列表应该具有哪些特性？"><a href="#工业级的散列表应该具有哪些特性？" class="headerlink" title="工业级的散列表应该具有哪些特性？"></a>工业级的散列表应该具有哪些特性？</h4><ul><li>支持快速的查询、插入、删除操作；</li><li>内存占用合理，不能浪费过多的内存空间；</li><li>性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况。</li></ul><h4 id="从三个方面来考虑设计思路"><a href="#从三个方面来考虑设计思路" class="headerlink" title="从三个方面来考虑设计思路"></a>从三个方面来考虑设计思路</h4><ul><li>设计一个合适的散列函数；</li><li>定义装载因子阈值，并且设计动态扩容策略；</li><li>选择合适的散列冲突解决方法。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;散列表效率&quot;&gt;&lt;a href=&quot;#散列表效率&quot; class=&quot;headerlink&quot; title=&quot;散列表效率&quot;&gt;&lt;/a&gt;散列表效率&lt;/h3&gt;&lt;p&gt;之前讲到散列表的查询效率并不能笼统地说成是 &lt;code&gt;O(1)&lt;/code&gt; 
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>探索气温趋势</title>
    <link href="http://ipine.github.io/2018-11-26/"/>
    <id>http://ipine.github.io/2018-11-26/</id>
    <published>2018-11-26T06:22:44.405Z</published>
    <updated>2019-02-22T11:28:02.148Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://github.com/iPine/data_analysis_project_1" target="_blank" rel="noopener">代码传送门，包括扩展了交互功能的改进版</a></p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>分析全球和自己所在地的气温数据，比较所在城市的气温走向与全球气温走向。</p><h3 id="数据获取"><a href="#数据获取" class="headerlink" title="数据获取"></a>数据获取</h3><p>从数据库中提取数据。通过<a href="https://classroom.udacity.com/nanodegrees/nd002-cn-basic-vip/parts/d1865612-f3fd-4db0-80c7-348c594d573d/modules/7b83f9fd-759a-4cc6-8456-ce3783e17475/lessons/dce89631-d141-4a36-b3fd-5e8ec038bc70/concepts/530f21c0-2f37-4390-aaab-3ce440e56d80" target="_blank" rel="noopener">Udacity</a>提供的工作区，该工作区与数据库连接。</p><h4 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h4><p>写入以下SQL语句，导出世界气温数据以及最接近自己居住地的大城市气温数据。</p><ol><li><p>首先查看<code>city_list</code>表，<code>country</code>列等于<code>China</code>的城市有哪些;</p></li><li><p>然后将离自己所在城市<code>长沙</code>最近的城市<code>武汉</code>市的数据提取出来;</p></li><li><p>最后再将全球气温数据提取出来。</p><p> select * from city_list where country=’China’;</p><p> select * from city_data where city=’Wuhan’;</p><p> select * from global_data;</p></li></ol><h4 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h4><p>或者通过以下SQL命令，一次性将两个数据都提取到一个表格：</p><pre><code>select c.year, c.avg_temp as city_temp, g.avg_temp as global_tempfrom city_data c, global_data gwhere c.year = g.yearand c.city = &apos;Wuhan&apos;;</code></pre><h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><p>使用Python将提取的数据（<strong>这里的数据是采用方法一提取的</strong>）可视化成一个线条图，便于武汉市和全球气温比较。</p><h4 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h4><ol><li>绘制图使用<code>matplotlib.pyplot</code>模块；移动平均值计算需使用<code>pandas</code>库；设置坐标轴的ticks需用到<code>matplotlib.ticker</code>模块；matplotlib绘图可视化的各属性设置可参考<a href="http://python.jobbole.com/85106/" target="_blank" rel="noopener">这里</a></li></ol><ol start="2"><li><p>为了使绘制的线图更加平滑，便于观察气温走向，所以采用气温的移动平均值，而不是原始的年平均值。因而需要先计算移动平均值—–&gt;函数<code>calculate_moving_average()</code></p><p> 1）移动平均值的计算方法这里采用<a href="http://pandas.pydata.org/pandas-docs/version/0.17.1/generated/pandas.rolling_mean.html" target="_blank" rel="noopener">pandas.rolling_mean</a>函数。但是，按照文档说明传入参数后，会报出<code>AttributeError: module &#39;pandas&#39; has no attribute &#39;rolling_mean&#39;</code>错误，后来发现是<code>pandas</code>库的版本问题，具体解决方案可参考<a href="https://stackoverflow.com/questions/50482884/module-pandas-has-no-attribute-rolling-mean" target="_blank" rel="noopener">这里</a>。</p><p> 2）移动平均值窗口大小的设定需要权衡考虑。设置得过小，起不到平滑的作用，波动仍然会很剧烈；设置得过大，数据越平滑，但是准确性和敏感性就降低的越多。所以需要在数据变化准确性和平滑程度之间进行一个权衡，既想要观察到更多局部的波动，又想要观察长远趋势，10年左右是比较好的选择。</p></li></ol><ol start="3"><li><p>有了移动均值后，就可以开始绘制图形了—–&gt;函数<code>show_fig()</code></p><p> 1）绘制图形时需要考虑所在城市的数据范围是否与全球气温数据的范围一致。武汉市的数据是从1841年到2013年，而全球气温数据是从1750年到2015年，所以要将城市数据和全球数据处理成在相同时间段内，才能正确比较趋势。</p><p> <em>注：只有当采用方法一获取数据时才需考虑第一点</em></p><p> 2）需要考虑如何设置图形坐标轴的刻度尺大小，使得图形大小更为合适，便于查看和比较本地城市和全球的气温。</p></li></ol><pre><code><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""分析所在城市和全球的气温趋势</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> MultipleLocator, FormatStrFormatter</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_moving_average</span><span class="params">(row_data,window)</span>:</span></span><br><span class="line">    <span class="string">"""计算移动平均值</span></span><br><span class="line"><span class="string">       参数1：需要计算移动平均值的csv文件</span></span><br><span class="line"><span class="string">       参数2：移动窗口大小</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = pd.read_csv(row_data)</span><br><span class="line">    data[<span class="string">'mavg_temp'</span>] = round(data[<span class="string">'avg_temp'</span>].rolling(window).mean(),<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_fig</span><span class="params">(city_data,global_data)</span>:</span></span><br><span class="line">    <span class="string">"""将所在城市与全球平均气温数据绘制成折线图并展示</span></span><br><span class="line"><span class="string">       参数1：城市平均气温数据</span></span><br><span class="line"><span class="string">       参数2：全球平均气温数据</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">#设置显示的图片大小</span></span><br><span class="line">    figsize = <span class="number">10</span>,<span class="number">5</span> </span><br><span class="line">    figure, ax = plt.subplots(figsize=figsize) </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#X,Y轴的标签</span></span><br><span class="line">    plt.xlabel(<span class="string">'Year'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Moving Average Temperature (ºC)'</span>)</span><br><span class="line"></span><br><span class="line">    xmajorLocator   = MultipleLocator(<span class="number">20</span>) <span class="comment">#将x轴主刻度标签设置为20的倍数</span></span><br><span class="line">    xminorLocator   = MultipleLocator(<span class="number">5</span>) <span class="comment">#将x轴次刻度标签设置为5的倍数</span></span><br><span class="line">    ax.xaxis.set_major_locator(xmajorLocator)</span><br><span class="line">    ax.xaxis.set_minor_locator(xminorLocator)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    ymajorLocator   = MultipleLocator(<span class="number">1</span>) <span class="comment">#将y轴主刻度标签设置为1的倍数</span></span><br><span class="line">    yminorLocator   = MultipleLocator(<span class="number">0.2</span>) <span class="comment">#将y轴次刻度标签设置为0.2的倍数</span></span><br><span class="line">    ax.yaxis.set_major_locator(ymajorLocator)</span><br><span class="line">    ax.yaxis.set_minor_locator(yminorLocator)</span><br><span class="line">    </span><br><span class="line">    ax.xaxis.grid(<span class="keyword">True</span>, which=<span class="string">'major'</span>) <span class="comment">#x坐标轴的网格使用主刻度</span></span><br><span class="line">    ax.yaxis.grid(<span class="keyword">True</span>, which=<span class="string">'minor'</span>) <span class="comment">#y坐标轴的网格使用次刻度</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    plt.plot(city_data[<span class="string">'year'</span>],city_data[<span class="string">'mavg_temp'</span>],color=<span class="string">'skyblue'</span>,linewidth=<span class="string">'2'</span>,label=<span class="string">'Wuhan'</span>)</span><br><span class="line">    plt.plot(global_data[<span class="string">'year'</span>],global_data[<span class="string">'mavg_temp'</span>],color=<span class="string">'lightgreen'</span>,linewidth=<span class="string">'2'</span>,label=<span class="string">'Global'</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.title(<span class="string">'Temperature Trend'</span>)</span><br><span class="line"></span><br><span class="line">    plt.show() </span><br><span class="line"></span><br><span class="line">city_data_file = <span class="string">'data/avg_temp_wuhan_data.csv'</span></span><br><span class="line">global_data_file = <span class="string">'data/avg_temp_global_data.csv'</span></span><br><span class="line">window = <span class="number">10</span></span><br><span class="line">city_data = calculate_moving_average(city_data_file,window)</span><br><span class="line">global_data = calculate_moving_average(global_data_file,window)</span><br><span class="line"><span class="comment"># print(city_data)</span></span><br><span class="line"><span class="comment"># print(global_data)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(city_data[9:])</span></span><br><span class="line">city_data = city_data[<span class="number">9</span>:] <span class="comment">#计算移动均值后，武汉市数据表前9行没有数据，从1850年起-2013年，共164行，有平均气温数据</span></span><br><span class="line"><span class="comment"># print(global_data[100:-2])</span></span><br><span class="line">global_data = global_data[<span class="number">100</span>:<span class="number">-2</span>] <span class="comment">#故为了正确比较，全球平均气温数据也只取第100行(1850年)到倒数第二行(2013年)之间的164行数据</span></span><br><span class="line"></span><br><span class="line">show_fig(city_data,global_data)</span><br></pre></td></tr></table></figure></code></pre><p><img src="http://ipineimg.lijundong.com/18-11-26/34848843.jpg" alt="trend"></p><h3 id="问题与观察结论"><a href="#问题与观察结论" class="headerlink" title="问题与观察结论"></a>问题与观察结论</h3><h4 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h4><p>全球气温的整体趋势是怎么样的？本地城市呢？</p><p>从上图中可以看到整体上，从1841年起到2015年之间的70多年间，全球和武汉市的平均气温都是呈上升趋势。世界是真的越来越热了，经过这70多年，全球平均气温上升了1.6度左右，而武汉市上升了1.8度左右。武汉市比全球气温上涨幅度略大。</p><h4 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h4><p>与全球平均气温相比，本地城市平均气温比较热还是比较冷？长期气温差异是否一致？</p><p>可以很明显的看到，武汉市比全球更热，其平均气温比全球平均气温高出8度左右。不愧是中国的“四大火炉城市”之一呀！1841年的时候，武汉的平均气温是16.2度，比全球平均气温8度，高出8.2度，到了近几年，武汉市的平均气温升到18度，达到最高峰值，比全球平均气温最高峰值9.6度，高出8.4度。这说明，长期来看，武汉市和全球的气温差异是一致的。</p><h4 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h4><p>在这几十年间，全球的气温波动如何？本地城市呢？</p><p>全球的气温几乎是呈平稳上升趋势，但是到了最近几年，尤其是1980年之后，气温增长得越来越快，图形呈负偏斜分布；而武汉市的气温虽然整体上是上升的趋势，但是趋势波动很大，某个时间段内气温下降，之后再上升，图形呈多峰分布。</p><h4 id="Q4"><a href="#Q4" class="headerlink" title="Q4"></a>Q4</h4><p>哪个时间段内，武汉市与全球气温趋势的趋势最为相似？</p><p>通过图可以观察到1860年-1885年这25年间，武汉市与全球气温趋势最为相近。在这25年，武汉和全球气温都两次达到气温最低峰值。第一次出现在1862年左右，第二次出现在1885年，武汉市大概为15.8度，全球气温大概为7.8度。不知道在这个两个时间点发生了什么，温度出现了下降现象，但在1885年之后，无论是武汉还是全球，尽管气温有波动，但都没有再降到最低峰值。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/iPine/data_analysis_project_1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;代码传送门，包括扩展了交互功能的改进版&lt;/a&gt;&lt;/p&gt;
&lt;/bloc
      
    
    </summary>
    
      <category term="project" scheme="http://ipine.github.io/categories/project/"/>
    
    
      <category term="python" scheme="http://ipine.github.io/tags/python/"/>
    
      <category term="data_analysis" scheme="http://ipine.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>散列表</title>
    <link href="http://ipine.github.io/2018-11-18/"/>
    <id>http://ipine.github.io/2018-11-18/</id>
    <published>2018-11-18T12:34:12.429Z</published>
    <updated>2019-02-22T11:27:59.834Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>Word有个拼写检查功能，一旦输入的英文单词有错，它就会在单词下方画上红色的波浪线。这个功能是如何实现的？</p><h3 id="散列表"><a href="#散列表" class="headerlink" title="散列表"></a>散列表</h3><p>散列表叫<code>Hash Table</code>，即<code>哈希表</code>或者<code>Hash</code>表。散列表用的是<strong>数组支持按照下标随机访问数据的特性</strong>，所以散列表其实是数组的一种扩展，由数组演化而来。如果没有数组，就没有散列表。</p><h4 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h4><p>假如有89名选手参加学校运动会，为了方便记录成绩，每个选手胸前都会贴上自己的参赛号码。这89名选手的编号依次是1到89。现在需要编程实现，通过编号快速找到对应选手信息。</p><p><strong>做法</strong>：将这89名选手的信息放在数组里，编号为1的选手，放在数组中下标为1的位置；编号为2的选手，放在数组中下标为2的位置。以此推类，编号为 <code>k</code> 的选手，放在数组中下标为 <code>k</code> 的位置。<br>当需要查询参赛编号为 <code>x</code> 的选手时，只需将下标为 <code>x</code> 的数组元素取出来就可以了，时间复杂为 <code>O(1)</code>。</p><p>这就是散列思想，其中，参赛选手的编号叫作<code>键（key）</code>或者<code>关键字</code>。把<strong>参赛编号转化为数组下标</strong>的映射方法就叫作<code>散列函数（哈希函数）</code>，散列函数计算得到的值就叫作<code>散列值（哈希值）</code>。</p><p>散列表用的是<strong>数组支持按照下标随机访问</strong>，时间复杂度是 <code>O(1)</code> 的特性。<br>通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。<br>当按照键值查询元素时，用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。</p><h3 id="散列函数"><a href="#散列函数" class="headerlink" title="散列函数"></a>散列函数</h3><p>散列函数在散列表中起着非常关键的作用。将其定义成 <code>hash(key)</code>，其中 <code>key</code> 表示元素的键值，<code>hash(key)</code>的值表示经过散列函数计算得到的散列值。<br>上个例子中，编号就是数组下标，所以<code>hash(key)</code>就等于<code>key</code>。</p><h4 id="散列函数设计的基本要求"><a href="#散列函数设计的基本要求" class="headerlink" title="散列函数设计的基本要求"></a>散列函数设计的基本要求</h4><p>1 . 散列函数计算得到的散列值是一个非负整数；<br>因为数组下标是从 0 开始的，所以散列函数生成的散列值也要是非负整数。</p><p>2 . 如果 <code>key1 = key2</code> ，那 <code>hash(key1) == hash(key2)</code>；<br>相同的 <code>key</code>，经过散列函数得到的散列值也应该是相同的。</p><p>3 . 如果 <code>key1 ≠ key2</code>，那 <code>hash(key1) ≠ hash(key2)</code>。<br>这个要求看起来合情合理，但是在真实的情况下，要想找到一个不同的 <code>key</code> 对应的散列值都不一样的散列函数，几乎是不可能的。即便像业界著名的<strong>MD5</strong>、<strong>SHA</strong>、<strong>CRC</strong>等哈希算法，也无法完全避免这种散列冲突。而且，因为<strong>数组的存储空间有限</strong>，也会加大散列冲突的概率。</p><p>几乎无法找到一个完美的无冲突的散列函数，即便能找到，付出的时间成本、计算成本也是很大的，所以针对散列冲突问题，需要通过其他途径来解决。</p><h3 id="散列冲突"><a href="#散列冲突" class="headerlink" title="散列冲突"></a>散列冲突</h3><p>常用的散列冲突解决方法有两类，<strong>开放寻址法（open addressing）</strong>和<strong>链表法（chaining）</strong>。</p><h4 id="开放寻址法"><a href="#开放寻址法" class="headerlink" title="开放寻址法"></a>开放寻址法</h4><p>开放寻址法的核心思想是，如果出现了散列冲突，就重新探测一个空闲位置，将其插入。那如何重新探测新的位置呢？<br>一个比较简单的探测方法，<code>线性探测（Linear Probing）</code>。</p><p>1 . 插入数据<br>当往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，那就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。</p><p>例如下图所示：<br><img src="http://ipineimg.lijundong.com/18-11-18/16695191.jpg" alt="插入数据"></p><p>黄色的块表示空闲，橙色的块表示已被存储数据。从图中可以看出，散列表的大小为 10，在元素 <code>x</code> 插入散列表之前，已经 6 个元素插入到散列表中。 <code>x</code> 经过 <code>Hash</code> 算法之后，被散列到位置下标为 7 的位置，但是这个位置已经有数据了，所以就产生了冲突。于是就顺序地往后一个一个找，看有没有空闲的位置，遍历到尾部都没有找到空闲的位置，只好再从表头开始找，直到找到空闲位置 2，于是将其插入到这个位置。</p><p>2 . 查找数据<br>在散列表中查找元素的过程有点儿类似插入过程。通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是要找的元素；否则就顺序往后依次查找。如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。</p><p>如下图所示：<br><img src="http://ipineimg.lijundong.com/18-11-18/23664537.jpg" alt="查找数据"></p><p>3 . 删除数据<br>对于使用线性探测法解决冲突的散列表，删除操作稍微有些特别，不能单纯地把要删除的元素设置为空。</p><p>在查找的时候，一旦通过线性探测方法，找到一个空闲位置，就可以认定散列表中不存在这个数据。<br>但是，如果这个空闲位置是后来删除的，就会导致原来的查找算法失效。本来存在的数据，会被认定为不存在。这个问题如何解决呢？</p><p>如下图所示：<br><img src="http://ipineimg.lijundong.com/18-11-18/89685434.jpg" alt="删除数据"></p><p>解决办法：<br>可以将删除的元素，特殊标记为 <code>deleted</code>。当线性探测查找的时候，遇到标记为 <code>deleted</code> 的空间，并不是停下来，而是继续往下探测。</p><h5 id="线性探测法的问题"><a href="#线性探测法的问题" class="headerlink" title="线性探测法的问题"></a>线性探测法的问题</h5><p>当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久。极端情况下，可能需要探测整个散列表，所以最坏情况下的时间复杂度为 <code>O(n)</code>。同理，在删除和查找时，也有可能会线性探测整张散列表，才能找到要查找或者删除的数据。</p><p>对于开放寻址冲突解决方法，除了线性探测方法之外，还有另外两种比较经典的探测方法，<strong>二次探测（Quadratic probing）</strong>和<strong>双重散列（Double hashing）</strong>。</p><p>二次探测，跟线性探测很像，线性探测每次探测的步长是 1，那它探测的下标序列就是<code>hash(key)+0，hash(key)+1，hash(key)+2</code>……而二次探测探测的步长就变成了原来的“二次方”，也就是说，它探测的下标序列就是 <code>hash(key)+0，hash(key)+1^2，hash(key)+2^2</code>……</p><p>双重散列，意思就是不仅要使用一个散列函数。而是使用一组散列函数 <code>hash1(key)，hash2(key)，hash3(key)</code>……先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。</p><p>为了尽可能保证散列表的操作效率，一般情况下，要尽可能保证散列表中有一定比例的空闲槽位。<br>用<strong>装载因子（load factor）</strong>来表示空位的多少。装载因子的计算公式是：</p><pre><code>散列表的装载因子 = 填入表中的元素个数 / 散列表的长度</code></pre><p>装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。</p><h4 id="链表法"><a href="#链表法" class="headerlink" title="链表法"></a>链表法</h4><p>链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。<br>在散列表中，每个<code>桶（bucket）</code>或者<code>槽（slot）</code>会对应一条链表，所有散列值相同的元素都放到相同槽位对应的链表中。</p><p>如下图所示：<br><img src="http://ipineimg.lijundong.com/18-11-18/86009483.jpg" alt="链表法"></p><p>当插入的时候，只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的时间复杂度是 <code>O(1)</code>。<br>当查找、删除一个元素时，同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除。</p><h5 id="查找或删除操作的时间复杂度"><a href="#查找或删除操作的时间复杂度" class="headerlink" title="查找或删除操作的时间复杂度"></a>查找或删除操作的时间复杂度</h5><p>两个操作的时间复杂度跟链表的长度 <code>k</code> 成正比，也就是 <code>O(k)</code>。<br>对于散列比较均匀的散列函数来说，理论上讲:</p><pre><code>k=n/m，其中 n 表示散列中数据的个数，m 表示散列表中“槽”的个数。</code></pre><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p>Word 文档中单词拼写检查功能是如何实现的？<br>用散列表来存储整个英文单词词典。<br>常用的英文单词有 20 万个左右，假设单词的平均长度是 10 个字母，平均一个单词占用 10 个字节的内存空间，那 20 万英文单词大约占 2MB 的存储空间，就算放大 10 倍也就是 20MB。对于现在的计算机来说，这个大小完全可以放在内存里面。</p><p>当用户输入某个英文单词时，拿用户输入的单词去散列表中查找。如果查到，则说明拼写正确；如果没有查到，则说明拼写可能有误，给予提示。借助散列表这种数据结构，就可以轻松实现快速判断是否存在拼写错误。</p><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>1 . 假设有 10 万条 URL 访问日志，如何按照访问次数给 URL 排序？<br>遍历 10 万条数据，以 URL 为 <code>key</code>，数组的下标为 <code>hash(key)</code>得到的值，访问次数count为相应数组下标的内容，存入散列表，同时记录下访问次数count的最大值 K，时间复杂度 <code>O(N)</code>。<br>如果 K 不是很大，可以使用<strong>桶排序</strong>，时间复杂度 <code>O(N)</code>。如果 K 非常大（比如大于 10 万），就使用<strong>快速排序</strong>，复杂度 <code>O(NlogN)</code>。</p><p>2 . 有两个字符串数组，每个数组大约有 10 万条字符串，如何快速找出两个数组中相同的字符串？<br>以第一个字符串数组构建散列表，<code>key</code> 为字符串，数组的下标为 <code>hash(key)</code>得到的值，出现次数count为相应数组下标的内容，时间复杂度为 <code>O(N)</code>。再遍历第二个字符串数组，以字符串为 <code>key</code> 在散列表中查找，找到散列值对应数组下标存储的count值，如果count大于零，说明存在相同字符串，时间复杂度为 <code>O(N)</code>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h3&gt;&lt;p&gt;Word有个拼写检查功能，一旦输入的英文单词有错，它就会在单词下方画上红色的波浪线。这个功能是如何实现的？&lt;/p&gt;
&lt;h3 id=&quot;散列表&quot;
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>跳表</title>
    <link href="http://ipine.github.io/2018-11-15/"/>
    <id>http://ipine.github.io/2018-11-15/</id>
    <published>2018-11-15T12:21:18.449Z</published>
    <updated>2019-02-22T11:27:57.867Z</updated>
    
    <content type="html"><![CDATA[<p>二分查找底层依赖的是<code>数组随机访问的特性</code>，所有只能用<strong>数组</strong>实现。<br>数据存储在链表中，通过改造链表，也可以支持类似<code>二分</code>的查找算法。这种改造之后的数据结构叫作<strong>跳表</strong>。<br>跳表是一种各方面性能都比较优秀的<code>动态数据结构</code>，可以支持快速的插入、删除、查找操作。</p><blockquote><p>可替代红黑树，代码实现比红黑树简单</p></blockquote><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>为什么 <a href="http://www.runoob.com/redis/redis-intro.html" target="_blank" rel="noopener">Redis</a> 会选择用跳表来实现有序集合？</p><h3 id="如何理解跳表"><a href="#如何理解跳表" class="headerlink" title="如何理解跳表"></a>如何理解跳表</h3><p>对于单链表，即便表中存储的数据是有序的，要在其中查找某个数据，也只能从头到尾遍历链表。查找的时间复杂度也很高，<code>O(n)</code>。</p><p>如何提高这个查找效率呢？<br>就是通过给链表建立<code>索引</code>，每两个结点提取一个结点到上一级，<strong>抽出来那一级叫作索引或索引层</strong>。上一级索引结点的有个 <code>down</code> 指针，指向下一级结点。</p><p>如图所示：<br><img src="http://ipineimg.lijundong.com/18-11-15/98683883.jpg" alt="建立索引"></p><p>加一层索引之后，查找一个结点需要遍历的结点个数减少了，即效率得到提高。不断地往上建立索引，查找效率的提升就会很多。</p><blockquote><p>这种链表加多级索引的结构，就是跳表。</p></blockquote><h3 id="跳表查询的时间复杂度"><a href="#跳表查询的时间复杂度" class="headerlink" title="跳表查询的时间复杂度"></a>跳表查询的时间复杂度</h3><p>按上面所说，<strong>每两个结点抽出一个结点</strong>作为上一级索引的结点，那第一级索引的结点个数大约就是 <code>n/2</code> ，第二级索引的结点个数大约就是 <code>n/4</code> ，第三级索引的结点个数大约就是 <code>n/8</code> ，依次类推，到了第 <code>k</code> 级索引的时候，结点个数是第 <code>k-1</code> 级索引的结点个数的 <code>1/2</code>， 即结点个数为 <code>n/(2^k)</code>。</p><p>假设索引有 <code>m</code> 级，最高级索引有<code>2</code>个结点。通过该公式，可以得到 <code>n/(2^m) = 2</code> ，<code>m=log2^n-1</code> 。如果包含原始链表这一层，整个跳表的高度就是 <code>log2^n</code> 。若每层需要遍历 <code>i</code> 个结点，那么在跳表中查询一个数据的时间复杂度就是 <code>O(i * logn)</code> 。</p><blockquote><p>i 的值在这里为3</p></blockquote><p><strong>原因</strong>：假设要查找的数据是 <code>x</code>，在第 <code>k</code> 级索引中，当遍历到 <code>y</code> 结点之后，发现 <code>x</code> 大于 <code>y</code>，小于后面的结点 <code>z</code>，所以就通过 <code>y</code> 的 <code>down</code> 指针，从第 <code>k</code> 级索引下降到第 <code>k-1</code> 级索引。在第 <code>k-1</code> 级索引中，<code>y</code> 和 <code>z</code> 之间只有 <strong>3 个结点（包含 y 和 z）</strong>，所以，在 <code>K-1</code> 级索引中最多只需要遍历 3 个结点，依次类推，每一级索引都最多只需要遍历 3 个结点。</p><p>如图所示：<br><img src="http://ipineimg.lijundong.com/18-11-15/37428961.jpg" alt="时间复杂度"></p><p>以上，跳表中查询任意数据的时间复杂度为 <code>O(logn)</code>。这个时间复杂度跟二分查找是一样的，但却是以<strong>空间换时间</strong>为代价。</p><h3 id="跳表的空间复杂度分析"><a href="#跳表的空间复杂度分析" class="headerlink" title="跳表的空间复杂度分析"></a>跳表的空间复杂度分析</h3><p>与纯粹的单链表相比，跳表需要存储多级索引，肯定需要消耗更多的存储空间。<br>假设原始链表大小为 <code>n</code>，那第一级索引大约有 <code>n/2</code> 个结点，第二级索引大约有 <code>n/4</code> 个结点，以此类推，每上升一级就减少一半，直到剩下 <code>2</code> 个结点。如果我们把每层索引的结点数写出来，就是一个等比数列。</p><p>原始链表大小为 <code>n</code> ,<strong>每2个结点抽取1个为索引</strong>，每层索引的结点数：</p><pre><code>n/2, n/4, n/8, ..., 8, 4, 2</code></pre><p>这几级索引的结点总和就是 <code>n/2+n/4+n/8…+8+4+2=n-2</code> 。所以，跳表的空间复杂度是 <code>O(n)</code>。也就是说，如果将包含 <code>n</code> 个结点的单链表构造成跳表，需要额外再用接近 <code>n</code> 个结点的存储空间。</p><h4 id="降低索引占用的内存空间"><a href="#降低索引占用的内存空间" class="headerlink" title="降低索引占用的内存空间"></a>降低索引占用的内存空间</h4><p>如果每三个结点，抽一个结点到上级索引，那么第一级索引需要大约 <code>n/3</code> 个结点，第二级索引需要大约 <code>n/9</code> 个结点。每往上一级，索引结点个数都除以 3。为了方便计算，假设最高一级的索引结点个数是 1。每级索引的结点个数相加，也是一个等比数列求和。</p><p>原始链表大小为 <code>n</code> ,<strong>每3个结点抽取1个为索引</strong>，每层索引的结点数：</p><pre><code>n/3, n/9, n/27, ..., 9, 3, 1</code></pre><p>通过等比数列求和公式，总的索引结点大约就是 <code>n/3+n/9+n/27+…+9+3+1=n/2</code> 。尽管空间复杂度还是 <code>O(n)</code>，但比上面的每两个结点抽一个结点的索引构建方法，要减少了一半的索引结点存储空间。</p><blockquote><p>实际上，在软件开发中，不必太在意索引占用的额外空间。<br>在实际的软件开发中，原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值和几个指针，并不需要存储对象，所以当对象比索引结点大很多时，那索引占用的额外空间就可以忽略。</p></blockquote><h3 id="高效的动态插入和删除"><a href="#高效的动态插入和删除" class="headerlink" title="高效的动态插入和删除"></a>高效的动态插入和删除</h3><p>跳表，不仅支持查找操作，还支持动态的插入、删除操作，而且插入、删除操作的时间复杂度也是 <code>O(logn)</code>。</p><h4 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h4><p>在单链表中，一旦定位好要插入的位置，插入结点的时间复杂度是很低的，就是 <code>O(1)</code>。但是，为了保证原始链表中数据的有序性，是需要先找到要插入的位置，这个查找操作就会比较耗时。</p><p>对于纯粹的单链表，需要遍历每个结点，来找到插入的位置。但是，对于跳表来说，查找某个结点的的时间复杂度是 <code>O(logn)</code>，所以查找某个数据应该插入的位置，方法也是类似的，时间复杂度也是 <code>O(logn)</code>。</p><h4 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h4><p>如果要删除的结点在索引中也有出现，那么除了要删除原始链表中的结点，还要删除索引中的。因为单链表中的删除操作需要拿到要删除结点的前驱结点，然后通过指针操作完成删除。所以在查找要删除的结点的时候，一定要获取前驱结点。当然，如果用的是双向链表，就不需要考虑这个问题了。</p><h3 id="跳表索引动态更新"><a href="#跳表索引动态更新" class="headerlink" title="跳表索引动态更新"></a>跳表索引动态更新</h3><p>当数据不断地被插入到跳表中，如果索引不更新，就有可能出现某2个索引结点之间数据非常多的情况，极端情况下，跳表就会退化成单链表。<br>作为一种动态数据结构，需要用某种手段来维护索引与原始链表大小之间的平衡，也就是说，如果链表中结点多了，索引结点就相应地增加一些，避免复杂度退化，以及查找、插入、删除操作性能下降。<br>跳表是通过<strong>随机函数</strong>来维护前面提到的<code>平衡性</code>。<br>当往跳表中插入数据的时候，可以选择同时将这个数据插入到部分索引层中。</p><h4 id="如何选择加入哪些索引层呢？"><a href="#如何选择加入哪些索引层呢？" class="headerlink" title="如何选择加入哪些索引层呢？"></a>如何选择加入哪些索引层呢？</h4><p>通过一个随机函数，来决定将这个结点插入到哪几级索引中，比如随机函数生成了值 <code>K</code> ，那就将这个结点添加到第一级到第 <code>K</code> 级，总共 <code>K</code> 级索引中。</p><blockquote><p>随机函数的选择很有讲究，从概率上来讲，能够保证跳表的索引大小和数据大小平衡性，不至于性能过度退化。</p></blockquote><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p><code>Redis</code> 中的有序集合是通过跳表来实现的，严格点讲，其实还用到了<code>散列表</code>。<br><code>Redis</code> 中的有序集合支持的核心操作主要有下面这几个：</p><ul><li>插入一个数据；</li><li>删除一个数据；</li><li>查找一个数据；</li><li>按照区间查找数据（比如查找值在 [100, 356] 之间的数据）；</li><li>迭代输出有序序列。</li></ul><h4 id="为什么选择跳表而不是红黑树实现有序集合？"><a href="#为什么选择跳表而不是红黑树实现有序集合？" class="headerlink" title="为什么选择跳表而不是红黑树实现有序集合？"></a>为什么选择跳表而不是红黑树实现有序集合？</h4><ul><li><p>原因1：对于插入、删除、查找以及迭代输出有序序列这几个操作，红黑树的完成时间复杂度跟跳表一样；而按照区间来查找数据这个操作，红黑树的效率没有跳表高。<br>对于按照区间查找数据这个操作，跳表可以做到 <code>O(logn)</code> 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了。</p></li><li><p>原因2：跳表代码实现更容易。虽然跳表的实现也不简单，但比起红黑树来说还是相对容易一些。跳表也更加灵活，它可以通过改变索引构建策略，有效平衡执行效率和内存消耗。</p></li></ul><p>不过，跳表也不能完全替代红黑树。因为红黑树比跳表的出现要早一些，很多编程语言中的 <code>Map</code> 类型都是通过红黑树来实现的。业务开发的时候，直接拿来用就可以了，不用自己去实现一个红黑树，但是跳表并没有一个现成的实现，所以在开发中，如果想使用跳表，必须要自己实现。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;二分查找底层依赖的是&lt;code&gt;数组随机访问的特性&lt;/code&gt;，所有只能用&lt;strong&gt;数组&lt;/strong&gt;实现。&lt;br&gt;数据存储在链表中，通过改造链表，也可以支持类似&lt;code&gt;二分&lt;/code&gt;的查找算法。这种改造之后的数据结构叫作&lt;strong&gt;跳表&lt;/stro
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>二分查找</title>
    <link href="http://ipine.github.io/2018-11-09/"/>
    <id>http://ipine.github.io/2018-11-09/</id>
    <published>2018-11-10T10:47:07.235Z</published>
    <updated>2019-02-22T11:27:56.156Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>通过IP地址可用查找到IP归属地。在百度搜索框里，随便输入一个IP地址，就会看到它的归属地。<br>这个功能是通过维护一个很大的IP地址库来实现的，地址库中包括IP地址范围和归属地的对应关系。<br>问题是，如果有12万条这样的IP区间与归属地的对应关系，如何快速定位出一个IP地址的归属地呢？</p><h3 id="二分查找的变形"><a href="#二分查找的变形" class="headerlink" title="二分查找的变形"></a>二分查找的变形</h3><p>二分查找中最简单的一种情况，是在不存在重复元素的有序数组中，查找值等于给定值的元素。最简单的二分查找比较容易，但是，二分查找的变形问题就没那么好写了。</p><blockquote><p>特别说明：假设要处理的数据是从小到大排列为前提，如果要处理的数据是从大到小排列的，解决思路也是一样的。</p></blockquote><h3 id="几个典型的变形问题"><a href="#几个典型的变形问题" class="headerlink" title="几个典型的变形问题"></a>几个典型的变形问题</h3><h4 id="查找第一个值等于给定值的元素"><a href="#查找第一个值等于给定值的元素" class="headerlink" title="查找第一个值等于给定值的元素"></a>查找第一个值等于给定值的元素</h4><p>有序数据集合中存在重复的数据，找到第一个值等于给定值的数据。比如，有以下这样一个有序数组，希望找到第一个等于8的数据位置，即下标为5的8.</p><pre><code>a[10]   1 3 4 5 6 8 8 8 11 19        0 1 2 3 4 5 6 7  8  9</code></pre><p>若用之前的二分查找代码实现，首先拿 8 与区间的中间值 <code>a[4]</code> 比较，8 比 6 大，于是在下标 5 到 9 之间继续查找。下标 5 和 9 的中间位置是下标 7，<code>a[7]</code> 正好等于 8，所以代码就返回了。<br>尽管 <code>a[7]</code> 等于 8，但它并不是要找的第一个等于 8 的元素，因为第一个值等于 8 的元素是数组下标为 5 的元素。</p><h5 id="正确的代码"><a href="#正确的代码" class="headerlink" title="正确的代码"></a>正确的代码</h5><pre><code>def binary_search_variant1(arr,ele):    length = len(arr)    low = 0    high = length - 1    while low &lt;= high:        mid = low + ((high-low)&gt;&gt;1)        if arr[mid] &gt; ele:            high = mid -1        elif arr[mid] &lt; ele:            low = mid + 1        else:            if mid == 0 or arr[mid-1] != ele:                return mid            high = mid-1    return -1</code></pre><h5 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h5><p>重点在于：当 <code>a[mid] = ele</code> 时，该如何处理？如果查找的是任意一个值等于给定值的元素，当 <code>a[mid]</code> 等于要查找的值时，<code>a[mid]</code> 就是要找的元素。但是，求解的是第一个值等于给定值的元素，当 <code>a[mid]</code> 等于要查找的值时，还需要确认一下这个 <code>a[mid]</code> 是不是第一个值等于给定值的元素。<br>如果 <code>mid</code> 等于 0，那这个元素已经是数组的第一个元素，那它肯定是正确的；如果 <code>mid</code> 不等于 0，但 <code>a[mid]</code> 的前一个元素 <code>a[mid-1]</code> 不等于 <code>ele</code>，那也说明 <code>a[mid]</code> 就是要找的第一个值等于给定值的元素。<br>如果经过检查之后发现 <code>a[mid]</code> 前面的一个元素 <code>a[mid-1]</code> 也等于 <code>ele</code>，那说明此时的 <code>a[mid]</code> 肯定不是要查找的第一个值等于给定值的元素。那就更新 <code>high=mid-1</code>，因为要找的元素肯定出现在 <code>[low, mid-1]</code> 之间。</p><h4 id="查找最后一个值等于给定值的元素"><a href="#查找最后一个值等于给定值的元素" class="headerlink" title="查找最后一个值等于给定值的元素"></a>查找最后一个值等于给定值的元素</h4><p>理解上一个变体的做法，对于查找最后一个值等于给定值的元素，就很好做了。</p><h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><pre><code>def binary_search_variant2(arr,ele):    length = len(arr)    low = 0    high = length - 1    while low &lt;= high:        mid = low + ((high-low)&gt;&gt;1)        if arr[mid] &gt; ele:            high = mid -1        elif arr[mid] &lt; ele:            low = mid + 1        else:            if mid == (length-1) or arr[mid+1] != ele:                return mid            low = mid+1    return -1</code></pre><h5 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h5><p>如果 <code>a[mid]</code> 这个元素已经是数组中的最后一个元素了，那它肯定是正确的；如果 <code>[mid]</code> 的后一个元素 <code>a[mid+1]</code> 不等于 <code>ele</code>，那也说明 <code>a[mid]</code> 就是要找的最后一个值等于给定值的元素。</p><p>如果经过检查之后，发现 <code>a[mid]</code> 后面的一个元素 <code>a[mid+1]</code> 也等于 <code>ele</code>，那说明当前的这个 <code>a[mid]</code> 并不是最后一个值等于给定值的元素。那就更新 <code>low=mid+1</code>，因为要找的元素肯定出现在 <code>[mid+1, high]</code> 之间。</p><h4 id="找第一个大于等于给定值的元素"><a href="#找第一个大于等于给定值的元素" class="headerlink" title="找第一个大于等于给定值的元素"></a>找第一个大于等于给定值的元素</h4><p>第三类变形问题。在有序数组中，查找第一个大于等于给定值的元素。<br>比如，数组中存储的这样一个序列：<code>3，4，6，7，10</code>。如果查找第一个大于等于 5 的元素，那就是 6。</p><h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><pre><code>def binary_search_variant3(arr,ele):    length = len(arr)    low = 0    high = length - 1    while low &lt;= high:        mid = low + ((high-low)&gt;&gt;1)        if arr[mid] &gt;= ele:            if mid == 0 or arr[mid-1] &lt; ele:                return mid            high = mid - 1        else:            low = mid + 1    return -1</code></pre><h5 id="分析-2"><a href="#分析-2" class="headerlink" title="分析"></a>分析</h5><p>如果 <code>a[mid]</code> 小于要查找的值 <code>ele</code>，那要查找的值肯定在 <code>[mid+1, high]</code> 之间，所以，更新 <code>low=mid+1</code>。<br>对于 <code>a[mid]</code> 大于等于给定值 <code>ele</code> 的情况，要确认这个 <code>a[mid]</code> 是不是要找的第一个值大于等于给定值的元素。如果 <code>a[mid]</code> 前面已经没有元素，或者前面一个元素小于要查找的值 <code>ele</code>，那 <code>a[mid]</code> 就是要找的元素。<br>如果 <code>a[mid-1]</code> 也大于等于要查找的值 <code>ele</code>，那说明要查找的元素在 <code>[low, mid-1]</code> 之间，所以，将 <code>high</code> 更新为 <code>mid-1</code>。</p><h4 id="查找最后一个小于等于给定值的元素"><a href="#查找最后一个小于等于给定值的元素" class="headerlink" title="查找最后一个小于等于给定值的元素"></a>查找最后一个小于等于给定值的元素</h4><p>查找最后一个小于等于给定值的元素。<br>比如，数组中存储了这样一组数据：<code>3，5，6，8，9，10</code>。最后一个小于等于 7 的元素就是 6。</p><h5 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h5><pre><code>def binary_search_variant4(arr,ele):    length = len(arr)    low = 0    high = length - 1    while low &lt;= high:        mid = low + ((high-low)&gt;&gt;1)        if arr[mid] &lt;= ele:            if mid == (length-1) or arr[mid+1] &gt; ele:                return mid            low = mid + 1        else:            high = mid - 1    return -1</code></pre><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p>如何快速定位出一个 IP 地址的归属地？</p><p>如果 IP 区间与归属地的对应关系不经常更新，就可以先预处理这 12 万条数据，让其按照起始 IP 从小到大排序。<br>IP 地址可以转化为 32 位的整型数。所以，可以将起始地址，按照对应的整型值的大小关系，从小到大进行排序。<br>然后，这个问题就可以<strong>转化为第四种变形问题</strong>“在有序数组中，查找最后一个小于等于某个给定值的元素”了。</p><p>当要查询某个 IP 归属地时，可以先通过二分查找，找到最后一个起始 IP 小于等于这个 IP 的 IP 区间，然后，检查这个 IP 是否在这个 IP 区间内，如果在，就取出对应的归属地显示；如果不在，就返回未查找到。</p><h3 id="Key"><a href="#Key" class="headerlink" title="Key"></a>Key</h3><p>凡是用二分查找能解决的问题，绝大部分更倾向于用<code>散列表</code>或者<code>二叉查找树</code>。即便是二分查找在内存使用上更节省，但是毕竟内存如此紧缺的情况并不多。</p><p>实际上，求“值等于给定值”的二分查找确实不怎么会被用到，二分查找<strong>更适合用在“近似”查找问题</strong>，在这类问题上，二分查找的优势更加明显。比如上面的几种变体问题，用其他数据结构，比如散列表、二叉树，就比较难实现了。<br>变体的二分查找算法写的时候容易因为细节处理不好而产生 Bug，这些容易出错的细节有：<strong>终止条件</strong>、<strong>区间上下界更新方法</strong>、<strong>返回值选择</strong>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h3&gt;&lt;p&gt;通过IP地址可用查找到IP归属地。在百度搜索框里，随便输入一个IP地址，就会看到它的归属地。&lt;br&gt;这个功能是通过维护一个很大的IP地址库来
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>二分查找</title>
    <link href="http://ipine.github.io/2018-11-08/"/>
    <id>http://ipine.github.io/2018-11-08/</id>
    <published>2018-11-08T07:00:00.000Z</published>
    <updated>2019-02-22T11:27:54.297Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>假设有1000万个整数数据，每个数据占8字节，<strong>如何设计数据结构和算法，快速判断某个整数是否出现在1000万数据中？（存在多次查找的情况）</strong></p><blockquote><p>前提：该功能不要太占用内存空间，最好不超过100MB</p></blockquote><h3 id="二分查找思想"><a href="#二分查找思想" class="headerlink" title="二分查找思想"></a>二分查找思想</h3><h4 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h4><p>生活中的“猜数字大小”游戏，猜的过程中，玩家每猜一次，庄家告诉你是猜大了还是猜小了，直到猜中为止。最快速猜中的方法就是用二分查找的思想。每次说猜测范围的中间数字，如果中间数有两个，则选择较小的那个。按照这个思想，这样即使猜的数字范围在0-999，最多也只要10次就能猜中。</p><p>二分查找针对的是一个<code>有序的整数集合</code>，查找思想类似于分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为0。</p><h3 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h3><p>二分查找是一种非常高效的查找算法。<br>假设数据大小是 <code>n</code>，每次查找后数据都会缩小为原来的一半，也就是会除以 2。最坏情况下，直到查找区间被缩小为空，才停止。</p><pre><code>被查找区间的大小变化：n, n/2, 2/4, n/8, ... n/2^k</code></pre><p>这是一个等比数列，其中 <code>n/2^k=1</code> 时， <code>k</code> 的值就是总共缩小的次数，每次缩小操作只涉及两个数据的大小比较，所以，经过 <code>k</code> 次区间缩小操作，时间复杂度为 <code>O(k)</code>。通过 <code>n/2^k=1</code>， 可以求得 <code>k = log2^n</code> ，所以时间复杂度就是 <code>O(logn)</code>。</p><h3 id="O-logn-对数时间复杂度"><a href="#O-logn-对数时间复杂度" class="headerlink" title="O(logn) 对数时间复杂度"></a><code>O(logn)</code> 对数时间复杂度</h3><p>这是一种极其高效的时间复杂度，有的时候甚至比时间复杂度是常量级 <code>O(1)</code> 的算法还要高效。<br>为什么这么说呢？<br>因为 <code>logn</code> 是一个非常“恐怖”的数量级，即便 <code>n</code> 非常非常大，对应的 <code>logn</code> 也很小。比如 <code>n</code> 等于 2 的 32 次方，<code>n</code> 大约是 42 亿。也就是说，如果我们在 <strong>42 亿</strong>个数据中用二分查找一个数据，最多需要比较 <strong>32</strong> 次。</p><blockquote><p>在用大 O 标记法表示时间复杂度的时候，会省略掉常数、系数和低阶。</p></blockquote><p>对于常量级时间复杂度的算法来说，<code>O(1)</code> 有可能表示的是一个非常大的常量值，比如 <code>O(1000)</code>、<code>O(10000)</code>。所以，常量级时间复杂度的算法有时候可能还没有 <code>O(logn)</code> 的算法执行效率高。<br>反过来，对数相对的就是指数。这也是为什么，指数时间复杂度的算法在大规模数据面前是无效的。</p><h3 id="简单二分查找的递归与非递归实现"><a href="#简单二分查找的递归与非递归实现" class="headerlink" title="简单二分查找的递归与非递归实现"></a>简单二分查找的递归与非递归实现</h3><p>简单二分查找，是指在<strong>不存在重复元素</strong>的<strong>有序数据</strong>中查找值等于给定值的数据。</p><h4 id="非递归代码"><a href="#非递归代码" class="headerlink" title="非递归代码"></a>非递归代码</h4><pre><code>def binary_search(arr, ele):    lenght = len(arr)    low = 0    high = length -1    while low &lt;= high:        mid = (low + high) // 2  # low + (high-low)&gt;&gt;1        if arr[mid] == ele:            return mid        elif arr[mid] &gt; ele:            high = mid - 1        else:            low = mid + 1    return -1</code></pre><h4 id="提示点"><a href="#提示点" class="headerlink" title="提示点"></a>提示点</h4><p>1 . 循环退出条件。是 <code>low &lt;= high</code>，而不是 <code>low &lt; high</code></p><p>2 . <code>mid</code> 的取值。实际上，<code>mid=(low+high)//2</code> 这种写法有问题。因为如果 <code>low</code> 和 <code>high</code> 比较大的话，两者之和就有可能会溢出。改进的方法是将 <code>mid</code> 的计算方式写成 <code>low+(high-low)//2</code>。更进一步，可以将这里的除以 2 操作转化成位运算 <code>low+(high-low) &gt;&gt;1</code>。因为相比除法运算来说，计算机处理位运算要快得多。</p><p>3 . <code>low</code> 和 <code>high</code> 的更新。 <code>low=mid+1</code>，<code>high=mid-1</code>。注意这里的 +1 和 -1，如果直接写成 <code>low=mid</code> 或者 <code>high=mid</code>，就可能会发生<strong>死循环</strong>。</p><blockquote><p>比如，当 high=3，low=3 时，如果 arr[3] 不等于 ele，就会导致一直循环不退出。</p></blockquote><h4 id="递归代码"><a href="#递归代码" class="headerlink" title="递归代码"></a>递归代码</h4><pre><code>def binary_search(arr, low, high, ele):    if low &gt; high:        return -1    mid = low + (high-low) // 2    if arr[mid] == ele:        return mid    elif arr[mid] &gt; ele:        return binary_search(arr, low, mid-1, ele)    else:        return binary_search(arr, mid+1, high, ele)</code></pre><h3 id="应用场景的局限性"><a href="#应用场景的局限性" class="headerlink" title="应用场景的局限性"></a>应用场景的局限性</h3><p>二分查找的时间复杂度是 <code>O(logn)</code>，查找数据的效率非常高。不过，并不是什么情况下都可以用二分查找，它的应用场景有很大局限性。</p><p>1 . 二分查找依赖的是<strong>顺序表结构</strong>，即<strong>数组</strong>。 二分查找不能依赖于其他数据结构，比如链表。主要原因是二分查找算法需要按照下标随机访问元素。数组按照下标随机访问数据的时间复杂度是 <code>O(1)</code>，而链表随机访问的时间复杂度是 <code>O(n)</code>。所以，如果数据使用链表存储，二分查找的时间复杂就会变得很高。</p><p>2 . 二分查找针对的是<strong>有序数据</strong>。如果数据没有序，需要先排序。排序的时间复杂度最低是 <code>O(nlogn)</code>。所以，如果针对的是一组静态的数据，没有频繁地插入、删除，就可以进行一次排序，多次二分查找。这样排序的成本可被均摊，二分查找的边际成本就会比较低。<br>针对有频繁插入、删除操作的这种动态数据集合，二分查找是不适用的。要用二分查找，要么每次插入、删除操作之后保证数据仍然有序，要么在每次二分查找之前都先进行排序。针对这种动态数据集合，无论哪种方法，维护有序的成本都很高。</p><p>3 . <strong>数据量太小</strong>不适合二分查找。如果要处理的数据量很小，完全没有必要用二分查找，顺序遍历就足够了。比如在一个大小为 10 的数组中查找一个元素，不管用二分查找还是顺序遍历，查找速度都差不多。只有数据量比较大的时候，二分查找的优势才会比较明显。</p><blockquote><p>有一个例外。如果数据之间的比较操作非常耗时，不管数据量大小，都推荐使用二分查找。比如，数组中存储的都是长度超过几百的字符串，如此长的两个字符串之间比大小，就会非常耗时。为了尽可能地减少比较次数，二分查找就比顺序遍历更有优势。</p></blockquote><p>4 . <strong>数据量太大</strong>也不适合二分查找。二分查找依赖的是数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间连续，对内存的要求比较苛刻。二分查找是作用在数组这种数据结构之上的，所以太大的数据用数组存储就比较困难，就不能用二分查找了。</p><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p>如何快速判断某个整数是否出现在在<code>1000万</code>数据中？<br>内存限制是 <code>100MB</code>，每个数据大小是 <code>8</code> 字节，最简单的办法就是将数据存储在数组中，内存占用差不多是 <code>80MB</code> ，符合内存的限制。<br>先对这 1000 万数据从小到大排序，然后再利用二分查找算法，就可以快速地查找想要的数据。</p><blockquote><p>散列表、二叉树这些支持快速查找的动态数据结构也可以解决这类问题。但因为内存的限制，使得这些方法在这里行不通。</p></blockquote><p>虽然大部分情况下，用二分查找可以解决的问题，用散列表、二叉树都可以解决。但是，不管是散列表还是二叉树，都会需要比较多的额外的内存空间。如果用散列表或者二叉树来存储这 <code>1000万</code> 的数据，用 <code>100MB</code> 的内存肯定是存不下的。而二分查找底层依赖的是数组，除了数据本身之外，不需要额外存储其他信息，是最省内存空间的存储方式，所以刚好能在限定的内存大小下解决这个问题。</p><h3 id="Key"><a href="#Key" class="headerlink" title="Key"></a>Key</h3><p>1 . 若二分查找依赖于链表结构，时间复杂度如何分析？<br>假设链表长度为 n，二分查找每次需要找到中间点，那么总共需要移动的指针次数为：</p><pre><code>n/2 + n/4 + n/8 + ... + 1</code></pre><p>这也是一个等比数列，根据等比数列求和公式 <code>(S = (a1-an*q)/1-q, q为公比, 且不为1)</code>，其和等于 <code>n-1</code> 。所有最后算法时间复杂度为 <code>O(n)</code>。<br>时间复杂度和顺序查找时间复杂度相同，但是，在二分查找的时候，由于要进行多余的运算，严格来说，会比顺序查找时间慢。</p><p>2 . 用二分查找“求一个数的平方根”，要求精确到小数点后6位（类似于LeetCode 69题）</p><pre><code>def mySqrt(self, x):        if x==0 or x==1:            return x        low = 0        high = max(x,1.0)        #high = x        mid = (low + high)/2.0        while abs(mid**2 - x) &gt; 1e-6:            if mid**2 &gt; x:                high = mid            else:                low = mid            mid = (low + high)/2.0        return mid</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h3&gt;&lt;p&gt;假设有1000万个整数数据，每个数据占8字节，&lt;strong&gt;如何设计数据结构和算法，快速判断某个整数是否出现在1000万数据中？（存在多次
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>排序</title>
    <link href="http://ipine.github.io/2018-11-04/"/>
    <id>http://ipine.github.io/2018-11-04/</id>
    <published>2018-11-04T12:56:00.000Z</published>
    <updated>2019-02-22T11:27:52.854Z</updated>
    
    <content type="html"><![CDATA[<p>主要内容，总结前面的几种算法在各方面的性能。</p><h3 id="如何选择合适的排序算法？"><a href="#如何选择合适的排序算法？" class="headerlink" title="如何选择合适的排序算法？"></a>如何选择合适的排序算法？</h3><p>总结前面几种主要排序算法的性能差异。一些算法在一些指标上达到最优情况，还有一些算法的复杂度虽然相同，但在实践中的表现却有差异。<br>最理想的排序算法是 <strong><code>O(n logn)</code> 时间</strong>、<strong><code>O(1)</code>空间</strong>、<strong>稳定</strong>、最好还<strong>具有适应性</strong>。当然目前，还没找到这种算法。</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">最坏时间复杂度</th><th style="text-align:center">平均时间复杂度</th><th style="text-align:center">最好时间复杂度</th><th style="text-align:center">是否稳定</th><th style="text-align:center">是否是原地排序</th><th style="text-align:center">适应性</th></tr></thead><tbody><tr><td style="text-align:center">冒泡排序</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(n)</td><td style="text-align:center">是</td><td style="text-align:center">是</td><td style="text-align:center">是</td></tr><tr><td style="text-align:center">插入排序</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(n)</td><td style="text-align:center">是</td><td style="text-align:center">是</td><td style="text-align:center">是</td></tr><tr><td style="text-align:center">选择排序</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">否</td><td style="text-align:center">是</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">快速排序</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">否</td><td style="text-align:center">是</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">归并排序</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">是</td><td style="text-align:center">否</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">计数排序</td><td style="text-align:center">O(n+k)</td><td style="text-align:center">O(n+k)</td><td style="text-align:center">O(n+k)</td><td style="text-align:center">是</td><td style="text-align:center">否</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">桶排序</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">O(n)</td><td style="text-align:center">O(n)</td><td style="text-align:center">是</td><td style="text-align:center">否</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">基数排序</td><td style="text-align:center">O(k*n)</td><td style="text-align:center">O(k*n)</td><td style="text-align:center">O(k*n)</td><td style="text-align:center">是</td><td style="text-align:center">否</td><td style="text-align:center">否</td></tr></tbody></table><h3 id="适用情况比较"><a href="#适用情况比较" class="headerlink" title="适用情况比较"></a>适用情况比较</h3><p>1 . 三个线性排序算法的时间复杂度低，但是适用场景特殊，所以通用的排序函数，不选择线性排序算法。<br>2 . 对小规模数据进行排序，可以选择时间复杂度是 <code>O(n2)</code> 的算法，如，<strong>冒泡排序</strong>和<strong>插入排序</strong>；<br>3 . 对大规模数据进行排序，选择时间复杂度是 <code>O(nlogn)</code> 的算法更加高效。</p><p>所以，为了兼顾任意规模数据的排序，一般都会首选时间复杂度是 <code>O(nlogn)</code> 的排序算法来实现排序函数。<br>时间复杂度为<code>O(nlogn)</code>的排序算法，目前有两个，快速排序和归并排序</p><h3 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h3><p>快速排序适合来实现通用的排序函数，但是，快速排序在最坏情况下的时间复杂度是 <code>O(n^2)</code>。</p><h4 id="为什么最坏情况下快排的时间复杂度是-O-n-2-呢？"><a href="#为什么最坏情况下快排的时间复杂度是-O-n-2-呢？" class="headerlink" title="为什么最坏情况下快排的时间复杂度是 O(n^2)呢？"></a>为什么最坏情况下快排的时间复杂度是 <code>O(n^2)</code>呢？</h4><p>如果要排序的数据原来就是有序的或者接近有序的，而每次分区点都选择最后一个数据，那快排的性能就很不好，这时时间复杂度就为 <code>O(n^2)</code>。所以，这种 <code>O(n^2)</code> 时间复杂度出现的主要原因是因为<strong>分区点选择不够合理</strong>。</p><p><strong>最理想的分区点是</strong>：被分区点分开的两个分区中，数据的数量差不多。若直接选择第一个或最后一个数据作为分区点，不考虑数据的特点，肯定就会出现最坏情况的时间复杂度。</p><h4 id="几种常用的分区算法"><a href="#几种常用的分区算法" class="headerlink" title="几种常用的分区算法"></a>几种常用的分区算法</h4><p>1 . 三数取中法<br>从区间的首、尾、中间，分别取出一个数，然后对比这三个数的大小，取3数中的中间值作为分区点。每间隔某个固定的长度，取数据出来比较，将中间值作为分区点。这种思路肯定比单纯取某一个数据更好，但是，如果要排序的数组比较大，那“三数取中”可能就不够，需要扩大范围，“五数取中”或者“十数取中”。</p><p>2 . 随机法<br>随机法是每次从要排序的区间中，随机选择一个元素作为分区点。这种方法并不能保证每次分区点都选的比较好，但是从概率的角度来看，也不大可能会出现每次分区点都选的很差的情况，所以平均情况下，这样选的分区点是比较好的。时间复杂度退化为最糟糕的 <code>O(n^2)</code> 的情况，出现的可能性不大。</p><p>快速排序用<code>递归实现</code>。递归需要警惕<code>堆栈溢出</code>。为了避免快速排序里，递归过深而堆栈过小，导致堆栈溢出，有两种解决办法：第一种是<strong>限制递归深度</strong>。一旦递归过深，超过了事先设定的阈值，就停止递归。第二种是通过在<strong>堆上模拟实现一个函数调用栈</strong>，手动模拟递归压栈、出栈的过程，这样就没有了系统栈大小的限制。</p><h3 id="举例分析排序函数"><a href="#举例分析排序函数" class="headerlink" title="举例分析排序函数"></a>举例分析排序函数</h3><p>实际排序程序会采用多种算法的组合，即<code>混成方法</code>。<br>在一些复杂排序算法里，也需要处理较短序列的排序问题。快排和归并排序就是这方面的典型：</p><ul><li><p>快速排序算法中，序列被划分为越来越短的片段。若序列已经很短，例如短于几个元素，快排还需要做几次递归调用（进栈、出栈）。这些赋值操作很耗时，<strong>表现在复杂度度描述中忽略了的常量因子</strong>。对于很短的序列，<strong>采用插入排序，效果很可能优于快速排序</strong>。</p></li><li><p>归并排序正好与快排相反，是从短的有序序列归并出越来越长的序列。从很多个各自包含一个元素的序列出发，通过几遍归并得到最终的有序序列，这其中需要做许多函数调用工作。与这几个元素做简单插入排序相比，归并排序消耗时间会更多。</p></li></ul><p>在实际程序里的排序功能，特别是各自程序库里的排序函数，通常不是纯粹第采用一种算法，而是使用两种或两种以上方法的组合。常见的是<strong>归并排序和插入排序的组合</strong>，以及<strong>快速排序和插入排序的组合</strong>。</p><h4 id="Python的内置排序算法"><a href="#Python的内置排序算法" class="headerlink" title="Python的内置排序算法"></a>Python的内置排序算法</h4><p>Python中的内置<code>排序函数 sort</code> 和<code>表list类的对象的sort方法</code>，两者共享同一个排序算法，是一种混成排序算法，叫作 <strong>Timsort(蒂姆排序)</strong>。</p><h5 id="基本情况"><a href="#基本情况" class="headerlink" title="基本情况"></a>基本情况</h5><p>蒂姆排序是一种<strong>基于归并技术</strong>的<strong>稳定</strong>排序算法，结合使用了归并排序和插入排序技术，最坏时间复杂度是<code>O(nlogn)</code>。它<strong>具有适应性</strong>，在被排序的数组元素接近排好序的情况下，它的时间复杂度可能远小于<code>O(nlogn)</code>，可能达到线性时间。在最坏情况下，它的需要<code>n/2</code>的工作空间，因此其空间复杂度是<code>O(n)</code>。</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">最坏时间复杂度</th><th style="text-align:center">平均时间复杂度</th><th style="text-align:center">最好时间复杂度</th><th style="text-align:center">是否稳定</th><th style="text-align:center">是否是原地排序</th><th style="text-align:center">适应性</th></tr></thead><tbody><tr><td style="text-align:center">蒂姆排序</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">O(n)</td><td style="text-align:center">是</td><td style="text-align:center">否</td><td style="text-align:center">是</td></tr></tbody></table><p>蒂姆排序算法适合许多实际应用中常见的情况，特别是被排序的数据序列分段有序或者基本有序，但仍有些非有序元素的情况。人们通过许多试验，发现蒂姆排序在平均性能上超过快排，是目前实际表现最好的排序算法。虽然理论上，它并没有克服归并排序<code>O(n)</code>空间开销的弱点，但实际开发中经常不需要很大的额外空间，且现在计算机的内存都很大，很多时候追求的都是速度。</p><h5 id="基本工作方式"><a href="#基本工作方式" class="headerlink" title="基本工作方式"></a>基本工作方式</h5><p>蒂姆排序的优势是克服了归并排序没有适应性的缺陷，且又保持了其稳定性的特征。<br>1 . 考察待排序序列中非严格单调上升（后一个值大于等于前一个值）或严格单调下降（后一个值小于前一个值）的片段，反转其中的严格下降片段。<br>2 . 采用插入排序，对连续出现的几个短的上升排序序列，使整个序列变成一系列（非严格）单调上升的记录片段，每个片段都长于某个特定值。<br>3 . 采用归并产生更长的排序片段，控制这一归并过程，保证片段的长度尽可能均匀。归并中采用一些策略，尽可能地减少临时空间的使用。通过反复归并，最终得到排序序列</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>1 . 如果序列中的数据基本有序而且序列长度<code>n</code>比较小，直接插入排序能很快完成排序，即具有适应性。这种情况下，冒泡排序也比较快。<br>2 . 简单排序算法多是稳定的，而大部分时间性能好的排序都不稳定，如快速排序（以及堆排序）等。</p><blockquote><p>稳定性是具体算法实现的性质，采用同一种排序算法，有可能做出稳定的和不稳定的实现。但有些算法的实现可以很自然地做到稳定（如，插入排序，归并排序），另一些则需要附加的时间或空间开销（如，选择排序）</p></blockquote><p>3 . 实际应用中，数据记录通常有一个主关键码，例如各种唯一标识码，如学号、身份证号、用户账户、商品订单号等。这种关键码一般都具有<code>唯一性</code>。如果要做的是按主关键码排序，所用<strong>排序方法是否稳定就无关紧要</strong>。<br>但在另一些应用中，经常需要把记录中的其他成分作为排序码使用，例如，按学生的姓名、籍贯、年龄、成绩等排序。在做这种排序时，应该根据问题所需慎重选择排序方法，<strong>经常需要用稳定算法</strong>。若用了不稳定的排序算法，可能就还需要对具有相同关键码的数据段再次排序。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;主要内容，总结前面的几种算法在各方面的性能。&lt;/p&gt;
&lt;h3 id=&quot;如何选择合适的排序算法？&quot;&gt;&lt;a href=&quot;#如何选择合适的排序算法？&quot; class=&quot;headerlink&quot; title=&quot;如何选择合适的排序算法？&quot;&gt;&lt;/a&gt;如何选择合适的排序算法？&lt;/h3&gt;&lt;p&gt;
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>排序</title>
    <link href="http://ipine.github.io/2018-11-03/"/>
    <id>http://ipine.github.io/2018-11-03/</id>
    <published>2018-11-03T08:13:00.000Z</published>
    <updated>2019-02-22T11:27:51.587Z</updated>
    
    <content type="html"><![CDATA[<p>三种时间复杂度是 <code>O(n)</code> 的排序算法：<code>桶排序</code>、<code>计数排序</code>、<code>计数排序</code>。这些排序算法的时间复杂度是线性的，因而也叫线性排序。之所以能做到线性的复杂度，主要原因这三种算法都是<strong>非基于比较</strong>的排序算法，不涉及元素间的比较操作；但是这几种排序算法对<strong>数据的要求很苛刻</strong>，因而需要重点掌握它们的使用场景。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>如何根据年龄给100万用户排序？（时间复杂度最好要是线性的）</p><h3 id="桶排序（Bucket-sort）"><a href="#桶排序（Bucket-sort）" class="headerlink" title="桶排序（Bucket sort）"></a>桶排序（Bucket sort）</h3><h4 id="核心原理"><a href="#核心原理" class="headerlink" title="核心原理"></a>核心原理</h4><p>桶排序，顾名思义，会用到“桶”，这些“桶”，按区间划分，核心思想是将要排序的数据将其分到所属的桶里去，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就有序了。</p><h4 id="为什么时间复杂度为-O-n-？"><a href="#为什么时间复杂度为-O-n-？" class="headerlink" title="为什么时间复杂度为 O(n)？"></a>为什么时间复杂度为 <code>O(n)</code>？</h4><p>如果要排序的数据有 <code>n</code> 个，将其均匀地划分到  <code>m</code> 个桶内，每个桶里就有 <code>k = n/m</code> 个元素。每个桶内部用快速排序，时间复杂度就为 <code>O(k * logk)</code> 。 <code>m</code> 个桶排序的时间复杂度就是 <code>O(m * k * logk)</code>，又因为 <code>k = n/m</code>，所以整个桶排序的时间复杂度就是 <code>O(n* logn/m)</code>。当桶的个数 <code>m</code> 接近数据个数 <code>n</code> 时，<code>logn/m</code> 就是一个很小的常量，这个时候桶排序的时间复杂度接近 <code>O(n)</code></p><h4 id="对数据的苛刻要求"><a href="#对数据的苛刻要求" class="headerlink" title="对数据的苛刻要求"></a>对数据的苛刻要求</h4><p>1 . 首先，要排序的数据需要很容易就能划分成 <code>m</code> 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。</p><p>2 . 其次，数据在各个桶之间的<strong>分布是比较均匀的</strong>。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 <code>O(nlogn)</code> 的排序算法了。</p><h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><p>桶排序比较适合用在<strong>外部排序</strong>中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。</p><h4 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h4><h5 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h5><p>有 10GB 的订单数据，我们希望按订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百 MB，没办法一次性把 10GB 的数据都加载到内存中。</p><h5 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h5><p>先扫描一遍文件，看订单金额所处的数据范围。假设经过扫描之后得到，订单金额最小是 1 元，最大是 10 万元。将所有订单根据金额划分到 100 个桶里，第一个桶存储金额在 1 元到 1000 元之内的订单，第二桶存储金额在 1001 元到 2000 元之内的订单，以此类推。每一个桶对应一个文件，并且按照金额范围的大小顺序编号命名 (00，01，02…99)。</p><p>理想的情况下，如果订单金额在 1 到 10 万之间<strong>均匀分布</strong>，那订单会被均匀划分到 100 个文件中，每个小文件中存储大约 100MB 的订单数据，就可以将这 100 个小文件依次放到内存中，用快排来排序。等所有文件都排好序之后，只需要按照文件编号，从小到大依次读取每个小文件中的订单数据，并将其写入到一个文件中，那这个文件中存储的就是按照金额从小到大排序的订单数据了。</p><p>不过，订单按照金额在 1 元到 10 万元之间并不一定是均匀分布的 ，所以 10GB 订单数据是无法均匀地被划分到 100 个文件中的。有可能某个金额区间的数据特别多，划分之后对应的文件就会很大，没法一次性读入内存。</p><p>针对这些划分之后还是比较大的文件，可以继续划分，比如，订单金额在 1 元到 1000 元之间的比较多，就将这个区间继续划分为 10 个小区间，1 元到 100 元，101 元到 200 元，201 元到 300 元…901 元到 1000 元。如果划分之后，101 元到 200 元之间的订单还是太多，无法一次性读入内存，那就继续再划分，直到所有的文件都能读入内存为止。</p><h3 id="计数排序（Counting-sort）"><a href="#计数排序（Counting-sort）" class="headerlink" title="计数排序（Counting sort）"></a>计数排序（Counting sort）</h3><p><strong>计数排序其实是桶排序的一种特殊情况</strong>。当要排序的 <code>n</code> 个数据，所处的范围并不大的时候，比如最大值是 <code>k</code>，就可以把数据划分成 <code>k</code> 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。</p><h4 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h4><p>查询高考成绩，系统会显示分数和所在省的排名。如果所在的省分有50万考生，如何通过成绩快速排序得出名次呢？<br>假设考生的满分是 900 分，最小是 0 分，这个数据的范围很小，所以可以分成 901 个桶，对应分数从 0 分到 900 分。根据考生的成绩，将这 50 万考生划分到这 901 个桶里。桶内的数据都是分数相同的考生，所以并不需要再进行排序。最后只需要依次扫描每个桶，将桶内的考生依次输出到一个数组中，就实现了 50 万考生的排序。因为只涉及扫描遍历操作，所以时间复杂度是 <code>O(n)</code>。</p><blockquote><p>这就是计数排序的算法思想，跟桶排序非常类似，只是桶的大小粒度不一样。</p></blockquote><h4 id="为什么叫计数排序"><a href="#为什么叫计数排序" class="headerlink" title="为什么叫计数排序"></a>为什么叫<strong>计数</strong>排序</h4><p>要了解<code>计数</code>的含义，就需要明白计算排序算法的实现方法。</p><h5 id="还是那个栗子"><a href="#还是那个栗子" class="headerlink" title="还是那个栗子"></a>还是那个栗子</h5><p>假设只有 8 个考生了，分数在 0 到 5 分之间。将这 8 个考生的成绩放在一个数组 <code>A[8]</code> 中，它们分别是：<code>2，5，3，0，2，3，0，3</code>分。</p><pre><code>#数组A8数组 [2] [5] [3] [0] [2] [3] [0] [3]下标  0   1   2   3   4   5   6   7</code></pre><p>考生的成绩从 0 到 5 分，使用大小为 6 的数组 <code>C[6]</code> 表示桶，其中<strong>下标对应分数</strong>。 <code>C[6]</code> 中的每个<strong>元素存对应分数的考生个数</strong>。</p><pre><code>#数组C6：数组-出现次数： [2] [0] [2] [3] [0] [1]下标-对应分数：  0   1   2   3   4   5</code></pre><p>现在的问题是，如何快速计算出，每个分数的考生在有序数组 (最后排好序的结果数组) 中对应的存储位置呢？</p><p><strong>巧妙的思路</strong><br>1 . 首先对 <code>C6</code> 数组顺序求和（<code>前面一个位置的值+当前自己本身的值 = 当前的新值</code>），得到新的 <code>C6</code> 数组：</p><pre><code>#新的数组C6：数组-出现次数： [2] [2] [4] [7] [7] [8]下标-对应分数：  0   1   2   3   4   5</code></pre><p>2 . 然后<strong>从后到前</strong>依次扫描数组 <code>A</code>。<br>过程如下：扫描到第一个3时，从数组 <code>C</code> 中取出下标为3的值，即7， 7在这里的含义是，到目前位置，包括当前这个在内，小于等于3分的考生个数是7个，即3是结果数组 <code>R</code> 中的第7个元素（对应于数组下标为6的位置<code>R[6] = 3</code>）。将这个3放进 <code>R</code> 数组后，数组 <code>C</code> 中小于等于3的元素个数减一就变成6个，即 <code>C[3] = 6</code>。以此推类，扫描完整个数组A后，数组 <code>R</code> 内的数据就是按照分数从小到大有序排列。</p><h5 id="过程图："><a href="#过程图：" class="headerlink" title="过程图："></a>过程图：</h5><p><img src="http://ipineimg.lijundong.com/18-11-4/39713280.jpg" alt="计数排序"></p><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><pre><code>from typing import Listimport itertoolsdef counting_sort(a: List[int]):    if len(a) &lt;= 1:return    counts = [0] * (max(a) + 1) #创建桶，初始值为0    for num in a:  #统计数组中每个元素出现的次数        counts[num] += 1    counts = list(itertools.accumulate(counts))  #对counts数组顺序求和，得到新的counts数组    a_sorted = [0] * len(a)  #创建一个临时结果数组，存储排序后的结果    for num in reversed(a):  #从后往前扫描需要被排序的数组        index = counts[num] - 1  #找到num在临时结果数组中位置        a_sorted[index] = num    #将num放到临时结果数组中        counts[num] -= 1         #num对应的个数减1    a = a_sorted  #将临时结果数组赋给原数组</code></pre><h4 id="适用场景-1"><a href="#适用场景-1" class="headerlink" title="适用场景"></a>适用场景</h4><p>计数排序只能用在数据范围不大的场景中，如果数据范围 <code>k</code> 比要排序的数据 <code>n</code> 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。</p><h5 id="栗子说明"><a href="#栗子说明" class="headerlink" title="栗子说明"></a>栗子说明</h5><p>比如，如果考生成绩精确到小数后一位，就需要将所有的分数都先乘以 10，转化成整数，然后再放到 9010 个桶内。再比如，如果要排序的数据中有负数，数据的范围是 [-1000, 1000]，那就需要先对每个数据都加 1000，转化成非负整数。</p><h3 id="基数排序（Radix-sort）"><a href="#基数排序（Radix-sort）" class="headerlink" title="基数排序（Radix sort）"></a>基数排序（Radix sort）</h3><p>首先按照最低有效位进行排序，最低位优先 <code>(Least Significant Digit first)</code> 法，简称 <code>LSD</code> 法：先从kd开始排序，再对kd-1进行排序，依次重复，直到对k1排序后便得到一个有序序列。</p><h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><p>假设有 10 万个手机号码，希望将这 10 万个手机号码从小到大排序，什么排序方法比较快速？</p><p>手机号码有 11 位，范围太大，显然不适合用桶排序和计数排序两种算法，基数排序就很适合。</p><h5 id="处理思路"><a href="#处理思路" class="headerlink" title="处理思路"></a>处理思路</h5><p>先按照最后一位来排序手机号码，然后，再按照倒数第二位重新排序，以此类推，最后按照第一位重新排序。经过 11 次排序之后，手机号码就都有序了。<br>注意，这里按照每位来排序的排序算法要是<strong>稳定</strong>的，否则这个实现思路就是不正确的。因为如果是非稳定排序算法，那最后一次排序只会考虑最高位的大小顺序，完全不管其他位的大小关系，那么低位的排序就完全没有意义了。</p><p>根据每一位来排序，可以用桶排序或者计数排序，它们的时间复杂度可以做到 <code>O(n)</code>。如果要排序的数据有 <code>k</code> 位，那就需要 <code>k</code> 次桶排序或者计数排序，总的时间复杂度是 <code>O(k*n)</code>。当 <code>k</code> 不大的时候，比如手机号码排序，<code>k</code> 最大就是 11，所以基数排序的时间复杂度就近似于 <code>O(n)</code>。</p><blockquote><p>实际上，有时候要排序的数据并不都是等长的。</p></blockquote><h5 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h5><p>可以把所有的数字补齐到相同长度，位数不够的可以在前面补0。而对于不等长的字符串排序，位数不够的可以在后面补<code>&quot;0&quot;</code>，因为根据ASCII 值，所有字母都大于<code>&quot;0&quot;</code>，所以补<code>&quot;0&quot;</code>不会影响到原有的大小顺序。这样就可以继续用基数排序了。</p><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><pre><code>def radix_sort(lt, d): #d表示d轮排序,取决于数组元素的长度    for k in xrange(d):        s = [[] for i in xrange(10)]  #创建10个桶，因为每位数字最大的就是9        #对数组中每个元素，按照最低有效数字进行排序，然后依次到高位        for i in lt:              s[i/(10**k)%10].append(i)        lt = [j for i in s for j in i]    return lt</code></pre><blockquote><p>例如<br>对数组[321,22,890]排序，第一轮对个位排，s[0]=[890],s[1]=[321],s[2]=[22]，第一轮排序结果lt[890,321,22]<br>第二轮对十位排，s[2] =[321,22],s[9]=[890]，第二轮排序结果lt[321,22,890]<br>第三轮百位排，s[0] =[22],s[3]=[321],s[8]=[890]，第三轮排序结果lt[22,321,890]，结束。</p></blockquote><h4 id="适用场景-2"><a href="#适用场景-2" class="headerlink" title="适用场景"></a>适用场景</h4><p>基数排序对要排序的数据是有要求的，需要可以分割出独立的<code>“位”</code>来比较，而且<strong>位之间有递进的关系</strong>，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的<strong>数据范围不能太大</strong>，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 <code>O(n)</code> 了。</p><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p>实际上，根据年龄给 100 万用户排序，就类似按照成绩给 50 万考生排序。<br>假设年龄的范围最小 1 岁，最大不超过 120 岁。<br>遍历这 100 万用户，根据年龄将其划分到120 个桶里，然后依次顺序遍历这 120 个桶中的元素。<br>这样就得到了按照年龄排序的 100 万用户数据。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;三种时间复杂度是 &lt;code&gt;O(n)&lt;/code&gt; 的排序算法：&lt;code&gt;桶排序&lt;/code&gt;、&lt;code&gt;计数排序&lt;/code&gt;、&lt;code&gt;计数排序&lt;/code&gt;。这些排序算法的时间复杂度是线性的，因而也叫线性排序。之所以能做到线性的复杂度，主要原因这三种算法都是&lt;
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>排序</title>
    <link href="http://ipine.github.io/2018-11-02/"/>
    <id>http://ipine.github.io/2018-11-02/</id>
    <published>2018-11-02T08:35:00.000Z</published>
    <updated>2019-02-22T11:27:50.468Z</updated>
    
    <content type="html"><![CDATA[<p>之前说的，冒泡排序、插入排序、选择排序三种算法的时间复杂度都是<code>O(n^2)</code>，很高，适用于小规模数据的排序。<br>而，<code>归并排序</code>和<code>快速排序</code>，适用于大规模的数据排序，更为常用。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>归并排序和快速排序都用到了分治思想，借助这个思想可以解决非排序问题。</p><blockquote><p>如何在O(n)的时间复杂度内查找一个无序数组中的第K大元素？</p></blockquote><h3 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h3><h4 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h4><p>对于要排序的数组，先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起。<br>归并排序用到的就是分治思想，顾名思义，就是分而治之，将大问题分解为小的子问题来解决。</p><blockquote><p>分治思想跟递归很向。分治算法一般都用递归来实现的。分治是一种解决问题的处理思想，递归是一种编程技巧。</p></blockquote><h4 id="如何用递归代码实现归并排序？"><a href="#如何用递归代码实现归并排序？" class="headerlink" title="如何用递归代码实现归并排序？"></a>如何用递归代码实现归并排序？</h4><p>先写出归并排序的递推公式</p><pre><code>递推公式：merge_sort(p...q) = merge(merge_sort(p...r), merge_sort(r+1...q)) #r = (p+q)/2,即数组的中间位置终止条件：p &gt;= q #不用再继续分解的时候</code></pre><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><pre><code>def merge_sort(lt):    if len(lt) &lt;= 1:        return lt    middle = len(lt)/2    left = merge_sort(lt[:middle])    right = merge_sort(lt[middle:])    return merge(left, right)def merge(arr1, arr2):    arr_result = []    while len(arr1)&gt;0 and len(arr2)&gt;0:        if arr1[0] &lt;= arr2[0]:            arr_result.append(arr1.pop(0))        else:            arr_result.append(arr2.pop(0))    #while循环结束，说明有个条件不满足，即有个数组已经没有数据元素了，此时将另一个数组的数据加入到结果数组中    arr_result += arr1    arr_result += arr2    return arr_result</code></pre><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><p>1 . 归并排序是否是稳定排序算法？关键看<code>merge()</code>函数，即两个有序子数组合并成最终结果数组的那部分代码。在合并过程中，如果<code>arr1[p...r]</code>和<code>arr2[r+1...q]</code>之间有相同元素，那么可以先把<code>arr1[p...r]</code>中的元素放入最终结果数组。这样就保证了值相同的元素，在合并前后的先后顺序不变。所以，归并排序是<strong>稳定的</strong>排序算法。<br>2 . 时间复杂度分析。归并排序涉及递归，时间复杂度该如何分析？<br><strong>递归适用场景</strong>：一个问题A可以分解为多个子问题B、C，求解A就就分解为求解B、C。问题B、C解决后，在把这个问题的结果合成A的结果。<br>若定义求解问题A的时间为<code>T(A)</code>，求解问题B、C的时间分别为<code>T(B)</code>和<code>T(C)</code>，则有一个递推关系</p><pre><code>T(A) = T(B) + T(C) + K    其中K为两个子问题B、C的结果合成问题A的结果所花费时间</code></pre><p>套用这个公式来分析归并排序的时间复杂度：<br>假设对 <code>n</code> 个元素进行归并排序需要的时间是 <code>T(n)</code>，那分解成两个子数组排序的时间都是 <code>T(n/2)</code>。<code>merge()</code> 函数合并两个有序子数组的时间复杂度是 <code>O(n)</code>。所以，套用前面的公式，归并排序的时间复杂度的计算公式就是：</p><pre><code>T(1) = C;  n=1 时，只需要常量级的执行时间T(n) = T(n/2) *2 + n;  n&gt;1 </code></pre><p>进一步分解可知道：</p><pre><code>T(n) = 2*T(n/2) + n     = 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n     = 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n     = 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n     ......     = 2^k * T(n/2^k) + k * n     ......即 T(n) = 2^k * T(n/2^k) + k * n, 当 T(n/2^k) = 1 时，k = log2^n则  T(n) = 2^log2^n + log2^n * n = Cn + n*log2^n</code></pre><p>用大O标记法表示，<code>T(n) = O(nlogn)</code></p><p>归并排序的<strong>执行效率与要排序的原始数组的有序程度无关</strong>，所以其时间复杂度是非常稳定的，不管是最好情况、最坏情况，还是平均情况，时间复杂度都是 <code>O(nlogn)</code>。</p><p>3 . 空间复杂度分析。归并排序的时间复杂度在任何情况下都是 <code>O(nlogn)</code>，看起来非常优秀，但是它并没有像快排那样应用广泛，其原因就是因为它有一个致命<code>弱点</code>，归并排序<strong>不是原地排序算法</strong>。主要原因在于<code>merge()</code>函数，需要借助额外的存储空间。</p><p>分析递归代码的空间复杂度并不能像时间复杂度那样累加。尽管每次合并操作都需要申请额外的内存空间，但在合并完成之后，临时开辟的内存空间就被释放掉了。在任意时刻，CPU 只会有一个函数在执行，也就只会有一个临时的内存空间在使用。临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 <code>O(n)</code>。</p><h3 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h3><h4 id="核心思想-1"><a href="#核心思想-1" class="headerlink" title="核心思想"></a>核心思想</h4><p>如果要排序数组中下标从 <code>p</code> 到 <code>q</code> 之间的一组数据，我们选择 <code>p</code> 到 <code>q</code> 之间的任意一个数据作为 <code>pivot（分区点）</code>（可选择末尾数字）。</p><p>遍历 <code>p</code> 到 <code>q</code> 之间的数据，将小于 <code>pivot</code> 的放到左边，将大于 <code>pivot</code> 的放到右边，将 <code>pivot</code> 放到中间。经过这一步骤之后，数组 <code>p</code> 到 <code>q</code> 之间的数据就被分成了三个部分，前面 <code>p</code> 到 <code>r-1</code> 之间都是小于 <code>pivot</code> 的，中间是 <code>pivot</code>，后面的 <code>r+1</code> 到 <code>q</code> 之间是大于 <code>pivot</code> 的。<br>其中一次排序步骤如下：</p><p><img src="http://ipineimg.lijundong.com/18-11-2/64232703.jpg" alt="快排"></p><p>递归排序下标从 <code>p</code> 到 <code>r-1</code> 之间的数据和下标从 <code>r+1</code> 到 <code>r</code> 之间的数据，直到区间缩小为 1，就说明所有的数据都有序了。</p><pre><code>递推公式quick_sort(p...q) = quick_sort(p...r-1) + quick_sort(r+1...q)终止条件p &gt;= q</code></pre><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><p>partition() 函数不需要额外的内存空间，保证快排是<strong>原地排序算法</strong>。</p><pre><code>def quick_sort(lt, lindex, rindex):    if lindex &lt; rindex:        pivot = partition(lt, lindex, rindex)        quick_sort(lt, lindex, pivot)        quick_sort(lt, pivot+1, rindex)    else:        returndef partition(lt, lindex, rindex):    i = lindex - 1    for j in range(lindex, rindex):        if lt[j] &lt;= lt[rindex]: #最后一个数据为pivot            i += 1            lt[i],lt[j] = lt[j], lt[i]    lt[i+1], lt[rindex] = lt[rindex], lt[i+1] #将分区点交换到数组中间位置    return i</code></pre><h4 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h4><p>1 . 快速排序是<strong>原地排序算法</strong>，即空间复杂度为O(1)。但在分区的过程涉及交换操作，如果数组中有两个相同的元素，在经过一次分区操作后，元素的相对先后顺序会改变。所以，快排<strong>不是一个稳定的排序算法</strong>。<br>2 . 时间复杂度分析。快排也是基于递归思想，前面的递归公式在这里仍适用。如果每次分区操作，都能正好把数组分成大小接近相等的两个小区间，那快排的时间复杂度递推求解公式跟归并是相同的。所以，快排的时间复杂度也是 <code>O(nlogn)</code>。但是，公式成立的前提是每次分区操作，选择的 <code>pivot</code> 都很合适，正好能将大区间对等地一分为二。但实际上这种情况是很难实现的。如果以最后一个元素作为<code>pivot</code>，需要进行大约 <code>n</code> 次分区操作，才能完成快排的整个过程。每次分区平均要扫描大约 <code>n/2</code> 个元素，这种情况下，快排的时间复杂度就从 <code>O(nlogn)</code> 退化成了 <code>O(n^2)</code>。<br>以上两种情况分别对应于<strong>最好情况</strong>和<strong>最坏情况</strong>，在大部分情况下快排的时间复杂度都可以做到 <code>O(nlogn)</code>，只有在极端情况下，才会退化到 <code>O(n^2)</code>。而且，有方法将这个极端情况的概率降到很低。</p><h3 id="快速排序和归并排序的区别"><a href="#快速排序和归并排序的区别" class="headerlink" title="快速排序和归并排序的区别"></a>快速排序和归并排序的区别</h3><p>快排和归并都用到分治思想，地推公式和递归代码也相似，它们的<strong>区别</strong>在于：归并排序的处理过程是<strong>由下到上</strong>的，先处理子问题，然后再合并；而快排正好相反，它的处理过程是<strong>由上到下</strong>的，先分区，再处理子问题。<br>归并排序虽然是<code>稳定的</code>、时间复杂度为 <code>O(nlogn)</code> 的排序算法，但是它是<code>非原地排序算法</code>，主要原因是合并函数无法在原地执行。快速排序通过设计巧妙的原地分区函数，可以实现<code>原地排序</code>，解决了归并排序占用太多内存的问题。</p><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p>利用分区思想，在<code>O(n)</code>时间复杂度时间内求无序数组中的第 <code>K</code> 大元素。<br>选择数组<code>arr[0,n-1]</code>的最后一个元素作为<code>pivot</code>，对数组<code>arr[0,n-1]</code>原地分区，数组分成三部分，<code>arr[0...p-1], arr[p], arr[p+1...n-1]</code>。如果 <code>p+1=K</code>，那 <code>arr[p]</code> 就是要求解的元素；如果 <code>K&gt;p+1</code>, 说明第 <code>K</code> 大元素出现在 <code>arr[p+1…n-1]</code> 区间，再按照上面的思路递归地在 <code>arr[p+1…n-1]</code> 这个区间内查找。同理，如果 <code>K&lt;p+1</code>，那就在 <code>arr[0…p-1]</code> 区间查找。</p><h4 id="为什么上述解决思路的时间复杂度是-O-n-？"><a href="#为什么上述解决思路的时间复杂度是-O-n-？" class="headerlink" title="为什么上述解决思路的时间复杂度是 O(n)？"></a>为什么上述解决思路的时间复杂度是 O(n)？</h4><p>第一次分区查找，需要对大小为 <code>n</code> 的数组执行分区操作，需要遍历 <code>n</code> 个元素。第二次分区查找，只需要对大小为 <code>n/2</code> 的数组执行分区操作，需要遍历 <code>n/2</code> 个元素。依次类推，分区遍历元素的个数分别为、<code>n/2、n/4、n/8、n/16.……</code> 直到区间缩小为 1。<br>把每次分区遍历的元素个数加起来，就是：<code>n+n/2+n/4+n/8+…+1</code> 。这是一个等比数列求和，最后的和等于 <code>2n-1</code>。所以，上述解决思路的时间复杂度就为 <code>O(n)</code>。</p><h4 id="另一种思路"><a href="#另一种思路" class="headerlink" title="另一种思路"></a>另一种思路</h4><p>每次取数组中的最小值，将其移动到数组的最前面，然后在剩下的数组中继续找最小值，以此类推，执行 <code>K</code> 次，找到的数据就是第 <code>K</code> 大元素。<br>思路是对的，但时间复杂度就不是 <code>O(n)</code> 了，而是 <strong><code>O(K * n)</code></strong>。当 <code>K</code> 是比较小的常量时，比如 1、2，那最好时间复杂度确实是 <code>O(n)</code>；但当 <code>K</code> 等于 <code>n/2</code> 或者 <code>n</code> 时，这种最坏情况下的时间复杂度就是 <code>O(n^2)</code> 了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;之前说的，冒泡排序、插入排序、选择排序三种算法的时间复杂度都是&lt;code&gt;O(n^2)&lt;/code&gt;，很高，适用于小规模数据的排序。&lt;br&gt;而，&lt;code&gt;归并排序&lt;/code&gt;和&lt;code&gt;快速排序&lt;/code&gt;，适用于大规模的数据排序，更为常用。&lt;/p&gt;
&lt;h3 id=
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>排序</title>
    <link href="http://ipine.github.io/2018-10-30/"/>
    <id>http://ipine.github.io/2018-10-30/</id>
    <published>2018-10-30T06:27:00.000Z</published>
    <updated>2019-02-22T11:27:49.412Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题思考"><a href="#问题思考" class="headerlink" title="问题思考"></a>问题思考</h3><p>插入排序和冒泡排序的时间复杂度相同，都是O(n^2)，在实际软件开发里，为什么更倾向于使用插入排序算法而不是冒泡排序算法呢？</p><h3 id="如何分析一个排序算法"><a href="#如何分析一个排序算法" class="headerlink" title="如何分析一个排序算法"></a>如何分析一个<strong>排序算法</strong></h3><h4 id="排序算法的执行效率"><a href="#排序算法的执行效率" class="headerlink" title="排序算法的执行效率"></a>排序算法的执行效率</h4><p>1 . 最好情况、最坏情况、平均情况时间复杂度<br>分析排序算法的时间复杂度是，要分别给出最好情况、最坏情况、平均情况下的时间复杂度。除此之外，还要说出最好、最坏时间复杂度对应的要排序的原始数据长什么样。</p><p>2 . 时间复杂度的系数、常数、低阶<br>尽管表示时间复杂度时，忽略了系数、常数、低阶。但实际软件开发中，排序的数据可能是10个、100个、1000个这样的小规模数据，因而对于同一阶时间复杂度的排序算法，在比较时，应该把系数、常数和低阶考虑进来。</p><p>3 . 比较次数和交换（移动）次数<br>基于比较的排序算法在执行过程中，会涉及到两种操作，一种是比较元素大小，另一种是元素交换或移动。</p><h4 id="排序算法的内存消耗"><a href="#排序算法的内存消耗" class="headerlink" title="排序算法的内存消耗"></a>排序算法的内存消耗</h4><p>内存消耗可以通过空间复杂度来衡量。针对排序算法的空间复杂度，引入一个新概念，<code>原地排序（Sorted in place）</code>。原地排序算法，就是特指空间复杂度是<code>O(1)</code>的排序算法。</p><blockquote><p>插入排序、冒泡排序、选择排序都是原地排序算法。</p></blockquote><h4 id="排序算法的稳定性"><a href="#排序算法的稳定性" class="headerlink" title="排序算法的稳定性"></a>排序算法的稳定性</h4><p>稳定性指：如果待排序的序列中存在值相等的元素，经过排序后，相等元素之间原有的先后顺序不变。<br>相等元素之间原有的先后顺序没有变，这种排序算法叫作<strong>稳定的排序算法</strong>；否则，叫作<strong>不稳定的排序算法</strong>。</p><h5 id="为什么要考察排序算法的稳定性？"><a href="#为什么要考察排序算法的稳定性？" class="headerlink" title="为什么要考察排序算法的稳定性？"></a>为什么要考察排序算法的稳定性？</h5><p><strong>场景举栗</strong><br>比如说，我们现在要给电商交易系统中的“订单”排序。订单有两个属性，一个是下单时间，另一个是订单金额。<br>如果我们现在有 10 万条订单数据，我们希望按照金额从小到大对订单数据排序。对于金额相同的订单，我们希望按照下单时间从早到晚有序。对于这样一个排序需求，我们怎么来做呢？</p><p><strong>思路分析</strong></p><ul><li>最先想到的方法是：先按照金额对订单数据进行排序，然后，再遍历排序之后的订单数据，对于每个金额相同的小区间再按照下单时间排序。这种排序思路理解起来不难，但是实现起来会很复杂。</li><li><p>更好的方法是：借助稳定排序算法。先按照下单时间给订单排序，注意是按照下单时间，不是金额。排序完成之后，再用稳定排序算法，按照订单金额重新排序。两遍排序之后，得到的订单数据就是按照金额从小到大排序，金额相同的订单按照下单时间从早到晚排序的。</p></li><li><p>原因：稳定排序算法可以保持金额相同的两个对象，在排序之后的前后顺序不变。第一次排序之后，所有的订单按照下单时间从早到晚有序了。在第二次排序中，因为用的是稳定的排序算法，所以经过第二次排序之后，相同金额的订单仍然保持下单时间从早到晚有序。</p></li></ul><h3 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h3><h4 id="排序过程"><a href="#排序过程" class="headerlink" title="排序过程"></a>排序过程</h4><p>冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复 <code>n</code> 次，就完成了 <code>n</code> 个数据的排序工作。</p><h4 id="优化过程"><a href="#优化过程" class="headerlink" title="优化过程"></a>优化过程</h4><p>当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，就不用再继续执行后续的冒泡操作。</p><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><pre><code>def bubble_sort(lt):    length = len(lt)    flag = False    for i in range(0,length):        for j in range(i+1,length):            if lt[i] &gt; lt[j]:                                lt[i], lt[j] = lt[j], lt[i] #数据交换                flag = True        if not flag:            break    return lt</code></pre><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><p>1 . 冒泡排序只涉及相邻数据的交换操作，只需常量级的临时空间，空间复杂度为<code>O(1)</code>，所以是一个<strong>原地排序算法</strong>。<br>2 . 冒泡排序中只有交换才改变两个元素的前后顺序。为了保证其稳定性，当相邻元素相等时，不做交换，那么相同大小的数据在排序前后不会改变顺序。所以冒泡排序是<strong>稳定</strong>的排序算法。<br>3 . 最好情况下，排序数据已经是有序的，只进行一次冒泡操作，所以时间复杂度是<code>O(n)</code>；最坏情况是，排序的数据刚好是倒序排列的，需要进行n次冒泡操作，所以时间复杂度为<code>O(n^2)</code>；<br>平均时间复杂度，采用一种不严格的方法，通过<strong>有序度</strong>和<strong>逆序度</strong>两个概念来分析。</p><blockquote><p>有序度：数组中具有有序关系的元素对的个数。（默认，从小到大是有序的）</p></blockquote><p>例：2,4,3,5这组数据的有序度为：5，分别是<code>(2,4),(2,3),(2,5),(4,5),(3,5)</code>；同理，对于一个倒序排列的数组，有序度为0；对于一个完全有序的数组，比如2,3,4,5，有序度就是<code>n*(n-1)/2</code>，也就是6。把这种完全有序的数组的有序度叫作<strong>满有序度</strong>。<br><strong>逆有序度</strong>：其定义跟有序度正好相反。</p><blockquote><p>逆有序度 = 满有序度 - 有序度 </p></blockquote><p>排序的过程就是一种增加有序度，减少逆序度的过程，最后达到满有序度，说明排序完成。<br>冒泡排序中，包含两个操作，比较和交换。每交换一次，有序度就加1。不管算法怎么改进，交换次数总是确定的，即为逆序度，也就是等于<code>n*(n-1)/2 - 初始有序度</code>。对于2,4,3,5这组数据来说，6-5=1，只需进行1次交换操作。</p><h4 id="那么对于包含n个数据的数组进行冒泡排序，平均交换次数是多少呢？"><a href="#那么对于包含n个数据的数组进行冒泡排序，平均交换次数是多少呢？" class="headerlink" title="那么对于包含n个数据的数组进行冒泡排序，平均交换次数是多少呢？"></a>那么对于包含n个数据的数组进行冒泡排序，平均交换次数是多少呢？</h4><ul><li><strong>最坏情况</strong>：初始有序度为<strong>0</strong>，需要进行<code>n*(n-1)/2</code>次交换</li><li><strong>最好情况</strong>：初始有序度为 <code>n*(n-1)/2</code>，需要进行<strong>0</strong>次交换</li><li><strong>平均情况</strong>：取一个中间值 <code>n*(n-1)/4</code>，来表示初始有序度既不是很高也不是很低的平均情况。换句话说，平均情况下，需要 <code>n*(n-1)/4</code> 次交换操作，比较操作肯定比交换操作更多，而时间复杂度的上限是 <code>O(n^2)</code>，所以平均情况下的时间复杂度就是 <code>O(n^2)</code>。</li></ul><h3 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h3><p>对于一个原本有序的数组，往里面加一个新数据后，如何继续保持数据的有序呢？很简单，只需要遍历数组，找到数据应该插入的位置将其插入即可。</p><blockquote><p>插入排序就是借助这个思想来实现排序的。</p></blockquote><h4 id="排序过程-1"><a href="#排序过程-1" class="headerlink" title="排序过程"></a>排序过程</h4><p>首先，将数组中的数据分为两个区间，已排序区间和未排序区间。初始已排序区间只有一个元素，就是数组的第一个元素。插入算法的核心思想是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序。重复这个过程，直到未排序区间中元素为空，算法结束。</p><h4 id="两种操作"><a href="#两种操作" class="headerlink" title="两种操作"></a>两种操作</h4><p>一种是元素的比较，另一种是元素的移动。对于不同的查找插入点方法（从头到尾，从尾到头），元素的比较次数是有区别的。但<strong>对于一个给定的初始序列，移动操作的次数总是固定的，即为逆序度</strong>。（为什么<code>移动次数=逆序度</code>，可以拿个实例画一个图，很容易明白）</p><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><pre><code>def insertion_sort(lt):    length = len(lt)    for i in range(1, length):        value = lt[i]        for j in range(i-1,-1,-1):            if lt[j] &gt; value:                lt[j+1] = lt[j] #数据移动            else:                break #位置确定        lt[j+1] = value  #插入数据    return lt</code></pre><h4 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h4><p>1 . 插入排序算法的运行并不需要额外的存储空间，空间复杂度为 <code>O(1)</code>，所以是一个<strong>原地排序算法</strong>。<br>2 . 插入排序中，对于值相同的元素，可以选择将后面出现的元素，插入到前面出现元素后面，保持原有前后顺序不变。所以插入排序是<strong>稳定</strong>的排序算法。<br>3 . 时间复杂度分析。</p><ul><li><strong>最好情况</strong>：数据已经有序，不需要搬移任何数据。如果从尾到头在有序数组里查找插入位置，每次只需比较一个数据就能确定插入位置。时间复杂度为 <code>O(n)</code>；</li><li><strong>最坏情况</strong>：数组是倒序的，每次插入都相当于在数组的第一个位置插入新数据，所有需要移动大量数据。时间复杂度为 <code>O(n^2)</code>；</li><li><strong>平均情况</strong>：在数组中插入一个数据的平均时间复杂度为 <code>O(n)</code>，对于插入排序来说，每次插入操作就相当于在数组中插入一个数据，循环执行 <code>n</code> 次插入操作。所以平均时间复杂度为 <code>O(n^2)</code>。</li></ul><h3 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h3><p>思路与插入排序类似，也分已排序区间和未排序区间。但是选择排序<strong>每次会从未排序区间中找到最小的元素，将其放到已排序区间末尾</strong>。最开始没有已排好的区间，找到数组中最小元素，将其与第一个元素交换，然后再执行以上过程。</p><h4 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h4><pre><code>def selection_sort(lt):    length = len(lt)    for i in range(0,length-1):        smallest_index = i        for j in range(i+1, length):            if lt[j] &lt; lt[smallest_index]:                lt[j], lt[smallest_index] = lt[smallest_index], lt[j]    return lt</code></pre><h4 id="分析-2"><a href="#分析-2" class="headerlink" title="分析"></a>分析</h4><p>1 . 选择排序空间复杂度为O(1)，是一种<strong>原地排序算法</strong>。<br>2 . 时间复杂度分析。最好情况、最坏情况和平均时间复杂度都为 <code>O(n^2)</code>。<br>3 . 选择排序是一种<strong>不稳定</strong>的排序算法。因为其每次都要找剩余未排序元素中的最小值，并和前面的元素交换位置，这样就破坏了稳定性。也因为此，相比于冒泡排序和插入排序，选择排序没那么好。</p><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p>冒泡排序和插入排序的时间复杂度都是 <code>O(n2)</code>，都是原地排序算法，为什么插入排序要比冒泡排序更受欢迎呢？<br>前面说过，冒泡排序不管怎么优化，元素交换的次数是一个固定值，是原始数据的逆序度。插入排序是同样的，不管怎么优化，元素移动的次数也等于原始数据的逆序度。<br>但是，从代码实现上来看，<strong>冒泡排序的数据交换要比插入排序的数据移动更复杂</strong>，冒泡排序需要 3 个赋值操作，而插入排序只需要 1 个。所以在对相同数组进行排序时，冒泡排序的运行时间理论上要长于插入排序。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题思考&quot;&gt;&lt;a href=&quot;#问题思考&quot; class=&quot;headerlink&quot; title=&quot;问题思考&quot;&gt;&lt;/a&gt;问题思考&lt;/h3&gt;&lt;p&gt;插入排序和冒泡排序的时间复杂度相同，都是O(n^2)，在实际软件开发里，为什么更倾向于使用插入排序算法而不是冒泡排序算法呢？
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>递归</title>
    <link href="http://ipine.github.io/2018-10-29/"/>
    <id>http://ipine.github.io/2018-10-29/</id>
    <published>2018-10-29T07:00:00.000Z</published>
    <updated>2019-02-22T11:27:48.310Z</updated>
    
    <content type="html"><![CDATA[<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>很多APP都有推荐用户注册返佣金或奖励的功能。在这个功能中，用户A推荐用户B来注册，用户B又推荐用户C来注册。那么用户C的<code>最终推荐人</code>就为A，用户B的<code>最终推荐人</code>也为A，用户A没有最终推荐人。在数据库表中，可以记录两行数据，其中<code>user_id</code>表示用户ID，<code>referrer_id</code>表示推荐人ID。<br>那么，问题是，给定一个用户ID，如何查找这个用户的<code>最终推荐人</code>？<br>应用到的思想就是递归</p><h3 id="如何理解递归"><a href="#如何理解递归" class="headerlink" title="如何理解递归"></a>如何理解<strong>递归</strong></h3><p>很多数据结构和算法的实现都要用到递归，比如<strong>DFS深度优先搜索</strong>、<strong>前中后序二叉树遍历</strong>等。</p><p>一个生活中的例子，在电影院由于太黑，你看不清自己在第几排，但是又想知道，怎么办呢？问前一排的人，他的排数+1就是你的排数。但是前一排的人也看不清自己在第几排，他又通过问自己的前一排，就这样一直传递问下去，直到第一排的人说我是第一排，于是又一排一排把数字传回来。<br>这样一个过程就是递归求解问题的分解过程，去的过程叫<code>递</code>，回来的过程叫<code>归</code>。基本上，所有的递归问题都可以用递推公式来表示。</p><pre><code>f(n) = f(n-1) + 1, 其中，f(1) = 1</code></pre><h3 id="什么样的问题能用递归来解决？"><a href="#什么样的问题能用递归来解决？" class="headerlink" title="什么样的问题能用递归来解决？"></a>什么样的问题能用递归来解决？</h3><p>同时满足以下三个条件，就可用递归来解决。</p><ul><li><p>一个问题的解可以分解为几个子问题的解。<br>子问题是指数据规模更小的问题<br>想知道你“自己在哪一排”，可以分解为“前一排的人在哪一排”这个子问题</p></li><li><p>这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样。<br>你求解“自己在哪一排”，与前面一排求解“自己在哪一排”的思路是相同的。</p></li><li><p>存在递归终止条件<br>问题分解为子问题，子问题再一层层分解下去，但是不能无限循环，必须有终止条件。<br>电影院第一排的人知道自己在哪一排，即<code>f(1) = 1</code>,这就是递归终止条件。</p></li></ul><h3 id="编写递归代码"><a href="#编写递归代码" class="headerlink" title="编写递归代码"></a>编写递归代码</h3><p><strong>关键点：写出递归公式，找到终止条件。</strong></p><h4 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h4><p>假设有n个台阶，每次可以跨1个台阶或者2个台阶，那么请问走完这n个台阶，共有多少种走法？</p><h5 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h5><p>可以根据第一步的走法把所有走法分为两类，第一类是，第一步走1个台阶；第二类是，第一步走2个台阶。<br>所以，<code>n</code>个台阶的走法就等于，先走1阶后，<code>n-1</code>个台阶的走法，加上，先走2阶后，<code>n-2</code>个台阶的走法。<br>公式表示为：</p><pre><code>f(n) = f(n-1) + f(n-2)</code></pre><p>有了递推公式还不够，再分析终止条件：当有1个台阶时，就只有一个走法，所以<code>f(1) = 1</code>。用小规模数试验一下，该终止条件是否合理，当<code>n=2</code>时，<code>f(2) = f(1) + f(0)</code>。发现<code>f(2)</code>没法求解，因为没给<code>f(0)</code>的值。可以给定<code>f(0) = 0</code>，表示走0个台阶有1种走法，但这不符合常识，因而可以直接给定<code>f(2) = 2</code>，表示走2个台阶有2种走法，要么一步1个台阶走，要么一次跨2个台阶。<br>这样再试验<code>f(3) = f(2) + f(1)</code>，可以得出结果并正确。所以，递归终止条件就为<code>f(1)= 1, f(2) = 2</code>。<br>最终公式</p><pre><code>f(1)= 1f(2) = 2f(n) = f(n-1) + f(n-2)</code></pre><h5 id="递归代码"><a href="#递归代码" class="headerlink" title="递归代码"></a>递归代码</h5><pre><code>def climbStairs(self,n):    if n==1:        return 1    elif n==2:        return 2    else:        return self.climbStairs(n-1) + self.climbStairs(n-2)</code></pre><h3 id="Key"><a href="#Key" class="headerlink" title="Key"></a>Key</h3><p>对于递归代码，试图想清楚整个递和归过程的做法，实际上是进入了一个思维误区。很多时候，理解起来比较吃力，主要原因就是自己给自己制造了这种理解障碍。</p><p><strong>正确的思维方式</strong>应该是:<br>如果一个问题 A 可以分解为若干子问题 B、C、D，就假设子问题 B、C、D 已经解决，在此基础上思考如何解决问题 A。而且，只需要思考问题 A 与子问题 B、C、D 两层之间的关系即可，不需要一层一层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样子理解起来就简单多了。<br>因此，编写递归代码的关键是，只要遇到递归，就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。</p><h3 id="注意问题"><a href="#注意问题" class="headerlink" title="注意问题"></a>注意问题</h3><p>1 . 递归代码要警惕堆栈溢出。函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完成返回时，才出栈。系统栈或者虚拟机栈空间一般都不大。如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。</p><p><strong>解决思路</strong>：可以通过在代码中限制递归调用的最大深度的方式来解决这个问题。递归调用超过一定深度（比如 1000）之后，我们就不继续往下再递归了，直接返回报错。</p><p>2 . 递归代码要警惕重复计算。刚刚的例子中，就存在这个问题，比如要计算<code>f(5)</code>，就需要计算<code>f(4)</code>和<code>f(3)</code>，而计算<code>f(4)</code>，需要计算<code>f(3)</code>和<code>f(2)</code>，这个过程中<strong>f(3)就被计算了多次</strong>。</p><p><strong>解决思路</strong>：通过一个数据结构（散列表）来保存已经求解过的f(i)。当递归调用到f(i)时，先查找这个值是否已经求解。若是，则直接从散列表中取值返回，避免重复计算。</p><h4 id="修改栗子中的代码"><a href="#修改栗子中的代码" class="headerlink" title="修改栗子中的代码"></a>修改栗子中的代码</h4><pre><code>def climbStairs(self,n):    hash_list = [0,1,2]    if n==1:        return hash_list[1]    elif n==2:        return hash_list[2]    else:        for i in range(3, n+1):            hash_list.append(hash_list[i-1] + hash_list[i-2])        return  hash_list[n]</code></pre><p>3 . 时间和空间成本很高。在时间效率上，递归代码里多了很多函数调用，当这些函数调用的数量较大时，就会积聚成一个可观的时间成本。在空间复杂度上，因为递归调用一次就会在内存栈中保存一次现场数据，所以在分析递归代码空间复杂度时，需要额外考虑这部分的开销，比如前面的电影院递归代码，空间复杂度并不是 <code>O(1)</code>，而是 <code>O(n)</code>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;应用场景&quot;&gt;&lt;a href=&quot;#应用场景&quot; class=&quot;headerlink&quot; title=&quot;应用场景&quot;&gt;&lt;/a&gt;应用场景&lt;/h3&gt;&lt;p&gt;很多APP都有推荐用户注册返佣金或奖励的功能。在这个功能中，用户A推荐用户B来注册，用户B又推荐用户C来注册。那么用户C的&lt;
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>队列</title>
    <link href="http://ipine.github.io/2018-10-16/"/>
    <id>http://ipine.github.io/2018-10-16/</id>
    <published>2018-10-16T11:58:00.000Z</published>
    <updated>2019-02-22T11:27:46.805Z</updated>
    
    <content type="html"><![CDATA[<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>CPU资源有限，任务的处理速度与线程个数并不是线性正相关。过多的线程会导致CPU频繁切换，处理性能下降。<br>当我们向固定大小的线程池中请求一个线程时，如果线程池中没有空闲资源了，这个时候线程池如何处理这个请求？是拒绝请求还是排队请求？各种处理策略又是怎么实现的呢？<br>这就需要用到<code>队列</code>这个数据结构</p><h3 id="如何理解队列"><a href="#如何理解队列" class="headerlink" title="如何理解队列"></a>如何理解<code>队列</code></h3><p>理解成，排队购票，排在前面的先买，排在后面的后买。即<code>先进者先出</code>（FIFO）。<br>队列跟栈非常相似，支持的操作也有限，最基本的也是两个：<strong>入队和出队，一端出队，另一端入队</strong>；所以队列也是一种操作受限的<code>线性表</code>数据结构。</p><h3 id="顺序队列和链式队列"><a href="#顺序队列和链式队列" class="headerlink" title="顺序队列和链式队列"></a>顺序队列和链式队列</h3><p>用数组实现的队列叫作顺序队列，用链表实现的队列叫作链式队列。</p><h4 id="顺序队列"><a href="#顺序队列" class="headerlink" title="顺序队列"></a>顺序队列</h4><p>不理想的设计：<br>1 . 若使用顺序表的尾端插入实现<code>enqueue</code>操作，根据队列性质，出队操作应该在表的首端进行。为了维护顺序表的完整性（表元素在表前端连续存放），出队操作取出当时的首元素后，就需要把表中其余元素全部前移，这样就会是一个 <code>O(n)</code> 时间的操作。<br>2 . 反过来：从尾端出队是 <code>O(1)</code> 操作，但从首端入队就是 <code>O(n)</code> 时间操作，这种设计也不理想。<br>3 . 另一种是在队首元素出队后表中的元素不前移，但记住新队头位置。如果队列中没有空闲了，只需要在入队时，再集中触发一次数据的搬移操作。</p><h4 id="链式队列"><a href="#链式队列" class="headerlink" title="链式队列"></a>链式队列</h4><p>最简单的单链表只支持首端 <code>O(1)</code> 的操作，在另一端操作需要 <code>O(n)</code> 时间。不适合作为队列的实现基础。<br>考虑<code>带表尾指针</code>的单链表，它支持 <code>O(1)</code> 时间的尾端插入操作；再加上表首端的高效访问和删除，基于单链表实现队列就很容易。</p><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><pre><code>class LNode:    def __init__(self, elem, next_=None):        self.data = elem        self.next = next_class QueueUnderflow(ValueError):    passclass LQueue:    def __init__(self):        self._head = None        self._rear = None    def is_empty(self):        return self._head is None    def peek(self):        &quot;&quot;&quot;查看队列最早元素，不删除&quot;&quot;&quot;        if self._head is None: #是空队列            raise QueueUnderflow(&apos;in peek of Queue&apos;)        else:            return self._head.data    def dequeue(self):        &quot;&quot;&quot;删除队列头结点，并返回这个结点里的数据&quot;&quot;&quot;        if self._head == None:            raise QueueUnderflow(&quot;in dequeue&quot;)        e = self._head.data        self._head = self._head.next        return e    def enqueue(self, elem):        if self._head is None:#空表            self._head = LNode(elem, self._head)            self._rear = self._head        else:            self._rear.next = LNode(elem)            self._rear = self._rear.next</code></pre><h3 id="循环队列"><a href="#循环队列" class="headerlink" title="循环队列"></a>循环队列</h3><p>一个具体的实现示例：基于Python的list实现顺序表示的循环队列。<br>考虑定义一个可以自定扩充存储结构的队列类。</p><blockquote><p>注：不能直接利用list的自动存储扩充机制。两个原因：<br> 1 . 队列元素的存储方式与list元素的默认存储方式不一致；list元素总在其存储器的最前面一段，而队列的元素可能是表里的任意一段，有时还分为头尾两段。<br> 2 . list没有提供检测元素存储区容量的机制，队列操作中无法判断系统何时扩容。</p></blockquote><h5 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h5><pre><code>class SQueue():    def __init__(self, init_len = 8):        self._len = init_len       #存储区长度        self._elems = [0] *init_len #元素存储        self._head = 0              #表头元素下标        self._num = 0               #元素个数    def is_empty(self):        return self._num == 0    def peek(self):        if self._num is None: #是空队列            raise QueueUnderflow(&apos;in peek of SQueue&apos;)        return self._elems[self._head]    def dequeue(self):        if self._num == 0:            raise QueueUnderflow(&apos;in dequeue of SQueue&apos;)        e = self._elems[self._head]        self._head = (self._head+1)%self._len        self._num -= 1        return e    def enqueue(self,e):        if self._num == self._len: #队满时            self._extend()        self._elems[(self._head+self._num)%self._len] = e        self._num += 1    def _extend(self):        old_len = self._len        self._len *= 2        new_elems = [0]*self._len #扩大元素存储区        for i in range(old_len):  #将原有元素搬迁到新表里（最前面的位置）            new_elems[i] = self._elems[(self._head+1)%old_len]        self._elems, self._head = new_elems, 0  </code></pre><p><strong>注解</strong></p><p>1 . 队列对象的4个属性，<code>_elems</code>，<code>_head</code>，<code>_num</code>，<code>_len</code>的作用分别是：<strong>存放队列元素</strong>，<strong>记录队列首元素所在位置的下标</strong>，<strong>记录表中元素个数</strong>，<strong>记录当存储区的有效容量（便于换存储表）</strong>。<br>2 . 在<code>_num = _len</code> 的情况下（队满）出现入队操作，就扩大存储区；队空就是 <code>_num == 0</code>。<br>3 . 队列里的元素总保存在<code>_elems</code>里，从<code>_head</code>开始的连续位置中。<br>4 . 新入队的元素存入在 <code>(_head + _num)%len</code> 算出的位置；若需要把元素存入下标<code>_len</code>的位置时，改为在<code>下标0位置</code>存入。<br>5 . 在<code>_extend</code>函数中新元素尚未入队，但<code>_extend</code>在enqueue返回后，enqueue的最后两句语句将正常完成这个工作。</p><h3 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h3><p>阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。</p><blockquote><p>注：可以用阻塞队列实现一个“生产者-消费者模型”。基于阻塞队列，可以通过协调“生产者”和“消费者”的个数，来提高数据的处理效率。</p></blockquote><h3 id="并发队列"><a href="#并发队列" class="headerlink" title="并发队列"></a>并发队列</h3><p>在多线程情况下，会有多个线程同时操作队列，这个时候就会存在线程安全问题。<br>要实现一个线程安全的队列就需要<code>并发队列</code>。<br>最简单直接的实现方式是直接在 <code>enqueue()</code>、<code>dequeue()</code> 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。</p><h3 id="解答引言"><a href="#解答引言" class="headerlink" title="解答引言"></a>解答引言</h3><p>一般有两种处理策略。</p><ul><li>第一种是非阻塞的处理方式，直接拒绝任务请求；</li><li>另一种是阻塞的处理方式，将请求排队，等到有空闲线程时，取出排队的请求继续处理。</li></ul><p><strong>那如何存储排队的请求呢？</strong><br>公平地处理每个排队的请求，先进者先服务，所以队列这种数据结构很适合来存储排队请求。</p><p>队列有基于链表和基于数组这两种实现方式。<strong>两种实现方式对于排队请求又有什么区别呢？</strong></p><h4 id="基于链表的实现方式"><a href="#基于链表的实现方式" class="headerlink" title="基于链表的实现方式"></a>基于链表的实现方式</h4><p>可以实现一个支持无限排队的<code>无界队列（unbounded queue）</code>，但是可能会导致过多的请求排队等待，请求处理的响应时间过长。<br>所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。</p><h4 id="基于数组的实现方式"><a href="#基于数组的实现方式" class="headerlink" title="基于数组的实现方式"></a>基于数组的实现方式</h4><p>可以实现的是<code>有界队列（bounded queue）</code>，队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。<br>这时，设置一个合理的队列大小，就非常重要。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。</p><blockquote><p>注：对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过<code>队列</code>这种数据结构来实现请求排队。</p></blockquote><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>队列的其他应用<br>1 . 文件打印<br>2 . 万维网服务器<br>3 . Windows系统和消息队列<br>4 . 离散事件系统模拟</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h3&gt;&lt;p&gt;CPU资源有限，任务的处理速度与线程个数并不是线性正相关。过多的线程会导致CPU频繁切换，处理性能下降。&lt;br&gt;当我们向固定大小的线程池中请
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>栈</title>
    <link href="http://ipine.github.io/2018-10-13/"/>
    <id>http://ipine.github.io/2018-10-13/</id>
    <published>2018-10-13T11:58:00.000Z</published>
    <updated>2019-02-22T11:27:45.130Z</updated>
    
    <content type="html"><![CDATA[<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>首先思考一个问题，浏览器的前进、后退功能是如何实现的呢？</p><h3 id="理解栈"><a href="#理解栈" class="headerlink" title="理解栈"></a>理解栈</h3><ul><li><code>栈</code>结构：先进的后出，后进的先出。类似于洗好的盘子，叠一摞，下次用的时候只能从最上面那个盘子开始拿。</li><li>操作特性：<code>操作受限</code>的<strong>线性表</strong></li><li>什么时候用：当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出的特性，就应该首选<code>栈</code>这种结构。</li></ul><h3 id="如何实现栈"><a href="#如何实现栈" class="headerlink" title="如何实现栈"></a>如何实现栈</h3><p>栈既可以用数组实现，也可以用链表来实现。用数组实现的栈，叫作顺序栈，用链表实现的栈，叫作链栈。</p><ul><li>示例：顺序栈</li></ul><pre><code>class Stack():    def __init__(self,size):        &quot;&quot;&quot;初始化&quot;&quot;&quot;        self.size = size        self.num = 0        self.stack = []    def getSize(self):        &quot;&quot;&quot;获取栈的长度&quot;&quot;&quot;        return self.num    def print_all(self):        &quot;&quot;&quot;输出栈元素&quot;&quot;&quot;        for s in self.stack:            print s    def append_stack(self,value):        &quot;&quot;&quot;入栈&quot;&quot;&quot;        if self.num &gt;= self.size:            print(&quot;the stack is full&quot;)            return        else:            self.stack.append(value)            self.num += 1    def pop_stack(self):        &quot;&quot;&quot; 出栈&quot;&quot;&quot;        if self.num is None:            print(&quot;the stack is empty&quot;)            return        else:            self.stack.remove(self.stack[-1])</code></pre><h3 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><h4 id="空间复杂度"><a href="#空间复杂度" class="headerlink" title="空间复杂度"></a>空间复杂度</h4><p>无论是顺序栈还是链栈，存储数据只需要一个大小为n的数组。在入栈和出栈过程中，只需要一两个临时变量存储空间，所以空间复杂度为<code>O(1)</code>。</p><blockquote><p>注：存储数据需要一个大小为n的数组，并不是指空间复杂度就为O(n)。因为，这 n 个空间是必须的，无法省掉。<br>我们说空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要的额外的存储空间。</p></blockquote><h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><p>不管顺序栈还是链栈，入栈、出栈只涉及栈顶个别数据的操作，所以复杂度为<code>O(1)</code>。</p><h4 id="支持动态扩容的顺序栈的入栈、出栈时间复杂度分析"><a href="#支持动态扩容的顺序栈的入栈、出栈时间复杂度分析" class="headerlink" title="支持动态扩容的顺序栈的入栈、出栈时间复杂度分析"></a>支持动态扩容的顺序栈的入栈、出栈时间复杂度分析</h4><p>对于出栈操作来说，不会涉及内存的重新申请和数据的搬移，所以出栈的时间复杂度仍然是 <code>O(1)</code>。但是，对于入栈操作来说，情况就不一样了。当栈中有空闲空间时，入栈操作的时间复杂度为 <code>O(1)</code>。但当空间不够时，就需要重新申请内存和数据搬移，所以时间复杂度就变成了 <code>O(n)</code>。</p><p>也就是说，对于入栈操作来说，最好情况时间复杂度是 <code>O(1)</code>，最坏情况时间复杂度是 <code>O(n)</code>。而平均时间复杂度，由摊还分析法分析可知为 <code>O(1)</code>。</p><h3 id="栈的应用"><a href="#栈的应用" class="headerlink" title="栈的应用"></a>栈的应用</h3><h4 id="在函数调用中的应用"><a href="#在函数调用中的应用" class="headerlink" title="在函数调用中的应用"></a>在函数调用中的应用</h4><p>操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。</p><h4 id="栈在表达式求值中的应用"><a href="#栈在表达式求值中的应用" class="headerlink" title="栈在表达式求值中的应用"></a>栈在表达式求值中的应用</h4><p>实现一个表达式求值的功能，编译器就是通过两个栈来实现的。<br>其中一个保存操作数的栈，另一个是保存运算符的栈。<br>从左向右遍历表达式，当遇到数字，就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。<br>如果当前运算符优先级高，就将当前运算符压入栈；如果运算符栈顶元素优先级高，就从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。</p><h5 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h5><p><code>3+5*8-6</code>表达式的计算过程如下：</p><p><img src="http://ipineimg.lijundong.com/18-10-16/98172578.jpg" alt="表达式"></p><h4 id="栈在括号匹配中的应用"><a href="#栈在括号匹配中的应用" class="headerlink" title="栈在括号匹配中的应用"></a>栈在括号匹配中的应用</h4><p>假设表达式中只包含三种括号，<code>圆括号 ()</code>、<code>方括号 []</code> 和<code>花括号{}</code>，并且它们可以任意嵌套。比如，<code>{[{}]}</code>或 <code>[{()}([])]</code> 等都为合法格式，而<code>{[}()]</code> 或 <code>[({)]</code> 为不合法的格式。</p><h5 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h5><p>给定一个包含三种括号的表达式字符串，如何检查它是否合法呢？</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><p>用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，比如<code>(</code>跟<code>)</code>匹配，<code>[</code>跟<code>]</code>匹配，<code>{</code>跟<code>}</code>匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。<br>当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。</p><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><pre><code>left_brackets = &apos;{[(&lt;&apos;right_brackets = &apos;}])&gt;&apos;matching_brackets = {&apos;}&apos;: &apos;{&apos;, &apos;]&apos;: &apos;[&apos;, &apos;)&apos;: &apos;(&apos;, &apos;&gt;&apos;: &apos;&lt;&apos;}def judgment_brackets_matching(rows):    stack = []    label = True    for row in rows:        if row in left_brackets:            stack.append(row)        elif row in right_brackets:            if len(stack) &lt; 1:                label = False                break            elif matching_brackets[row] == stack[-1]:                stack.pop()            else:                label = False                break        else:            continue    if stack:        label = False    return label</code></pre><h2 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h2><p>用栈实现浏览器的前进、后退功能</p><h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h3><p>使用两个栈，<code>X</code> 和 <code>Y</code>，把首次浏览的页面依次压入栈 <code>X</code>，当点击后退按钮时，再依次从栈 <code>X</code> 中出栈，并将出栈的数据依次放入栈 <code>Y</code>。当我们点击前进按钮时，我们依次从栈 <code>Y</code> 中取出数据，放入栈 <code>X</code> 中。当栈 <code>X</code> 中没有数据时，那就说明没有页面可以继续后退浏览了。当栈 <code>Y</code> 中没有数据，那就说明没有页面可以点击前进按钮浏览了。</p><h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>顺序查看了a,b,c三个页面，将其依次压入栈，栈中数据情况为：</p><pre><code>X: a-&gt;b-&gt;cY: None</code></pre><p>点击后退按钮，从c页面推到a页面，栈中数据情况为：</p><pre><code>X: NoneY: c-&gt;b-&gt;a</code></pre><p>想再次查看b页面，点击前进按钮到b页面，此时栈中数据情况为：</p><pre><code>X: a-&gt;bY: c</code></pre><p>假设，此时在b页面跳转到新页面d，页面c就无法通过前进或后退按钮重复查看了，因而需要清空Y栈：</p><pre><code>X: a-&gt;b-&gt;dY: None</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;思考&quot;&gt;&lt;a href=&quot;#思考&quot; class=&quot;headerlink&quot; title=&quot;思考&quot;&gt;&lt;/a&gt;思考&lt;/h2&gt;&lt;p&gt;首先思考一个问题，浏览器的前进、后退功能是如何实现的呢？&lt;/p&gt;
&lt;h3 id=&quot;理解栈&quot;&gt;&lt;a href=&quot;#理解栈&quot; class=&quot;he
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
</feed>
