<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>iPine&#39;s Blog</title>
  
  <subtitle>看似无意义的事，竟是有意义的</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://ipine.github.io/"/>
  <updated>2019-02-22T11:26:25.452Z</updated>
  <id>http://ipine.github.io/</id>
  
  <author>
    <name>iPine</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>散列表</title>
    <link href="http://ipine.github.io/2018-12-18/"/>
    <id>http://ipine.github.io/2018-12-18/</id>
    <published>2018-12-18T11:30:10.894Z</published>
    <updated>2019-02-22T11:26:25.452Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h3 id="散列表效率"><a href="#散列表效率" class="headerlink" title="散列表效率"></a>散列表效率</h3><p>之前讲到散列表的查询效率并不能笼统地说成是 <code>O(1)</code> 。它跟散列函数、装载因子、散列冲突都有关系。在极端情况下，恶意攻击者，通过精心构造的数据，使得所有数据经过散列函数后，都散列到同一个槽里。若我们使用的是基于链表的冲突解决办法，那这个时候，散列表就会退化为链表，查询时间度也退化为 <code>O(n)</code>。</p><h3 id="开篇问题"><a href="#开篇问题" class="headerlink" title="开篇问题"></a>开篇问题</h3><p>如何设计一个可以应对各种异常情况的工业级散列表？在散列冲突的情况下，能够避免散列表性能的急剧下降。</p><h3 id="散列函数"><a href="#散列函数" class="headerlink" title="散列函数"></a>散列函数</h3><ul><li>设计不能太复杂 ：避免消耗很多计算时间</li><li>生成的值要尽可能随机并且均匀分布：避免或者最小化散列冲突</li></ul><h3 id="装载因子过大怎么办？"><a href="#装载因子过大怎么办？" class="headerlink" title="装载因子过大怎么办？"></a>装载因子过大怎么办？</h3><p>装载因子越大，说明散列表中的元素越多，空闲位置越少，散列冲突的概率就越大。<br>不仅插入数据的过程要多次寻址或者拉很长的链，查找的过程也会因此变得很慢。</p><h4 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h4><p>使用动态扩容，重新申请一个更大的散列表，将数据搬移到这个新散列表中。</p><p><img src="http://ipineimg.lijundong.com/18-12-18/9130606.jpg" alt="动态扩容"></p><blockquote><p>存在问题：数据搬移操作很复杂，需要通过散列函数重新计算每个数据的存储位置。</p></blockquote><h4 id="插入数据时间复杂度"><a href="#插入数据时间复杂度" class="headerlink" title="插入数据时间复杂度"></a>插入数据时间复杂度</h4><ul><li>最好情况：不需要扩容，复杂度为 <code>O(1)</code></li><li>最坏情况：散列表装载因子过高，需扩容，重新申请内存，重新计算哈希位置，并搬移位置，复杂度为 <code>O(n)</code></li><li>平均情况：摊还分析，时间复杂度接近最好情况，为 <code>O(1)</code></li></ul><h4 id="平衡空间与时间的消耗"><a href="#平衡空间与时间的消耗" class="headerlink" title="平衡空间与时间的消耗"></a>平衡空间与时间的消耗</h4><p>若对空间消耗非常敏感，可以为装载因子设置阈值，当装载因子小于阈值之后，启动动态缩容。</p><p>若更在意执行效率，能够容忍多消耗一点内存空间，就不需要缩容。</p><p>装载因子阈值需要选择得当。如果太大，会导致冲突过多；如果太小，会导致内存浪费严重。<br>阈值的设置要权衡时间、空间复杂度。<br>如果内存空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；</p><p>相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值，甚至可以大于 1。</p><h3 id="避免低效扩容"><a href="#避免低效扩容" class="headerlink" title="避免低效扩容"></a>避免低效扩容</h3><p>为解决一次性扩容耗时过多的情况，可以将扩容操作穿插在插入操作的过程中，分批完成。</p><h4 id="具体过程"><a href="#具体过程" class="headerlink" title="具体过程"></a>具体过程</h4><ul><li>当装载因子触达阈值之后，只申请新空间，并不将老的数据搬移到新的散列表中。</li><li>每当有新数据插入，将新数据插入新散列表，并从旧散列表拿一个数据放入新散列表。</li></ul><p><img src="http://ipineimg.lijundong.com/18-12-18/95492788.jpg" alt="高效扩容"></p><h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><p>通过以上均摊方法，将一次扩容的代价，均摊到多次插入操作中。这种实现方式，在任何情况下，插入一个数据的时间复杂度都是 <code>O(1)</code></p><h4 id="查询操作"><a href="#查询操作" class="headerlink" title="查询操作"></a>查询操作</h4><ul><li>先在新散列表中查询</li><li>未查询到，再到旧散列表中查找</li></ul><h3 id="冲突解决方法"><a href="#冲突解决方法" class="headerlink" title="冲突解决方法"></a>冲突解决方法</h3><h4 id="开放寻址法"><a href="#开放寻址法" class="headerlink" title="开放寻址法"></a>开放寻址法</h4><p><strong>优点</strong></p><ul><li>数据存储在数组中，有效利用CPU缓存加快查询速度</li><li>方便序列化</li><li>不需要额外空间</li></ul><p><strong>缺点</strong></p><ul><li>查找、删除数据时，涉及到<code>delete</code>标记，比较麻烦</li><li>所有数据存储在一个数组中，冲突代价比较高</li><li>装载因子的上限不能太大，更浪费空间</li></ul><h4 id="链表法"><a href="#链表法" class="headerlink" title="链表法"></a>链表法</h4><p><strong>优点</strong></p><ul><li>对内存的利用率更高</li><li>对装载因子的容忍度更高；即便装载因子变成10，也只是链表的长度变长</li></ul><p><strong>缺点</strong></p><ul><li>需要额外的空间来保存指针</li><li>结点零散分布在内存中，不连续，对CPU缓存不友好</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>当数据量比较小、装载因子小的时候，适合采用开放寻址法；</p><p>面对大对象、大数据量的散列表时，适合采用基于链表的散列冲突处理方法。<br>而且，比起开放寻址法，链表法更加灵活，支持更多的优化策略，比如用红黑树代替链表。</p><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><h4 id="工业级的散列表应该具有哪些特性？"><a href="#工业级的散列表应该具有哪些特性？" class="headerlink" title="工业级的散列表应该具有哪些特性？"></a>工业级的散列表应该具有哪些特性？</h4><ul><li>支持快速的查询、插入、删除操作；</li><li>内存占用合理，不能浪费过多的内存空间；</li><li>性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况。</li></ul><h4 id="从三个方面来考虑设计思路"><a href="#从三个方面来考虑设计思路" class="headerlink" title="从三个方面来考虑设计思路"></a>从三个方面来考虑设计思路</h4><ul><li>设计一个合适的散列函数；</li><li>定义装载因子阈值，并且设计动态扩容策略；</li><li>选择合适的散列冲突解决方法。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;散列表效率&quot;&gt;&lt;a href=&quot;#散列表效率&quot; class=&quot;headerlink&quot; title=&quot;散列表效率&quot;&gt;&lt;/a&gt;散列表效率&lt;/h3&gt;&lt;p&gt;之前讲到散列表的查询效率并不能笼统地说成是 &lt;code&gt;O(1)&lt;/code&gt; 
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>探索气温趋势</title>
    <link href="http://ipine.github.io/2018-11-26/"/>
    <id>http://ipine.github.io/2018-11-26/</id>
    <published>2018-11-26T06:22:44.405Z</published>
    <updated>2019-02-22T11:28:02.148Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://github.com/iPine/data_analysis_project_1" target="_blank" rel="noopener">代码传送门，包括扩展了交互功能的改进版</a></p></blockquote><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>分析全球和自己所在地的气温数据，比较所在城市的气温走向与全球气温走向。</p><h3 id="数据获取"><a href="#数据获取" class="headerlink" title="数据获取"></a>数据获取</h3><p>从数据库中提取数据。通过<a href="https://classroom.udacity.com/nanodegrees/nd002-cn-basic-vip/parts/d1865612-f3fd-4db0-80c7-348c594d573d/modules/7b83f9fd-759a-4cc6-8456-ce3783e17475/lessons/dce89631-d141-4a36-b3fd-5e8ec038bc70/concepts/530f21c0-2f37-4390-aaab-3ce440e56d80" target="_blank" rel="noopener">Udacity</a>提供的工作区，该工作区与数据库连接。</p><h4 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h4><p>写入以下SQL语句，导出世界气温数据以及最接近自己居住地的大城市气温数据。</p><ol><li><p>首先查看<code>city_list</code>表，<code>country</code>列等于<code>China</code>的城市有哪些;</p></li><li><p>然后将离自己所在城市<code>长沙</code>最近的城市<code>武汉</code>市的数据提取出来;</p></li><li><p>最后再将全球气温数据提取出来。</p><p> select * from city_list where country=’China’;</p><p> select * from city_data where city=’Wuhan’;</p><p> select * from global_data;</p></li></ol><h4 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h4><p>或者通过以下SQL命令，一次性将两个数据都提取到一个表格：</p><pre><code>select c.year, c.avg_temp as city_temp, g.avg_temp as global_tempfrom city_data c, global_data gwhere c.year = g.yearand c.city = &apos;Wuhan&apos;;</code></pre><h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><p>使用Python将提取的数据（<strong>这里的数据是采用方法一提取的</strong>）可视化成一个线条图，便于武汉市和全球气温比较。</p><h4 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h4><ol><li>绘制图使用<code>matplotlib.pyplot</code>模块；移动平均值计算需使用<code>pandas</code>库；设置坐标轴的ticks需用到<code>matplotlib.ticker</code>模块；matplotlib绘图可视化的各属性设置可参考<a href="http://python.jobbole.com/85106/" target="_blank" rel="noopener">这里</a></li></ol><ol start="2"><li><p>为了使绘制的线图更加平滑，便于观察气温走向，所以采用气温的移动平均值，而不是原始的年平均值。因而需要先计算移动平均值—–&gt;函数<code>calculate_moving_average()</code></p><p> 1）移动平均值的计算方法这里采用<a href="http://pandas.pydata.org/pandas-docs/version/0.17.1/generated/pandas.rolling_mean.html" target="_blank" rel="noopener">pandas.rolling_mean</a>函数。但是，按照文档说明传入参数后，会报出<code>AttributeError: module &#39;pandas&#39; has no attribute &#39;rolling_mean&#39;</code>错误，后来发现是<code>pandas</code>库的版本问题，具体解决方案可参考<a href="https://stackoverflow.com/questions/50482884/module-pandas-has-no-attribute-rolling-mean" target="_blank" rel="noopener">这里</a>。</p><p> 2）移动平均值窗口大小的设定需要权衡考虑。设置得过小，起不到平滑的作用，波动仍然会很剧烈；设置得过大，数据越平滑，但是准确性和敏感性就降低的越多。所以需要在数据变化准确性和平滑程度之间进行一个权衡，既想要观察到更多局部的波动，又想要观察长远趋势，10年左右是比较好的选择。</p></li></ol><ol start="3"><li><p>有了移动均值后，就可以开始绘制图形了—–&gt;函数<code>show_fig()</code></p><p> 1）绘制图形时需要考虑所在城市的数据范围是否与全球气温数据的范围一致。武汉市的数据是从1841年到2013年，而全球气温数据是从1750年到2015年，所以要将城市数据和全球数据处理成在相同时间段内，才能正确比较趋势。</p><p> <em>注：只有当采用方法一获取数据时才需考虑第一点</em></p><p> 2）需要考虑如何设置图形坐标轴的刻度尺大小，使得图形大小更为合适，便于查看和比较本地城市和全球的气温。</p></li></ol><pre><code><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""分析所在城市和全球的气温趋势</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> MultipleLocator, FormatStrFormatter</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_moving_average</span><span class="params">(row_data,window)</span>:</span></span><br><span class="line">    <span class="string">"""计算移动平均值</span></span><br><span class="line"><span class="string">       参数1：需要计算移动平均值的csv文件</span></span><br><span class="line"><span class="string">       参数2：移动窗口大小</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    data = pd.read_csv(row_data)</span><br><span class="line">    data[<span class="string">'mavg_temp'</span>] = round(data[<span class="string">'avg_temp'</span>].rolling(window).mean(),<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_fig</span><span class="params">(city_data,global_data)</span>:</span></span><br><span class="line">    <span class="string">"""将所在城市与全球平均气温数据绘制成折线图并展示</span></span><br><span class="line"><span class="string">       参数1：城市平均气温数据</span></span><br><span class="line"><span class="string">       参数2：全球平均气温数据</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">#设置显示的图片大小</span></span><br><span class="line">    figsize = <span class="number">10</span>,<span class="number">5</span> </span><br><span class="line">    figure, ax = plt.subplots(figsize=figsize) </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#X,Y轴的标签</span></span><br><span class="line">    plt.xlabel(<span class="string">'Year'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Moving Average Temperature (ºC)'</span>)</span><br><span class="line"></span><br><span class="line">    xmajorLocator   = MultipleLocator(<span class="number">20</span>) <span class="comment">#将x轴主刻度标签设置为20的倍数</span></span><br><span class="line">    xminorLocator   = MultipleLocator(<span class="number">5</span>) <span class="comment">#将x轴次刻度标签设置为5的倍数</span></span><br><span class="line">    ax.xaxis.set_major_locator(xmajorLocator)</span><br><span class="line">    ax.xaxis.set_minor_locator(xminorLocator)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    ymajorLocator   = MultipleLocator(<span class="number">1</span>) <span class="comment">#将y轴主刻度标签设置为1的倍数</span></span><br><span class="line">    yminorLocator   = MultipleLocator(<span class="number">0.2</span>) <span class="comment">#将y轴次刻度标签设置为0.2的倍数</span></span><br><span class="line">    ax.yaxis.set_major_locator(ymajorLocator)</span><br><span class="line">    ax.yaxis.set_minor_locator(yminorLocator)</span><br><span class="line">    </span><br><span class="line">    ax.xaxis.grid(<span class="keyword">True</span>, which=<span class="string">'major'</span>) <span class="comment">#x坐标轴的网格使用主刻度</span></span><br><span class="line">    ax.yaxis.grid(<span class="keyword">True</span>, which=<span class="string">'minor'</span>) <span class="comment">#y坐标轴的网格使用次刻度</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    plt.plot(city_data[<span class="string">'year'</span>],city_data[<span class="string">'mavg_temp'</span>],color=<span class="string">'skyblue'</span>,linewidth=<span class="string">'2'</span>,label=<span class="string">'Wuhan'</span>)</span><br><span class="line">    plt.plot(global_data[<span class="string">'year'</span>],global_data[<span class="string">'mavg_temp'</span>],color=<span class="string">'lightgreen'</span>,linewidth=<span class="string">'2'</span>,label=<span class="string">'Global'</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.title(<span class="string">'Temperature Trend'</span>)</span><br><span class="line"></span><br><span class="line">    plt.show() </span><br><span class="line"></span><br><span class="line">city_data_file = <span class="string">'data/avg_temp_wuhan_data.csv'</span></span><br><span class="line">global_data_file = <span class="string">'data/avg_temp_global_data.csv'</span></span><br><span class="line">window = <span class="number">10</span></span><br><span class="line">city_data = calculate_moving_average(city_data_file,window)</span><br><span class="line">global_data = calculate_moving_average(global_data_file,window)</span><br><span class="line"><span class="comment"># print(city_data)</span></span><br><span class="line"><span class="comment"># print(global_data)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(city_data[9:])</span></span><br><span class="line">city_data = city_data[<span class="number">9</span>:] <span class="comment">#计算移动均值后，武汉市数据表前9行没有数据，从1850年起-2013年，共164行，有平均气温数据</span></span><br><span class="line"><span class="comment"># print(global_data[100:-2])</span></span><br><span class="line">global_data = global_data[<span class="number">100</span>:<span class="number">-2</span>] <span class="comment">#故为了正确比较，全球平均气温数据也只取第100行(1850年)到倒数第二行(2013年)之间的164行数据</span></span><br><span class="line"></span><br><span class="line">show_fig(city_data,global_data)</span><br></pre></td></tr></table></figure></code></pre><p><img src="http://ipineimg.lijundong.com/18-11-26/34848843.jpg" alt="trend"></p><h3 id="问题与观察结论"><a href="#问题与观察结论" class="headerlink" title="问题与观察结论"></a>问题与观察结论</h3><h4 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h4><p>全球气温的整体趋势是怎么样的？本地城市呢？</p><p>从上图中可以看到整体上，从1841年起到2015年之间的70多年间，全球和武汉市的平均气温都是呈上升趋势。世界是真的越来越热了，经过这70多年，全球平均气温上升了1.6度左右，而武汉市上升了1.8度左右。武汉市比全球气温上涨幅度略大。</p><h4 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h4><p>与全球平均气温相比，本地城市平均气温比较热还是比较冷？长期气温差异是否一致？</p><p>可以很明显的看到，武汉市比全球更热，其平均气温比全球平均气温高出8度左右。不愧是中国的“四大火炉城市”之一呀！1841年的时候，武汉的平均气温是16.2度，比全球平均气温8度，高出8.2度，到了近几年，武汉市的平均气温升到18度，达到最高峰值，比全球平均气温最高峰值9.6度，高出8.4度。这说明，长期来看，武汉市和全球的气温差异是一致的。</p><h4 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h4><p>在这几十年间，全球的气温波动如何？本地城市呢？</p><p>全球的气温几乎是呈平稳上升趋势，但是到了最近几年，尤其是1980年之后，气温增长得越来越快，图形呈负偏斜分布；而武汉市的气温虽然整体上是上升的趋势，但是趋势波动很大，某个时间段内气温下降，之后再上升，图形呈多峰分布。</p><h4 id="Q4"><a href="#Q4" class="headerlink" title="Q4"></a>Q4</h4><p>哪个时间段内，武汉市与全球气温趋势的趋势最为相似？</p><p>通过图可以观察到1860年-1885年这25年间，武汉市与全球气温趋势最为相近。在这25年，武汉和全球气温都两次达到气温最低峰值。第一次出现在1862年左右，第二次出现在1885年，武汉市大概为15.8度，全球气温大概为7.8度。不知道在这个两个时间点发生了什么，温度出现了下降现象，但在1885年之后，无论是武汉还是全球，尽管气温有波动，但都没有再降到最低峰值。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/iPine/data_analysis_project_1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;代码传送门，包括扩展了交互功能的改进版&lt;/a&gt;&lt;/p&gt;
&lt;/bloc
      
    
    </summary>
    
      <category term="project" scheme="http://ipine.github.io/categories/project/"/>
    
    
      <category term="python" scheme="http://ipine.github.io/tags/python/"/>
    
      <category term="data_analysis" scheme="http://ipine.github.io/tags/data-analysis/"/>
    
  </entry>
  
  <entry>
    <title>散列表</title>
    <link href="http://ipine.github.io/2018-11-18/"/>
    <id>http://ipine.github.io/2018-11-18/</id>
    <published>2018-11-18T12:34:12.429Z</published>
    <updated>2019-02-22T11:27:59.834Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>Word有个拼写检查功能，一旦输入的英文单词有错，它就会在单词下方画上红色的波浪线。这个功能是如何实现的？</p><h3 id="散列表"><a href="#散列表" class="headerlink" title="散列表"></a>散列表</h3><p>散列表叫<code>Hash Table</code>，即<code>哈希表</code>或者<code>Hash</code>表。散列表用的是<strong>数组支持按照下标随机访问数据的特性</strong>，所以散列表其实是数组的一种扩展，由数组演化而来。如果没有数组，就没有散列表。</p><h4 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h4><p>假如有89名选手参加学校运动会，为了方便记录成绩，每个选手胸前都会贴上自己的参赛号码。这89名选手的编号依次是1到89。现在需要编程实现，通过编号快速找到对应选手信息。</p><p><strong>做法</strong>：将这89名选手的信息放在数组里，编号为1的选手，放在数组中下标为1的位置；编号为2的选手，放在数组中下标为2的位置。以此推类，编号为 <code>k</code> 的选手，放在数组中下标为 <code>k</code> 的位置。<br>当需要查询参赛编号为 <code>x</code> 的选手时，只需将下标为 <code>x</code> 的数组元素取出来就可以了，时间复杂为 <code>O(1)</code>。</p><p>这就是散列思想，其中，参赛选手的编号叫作<code>键（key）</code>或者<code>关键字</code>。把<strong>参赛编号转化为数组下标</strong>的映射方法就叫作<code>散列函数（哈希函数）</code>，散列函数计算得到的值就叫作<code>散列值（哈希值）</code>。</p><p>散列表用的是<strong>数组支持按照下标随机访问</strong>，时间复杂度是 <code>O(1)</code> 的特性。<br>通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。<br>当按照键值查询元素时，用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。</p><h3 id="散列函数"><a href="#散列函数" class="headerlink" title="散列函数"></a>散列函数</h3><p>散列函数在散列表中起着非常关键的作用。将其定义成 <code>hash(key)</code>，其中 <code>key</code> 表示元素的键值，<code>hash(key)</code>的值表示经过散列函数计算得到的散列值。<br>上个例子中，编号就是数组下标，所以<code>hash(key)</code>就等于<code>key</code>。</p><h4 id="散列函数设计的基本要求"><a href="#散列函数设计的基本要求" class="headerlink" title="散列函数设计的基本要求"></a>散列函数设计的基本要求</h4><p>1 . 散列函数计算得到的散列值是一个非负整数；<br>因为数组下标是从 0 开始的，所以散列函数生成的散列值也要是非负整数。</p><p>2 . 如果 <code>key1 = key2</code> ，那 <code>hash(key1) == hash(key2)</code>；<br>相同的 <code>key</code>，经过散列函数得到的散列值也应该是相同的。</p><p>3 . 如果 <code>key1 ≠ key2</code>，那 <code>hash(key1) ≠ hash(key2)</code>。<br>这个要求看起来合情合理，但是在真实的情况下，要想找到一个不同的 <code>key</code> 对应的散列值都不一样的散列函数，几乎是不可能的。即便像业界著名的<strong>MD5</strong>、<strong>SHA</strong>、<strong>CRC</strong>等哈希算法，也无法完全避免这种散列冲突。而且，因为<strong>数组的存储空间有限</strong>，也会加大散列冲突的概率。</p><p>几乎无法找到一个完美的无冲突的散列函数，即便能找到，付出的时间成本、计算成本也是很大的，所以针对散列冲突问题，需要通过其他途径来解决。</p><h3 id="散列冲突"><a href="#散列冲突" class="headerlink" title="散列冲突"></a>散列冲突</h3><p>常用的散列冲突解决方法有两类，<strong>开放寻址法（open addressing）</strong>和<strong>链表法（chaining）</strong>。</p><h4 id="开放寻址法"><a href="#开放寻址法" class="headerlink" title="开放寻址法"></a>开放寻址法</h4><p>开放寻址法的核心思想是，如果出现了散列冲突，就重新探测一个空闲位置，将其插入。那如何重新探测新的位置呢？<br>一个比较简单的探测方法，<code>线性探测（Linear Probing）</code>。</p><p>1 . 插入数据<br>当往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，那就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。</p><p>例如下图所示：<br><img src="http://ipineimg.lijundong.com/18-11-18/16695191.jpg" alt="插入数据"></p><p>黄色的块表示空闲，橙色的块表示已被存储数据。从图中可以看出，散列表的大小为 10，在元素 <code>x</code> 插入散列表之前，已经 6 个元素插入到散列表中。 <code>x</code> 经过 <code>Hash</code> 算法之后，被散列到位置下标为 7 的位置，但是这个位置已经有数据了，所以就产生了冲突。于是就顺序地往后一个一个找，看有没有空闲的位置，遍历到尾部都没有找到空闲的位置，只好再从表头开始找，直到找到空闲位置 2，于是将其插入到这个位置。</p><p>2 . 查找数据<br>在散列表中查找元素的过程有点儿类似插入过程。通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是要找的元素；否则就顺序往后依次查找。如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。</p><p>如下图所示：<br><img src="http://ipineimg.lijundong.com/18-11-18/23664537.jpg" alt="查找数据"></p><p>3 . 删除数据<br>对于使用线性探测法解决冲突的散列表，删除操作稍微有些特别，不能单纯地把要删除的元素设置为空。</p><p>在查找的时候，一旦通过线性探测方法，找到一个空闲位置，就可以认定散列表中不存在这个数据。<br>但是，如果这个空闲位置是后来删除的，就会导致原来的查找算法失效。本来存在的数据，会被认定为不存在。这个问题如何解决呢？</p><p>如下图所示：<br><img src="http://ipineimg.lijundong.com/18-11-18/89685434.jpg" alt="删除数据"></p><p>解决办法：<br>可以将删除的元素，特殊标记为 <code>deleted</code>。当线性探测查找的时候，遇到标记为 <code>deleted</code> 的空间，并不是停下来，而是继续往下探测。</p><h5 id="线性探测法的问题"><a href="#线性探测法的问题" class="headerlink" title="线性探测法的问题"></a>线性探测法的问题</h5><p>当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久。极端情况下，可能需要探测整个散列表，所以最坏情况下的时间复杂度为 <code>O(n)</code>。同理，在删除和查找时，也有可能会线性探测整张散列表，才能找到要查找或者删除的数据。</p><p>对于开放寻址冲突解决方法，除了线性探测方法之外，还有另外两种比较经典的探测方法，<strong>二次探测（Quadratic probing）</strong>和<strong>双重散列（Double hashing）</strong>。</p><p>二次探测，跟线性探测很像，线性探测每次探测的步长是 1，那它探测的下标序列就是<code>hash(key)+0，hash(key)+1，hash(key)+2</code>……而二次探测探测的步长就变成了原来的“二次方”，也就是说，它探测的下标序列就是 <code>hash(key)+0，hash(key)+1^2，hash(key)+2^2</code>……</p><p>双重散列，意思就是不仅要使用一个散列函数。而是使用一组散列函数 <code>hash1(key)，hash2(key)，hash3(key)</code>……先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。</p><p>为了尽可能保证散列表的操作效率，一般情况下，要尽可能保证散列表中有一定比例的空闲槽位。<br>用<strong>装载因子（load factor）</strong>来表示空位的多少。装载因子的计算公式是：</p><pre><code>散列表的装载因子 = 填入表中的元素个数 / 散列表的长度</code></pre><p>装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。</p><h4 id="链表法"><a href="#链表法" class="headerlink" title="链表法"></a>链表法</h4><p>链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。<br>在散列表中，每个<code>桶（bucket）</code>或者<code>槽（slot）</code>会对应一条链表，所有散列值相同的元素都放到相同槽位对应的链表中。</p><p>如下图所示：<br><img src="http://ipineimg.lijundong.com/18-11-18/86009483.jpg" alt="链表法"></p><p>当插入的时候，只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的时间复杂度是 <code>O(1)</code>。<br>当查找、删除一个元素时，同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除。</p><h5 id="查找或删除操作的时间复杂度"><a href="#查找或删除操作的时间复杂度" class="headerlink" title="查找或删除操作的时间复杂度"></a>查找或删除操作的时间复杂度</h5><p>两个操作的时间复杂度跟链表的长度 <code>k</code> 成正比，也就是 <code>O(k)</code>。<br>对于散列比较均匀的散列函数来说，理论上讲:</p><pre><code>k=n/m，其中 n 表示散列中数据的个数，m 表示散列表中“槽”的个数。</code></pre><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p>Word 文档中单词拼写检查功能是如何实现的？<br>用散列表来存储整个英文单词词典。<br>常用的英文单词有 20 万个左右，假设单词的平均长度是 10 个字母，平均一个单词占用 10 个字节的内存空间，那 20 万英文单词大约占 2MB 的存储空间，就算放大 10 倍也就是 20MB。对于现在的计算机来说，这个大小完全可以放在内存里面。</p><p>当用户输入某个英文单词时，拿用户输入的单词去散列表中查找。如果查到，则说明拼写正确；如果没有查到，则说明拼写可能有误，给予提示。借助散列表这种数据结构，就可以轻松实现快速判断是否存在拼写错误。</p><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>1 . 假设有 10 万条 URL 访问日志，如何按照访问次数给 URL 排序？<br>遍历 10 万条数据，以 URL 为 <code>key</code>，数组的下标为 <code>hash(key)</code>得到的值，访问次数count为相应数组下标的内容，存入散列表，同时记录下访问次数count的最大值 K，时间复杂度 <code>O(N)</code>。<br>如果 K 不是很大，可以使用<strong>桶排序</strong>，时间复杂度 <code>O(N)</code>。如果 K 非常大（比如大于 10 万），就使用<strong>快速排序</strong>，复杂度 <code>O(NlogN)</code>。</p><p>2 . 有两个字符串数组，每个数组大约有 10 万条字符串，如何快速找出两个数组中相同的字符串？<br>以第一个字符串数组构建散列表，<code>key</code> 为字符串，数组的下标为 <code>hash(key)</code>得到的值，出现次数count为相应数组下标的内容，时间复杂度为 <code>O(N)</code>。再遍历第二个字符串数组，以字符串为 <code>key</code> 在散列表中查找，找到散列值对应数组下标存储的count值，如果count大于零，说明存在相同字符串，时间复杂度为 <code>O(N)</code>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h3&gt;&lt;p&gt;Word有个拼写检查功能，一旦输入的英文单词有错，它就会在单词下方画上红色的波浪线。这个功能是如何实现的？&lt;/p&gt;
&lt;h3 id=&quot;散列表&quot;
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>跳表</title>
    <link href="http://ipine.github.io/2018-11-15/"/>
    <id>http://ipine.github.io/2018-11-15/</id>
    <published>2018-11-15T12:21:18.449Z</published>
    <updated>2019-02-22T11:27:57.867Z</updated>
    
    <content type="html"><![CDATA[<p>二分查找底层依赖的是<code>数组随机访问的特性</code>，所有只能用<strong>数组</strong>实现。<br>数据存储在链表中，通过改造链表，也可以支持类似<code>二分</code>的查找算法。这种改造之后的数据结构叫作<strong>跳表</strong>。<br>跳表是一种各方面性能都比较优秀的<code>动态数据结构</code>，可以支持快速的插入、删除、查找操作。</p><blockquote><p>可替代红黑树，代码实现比红黑树简单</p></blockquote><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>为什么 <a href="http://www.runoob.com/redis/redis-intro.html" target="_blank" rel="noopener">Redis</a> 会选择用跳表来实现有序集合？</p><h3 id="如何理解跳表"><a href="#如何理解跳表" class="headerlink" title="如何理解跳表"></a>如何理解跳表</h3><p>对于单链表，即便表中存储的数据是有序的，要在其中查找某个数据，也只能从头到尾遍历链表。查找的时间复杂度也很高，<code>O(n)</code>。</p><p>如何提高这个查找效率呢？<br>就是通过给链表建立<code>索引</code>，每两个结点提取一个结点到上一级，<strong>抽出来那一级叫作索引或索引层</strong>。上一级索引结点的有个 <code>down</code> 指针，指向下一级结点。</p><p>如图所示：<br><img src="http://ipineimg.lijundong.com/18-11-15/98683883.jpg" alt="建立索引"></p><p>加一层索引之后，查找一个结点需要遍历的结点个数减少了，即效率得到提高。不断地往上建立索引，查找效率的提升就会很多。</p><blockquote><p>这种链表加多级索引的结构，就是跳表。</p></blockquote><h3 id="跳表查询的时间复杂度"><a href="#跳表查询的时间复杂度" class="headerlink" title="跳表查询的时间复杂度"></a>跳表查询的时间复杂度</h3><p>按上面所说，<strong>每两个结点抽出一个结点</strong>作为上一级索引的结点，那第一级索引的结点个数大约就是 <code>n/2</code> ，第二级索引的结点个数大约就是 <code>n/4</code> ，第三级索引的结点个数大约就是 <code>n/8</code> ，依次类推，到了第 <code>k</code> 级索引的时候，结点个数是第 <code>k-1</code> 级索引的结点个数的 <code>1/2</code>， 即结点个数为 <code>n/(2^k)</code>。</p><p>假设索引有 <code>m</code> 级，最高级索引有<code>2</code>个结点。通过该公式，可以得到 <code>n/(2^m) = 2</code> ，<code>m=log2^n-1</code> 。如果包含原始链表这一层，整个跳表的高度就是 <code>log2^n</code> 。若每层需要遍历 <code>i</code> 个结点，那么在跳表中查询一个数据的时间复杂度就是 <code>O(i * logn)</code> 。</p><blockquote><p>i 的值在这里为3</p></blockquote><p><strong>原因</strong>：假设要查找的数据是 <code>x</code>，在第 <code>k</code> 级索引中，当遍历到 <code>y</code> 结点之后，发现 <code>x</code> 大于 <code>y</code>，小于后面的结点 <code>z</code>，所以就通过 <code>y</code> 的 <code>down</code> 指针，从第 <code>k</code> 级索引下降到第 <code>k-1</code> 级索引。在第 <code>k-1</code> 级索引中，<code>y</code> 和 <code>z</code> 之间只有 <strong>3 个结点（包含 y 和 z）</strong>，所以，在 <code>K-1</code> 级索引中最多只需要遍历 3 个结点，依次类推，每一级索引都最多只需要遍历 3 个结点。</p><p>如图所示：<br><img src="http://ipineimg.lijundong.com/18-11-15/37428961.jpg" alt="时间复杂度"></p><p>以上，跳表中查询任意数据的时间复杂度为 <code>O(logn)</code>。这个时间复杂度跟二分查找是一样的，但却是以<strong>空间换时间</strong>为代价。</p><h3 id="跳表的空间复杂度分析"><a href="#跳表的空间复杂度分析" class="headerlink" title="跳表的空间复杂度分析"></a>跳表的空间复杂度分析</h3><p>与纯粹的单链表相比，跳表需要存储多级索引，肯定需要消耗更多的存储空间。<br>假设原始链表大小为 <code>n</code>，那第一级索引大约有 <code>n/2</code> 个结点，第二级索引大约有 <code>n/4</code> 个结点，以此类推，每上升一级就减少一半，直到剩下 <code>2</code> 个结点。如果我们把每层索引的结点数写出来，就是一个等比数列。</p><p>原始链表大小为 <code>n</code> ,<strong>每2个结点抽取1个为索引</strong>，每层索引的结点数：</p><pre><code>n/2, n/4, n/8, ..., 8, 4, 2</code></pre><p>这几级索引的结点总和就是 <code>n/2+n/4+n/8…+8+4+2=n-2</code> 。所以，跳表的空间复杂度是 <code>O(n)</code>。也就是说，如果将包含 <code>n</code> 个结点的单链表构造成跳表，需要额外再用接近 <code>n</code> 个结点的存储空间。</p><h4 id="降低索引占用的内存空间"><a href="#降低索引占用的内存空间" class="headerlink" title="降低索引占用的内存空间"></a>降低索引占用的内存空间</h4><p>如果每三个结点，抽一个结点到上级索引，那么第一级索引需要大约 <code>n/3</code> 个结点，第二级索引需要大约 <code>n/9</code> 个结点。每往上一级，索引结点个数都除以 3。为了方便计算，假设最高一级的索引结点个数是 1。每级索引的结点个数相加，也是一个等比数列求和。</p><p>原始链表大小为 <code>n</code> ,<strong>每3个结点抽取1个为索引</strong>，每层索引的结点数：</p><pre><code>n/3, n/9, n/27, ..., 9, 3, 1</code></pre><p>通过等比数列求和公式，总的索引结点大约就是 <code>n/3+n/9+n/27+…+9+3+1=n/2</code> 。尽管空间复杂度还是 <code>O(n)</code>，但比上面的每两个结点抽一个结点的索引构建方法，要减少了一半的索引结点存储空间。</p><blockquote><p>实际上，在软件开发中，不必太在意索引占用的额外空间。<br>在实际的软件开发中，原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值和几个指针，并不需要存储对象，所以当对象比索引结点大很多时，那索引占用的额外空间就可以忽略。</p></blockquote><h3 id="高效的动态插入和删除"><a href="#高效的动态插入和删除" class="headerlink" title="高效的动态插入和删除"></a>高效的动态插入和删除</h3><p>跳表，不仅支持查找操作，还支持动态的插入、删除操作，而且插入、删除操作的时间复杂度也是 <code>O(logn)</code>。</p><h4 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h4><p>在单链表中，一旦定位好要插入的位置，插入结点的时间复杂度是很低的，就是 <code>O(1)</code>。但是，为了保证原始链表中数据的有序性，是需要先找到要插入的位置，这个查找操作就会比较耗时。</p><p>对于纯粹的单链表，需要遍历每个结点，来找到插入的位置。但是，对于跳表来说，查找某个结点的的时间复杂度是 <code>O(logn)</code>，所以查找某个数据应该插入的位置，方法也是类似的，时间复杂度也是 <code>O(logn)</code>。</p><h4 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h4><p>如果要删除的结点在索引中也有出现，那么除了要删除原始链表中的结点，还要删除索引中的。因为单链表中的删除操作需要拿到要删除结点的前驱结点，然后通过指针操作完成删除。所以在查找要删除的结点的时候，一定要获取前驱结点。当然，如果用的是双向链表，就不需要考虑这个问题了。</p><h3 id="跳表索引动态更新"><a href="#跳表索引动态更新" class="headerlink" title="跳表索引动态更新"></a>跳表索引动态更新</h3><p>当数据不断地被插入到跳表中，如果索引不更新，就有可能出现某2个索引结点之间数据非常多的情况，极端情况下，跳表就会退化成单链表。<br>作为一种动态数据结构，需要用某种手段来维护索引与原始链表大小之间的平衡，也就是说，如果链表中结点多了，索引结点就相应地增加一些，避免复杂度退化，以及查找、插入、删除操作性能下降。<br>跳表是通过<strong>随机函数</strong>来维护前面提到的<code>平衡性</code>。<br>当往跳表中插入数据的时候，可以选择同时将这个数据插入到部分索引层中。</p><h4 id="如何选择加入哪些索引层呢？"><a href="#如何选择加入哪些索引层呢？" class="headerlink" title="如何选择加入哪些索引层呢？"></a>如何选择加入哪些索引层呢？</h4><p>通过一个随机函数，来决定将这个结点插入到哪几级索引中，比如随机函数生成了值 <code>K</code> ，那就将这个结点添加到第一级到第 <code>K</code> 级，总共 <code>K</code> 级索引中。</p><blockquote><p>随机函数的选择很有讲究，从概率上来讲，能够保证跳表的索引大小和数据大小平衡性，不至于性能过度退化。</p></blockquote><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p><code>Redis</code> 中的有序集合是通过跳表来实现的，严格点讲，其实还用到了<code>散列表</code>。<br><code>Redis</code> 中的有序集合支持的核心操作主要有下面这几个：</p><ul><li>插入一个数据；</li><li>删除一个数据；</li><li>查找一个数据；</li><li>按照区间查找数据（比如查找值在 [100, 356] 之间的数据）；</li><li>迭代输出有序序列。</li></ul><h4 id="为什么选择跳表而不是红黑树实现有序集合？"><a href="#为什么选择跳表而不是红黑树实现有序集合？" class="headerlink" title="为什么选择跳表而不是红黑树实现有序集合？"></a>为什么选择跳表而不是红黑树实现有序集合？</h4><ul><li><p>原因1：对于插入、删除、查找以及迭代输出有序序列这几个操作，红黑树的完成时间复杂度跟跳表一样；而按照区间来查找数据这个操作，红黑树的效率没有跳表高。<br>对于按照区间查找数据这个操作，跳表可以做到 <code>O(logn)</code> 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了。</p></li><li><p>原因2：跳表代码实现更容易。虽然跳表的实现也不简单，但比起红黑树来说还是相对容易一些。跳表也更加灵活，它可以通过改变索引构建策略，有效平衡执行效率和内存消耗。</p></li></ul><p>不过，跳表也不能完全替代红黑树。因为红黑树比跳表的出现要早一些，很多编程语言中的 <code>Map</code> 类型都是通过红黑树来实现的。业务开发的时候，直接拿来用就可以了，不用自己去实现一个红黑树，但是跳表并没有一个现成的实现，所以在开发中，如果想使用跳表，必须要自己实现。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;二分查找底层依赖的是&lt;code&gt;数组随机访问的特性&lt;/code&gt;，所有只能用&lt;strong&gt;数组&lt;/strong&gt;实现。&lt;br&gt;数据存储在链表中，通过改造链表，也可以支持类似&lt;code&gt;二分&lt;/code&gt;的查找算法。这种改造之后的数据结构叫作&lt;strong&gt;跳表&lt;/stro
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>二分查找</title>
    <link href="http://ipine.github.io/2018-11-09/"/>
    <id>http://ipine.github.io/2018-11-09/</id>
    <published>2018-11-10T10:47:07.235Z</published>
    <updated>2019-02-22T11:27:56.156Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>通过IP地址可用查找到IP归属地。在百度搜索框里，随便输入一个IP地址，就会看到它的归属地。<br>这个功能是通过维护一个很大的IP地址库来实现的，地址库中包括IP地址范围和归属地的对应关系。<br>问题是，如果有12万条这样的IP区间与归属地的对应关系，如何快速定位出一个IP地址的归属地呢？</p><h3 id="二分查找的变形"><a href="#二分查找的变形" class="headerlink" title="二分查找的变形"></a>二分查找的变形</h3><p>二分查找中最简单的一种情况，是在不存在重复元素的有序数组中，查找值等于给定值的元素。最简单的二分查找比较容易，但是，二分查找的变形问题就没那么好写了。</p><blockquote><p>特别说明：假设要处理的数据是从小到大排列为前提，如果要处理的数据是从大到小排列的，解决思路也是一样的。</p></blockquote><h3 id="几个典型的变形问题"><a href="#几个典型的变形问题" class="headerlink" title="几个典型的变形问题"></a>几个典型的变形问题</h3><h4 id="查找第一个值等于给定值的元素"><a href="#查找第一个值等于给定值的元素" class="headerlink" title="查找第一个值等于给定值的元素"></a>查找第一个值等于给定值的元素</h4><p>有序数据集合中存在重复的数据，找到第一个值等于给定值的数据。比如，有以下这样一个有序数组，希望找到第一个等于8的数据位置，即下标为5的8.</p><pre><code>a[10]   1 3 4 5 6 8 8 8 11 19        0 1 2 3 4 5 6 7  8  9</code></pre><p>若用之前的二分查找代码实现，首先拿 8 与区间的中间值 <code>a[4]</code> 比较，8 比 6 大，于是在下标 5 到 9 之间继续查找。下标 5 和 9 的中间位置是下标 7，<code>a[7]</code> 正好等于 8，所以代码就返回了。<br>尽管 <code>a[7]</code> 等于 8，但它并不是要找的第一个等于 8 的元素，因为第一个值等于 8 的元素是数组下标为 5 的元素。</p><h5 id="正确的代码"><a href="#正确的代码" class="headerlink" title="正确的代码"></a>正确的代码</h5><pre><code>def binary_search_variant1(arr,ele):    length = len(arr)    low = 0    high = length - 1    while low &lt;= high:        mid = low + ((high-low)&gt;&gt;1)        if arr[mid] &gt; ele:            high = mid -1        elif arr[mid] &lt; ele:            low = mid + 1        else:            if mid == 0 or arr[mid-1] != ele:                return mid            high = mid-1    return -1</code></pre><h5 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h5><p>重点在于：当 <code>a[mid] = ele</code> 时，该如何处理？如果查找的是任意一个值等于给定值的元素，当 <code>a[mid]</code> 等于要查找的值时，<code>a[mid]</code> 就是要找的元素。但是，求解的是第一个值等于给定值的元素，当 <code>a[mid]</code> 等于要查找的值时，还需要确认一下这个 <code>a[mid]</code> 是不是第一个值等于给定值的元素。<br>如果 <code>mid</code> 等于 0，那这个元素已经是数组的第一个元素，那它肯定是正确的；如果 <code>mid</code> 不等于 0，但 <code>a[mid]</code> 的前一个元素 <code>a[mid-1]</code> 不等于 <code>ele</code>，那也说明 <code>a[mid]</code> 就是要找的第一个值等于给定值的元素。<br>如果经过检查之后发现 <code>a[mid]</code> 前面的一个元素 <code>a[mid-1]</code> 也等于 <code>ele</code>，那说明此时的 <code>a[mid]</code> 肯定不是要查找的第一个值等于给定值的元素。那就更新 <code>high=mid-1</code>，因为要找的元素肯定出现在 <code>[low, mid-1]</code> 之间。</p><h4 id="查找最后一个值等于给定值的元素"><a href="#查找最后一个值等于给定值的元素" class="headerlink" title="查找最后一个值等于给定值的元素"></a>查找最后一个值等于给定值的元素</h4><p>理解上一个变体的做法，对于查找最后一个值等于给定值的元素，就很好做了。</p><h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><pre><code>def binary_search_variant2(arr,ele):    length = len(arr)    low = 0    high = length - 1    while low &lt;= high:        mid = low + ((high-low)&gt;&gt;1)        if arr[mid] &gt; ele:            high = mid -1        elif arr[mid] &lt; ele:            low = mid + 1        else:            if mid == (length-1) or arr[mid+1] != ele:                return mid            low = mid+1    return -1</code></pre><h5 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h5><p>如果 <code>a[mid]</code> 这个元素已经是数组中的最后一个元素了，那它肯定是正确的；如果 <code>[mid]</code> 的后一个元素 <code>a[mid+1]</code> 不等于 <code>ele</code>，那也说明 <code>a[mid]</code> 就是要找的最后一个值等于给定值的元素。</p><p>如果经过检查之后，发现 <code>a[mid]</code> 后面的一个元素 <code>a[mid+1]</code> 也等于 <code>ele</code>，那说明当前的这个 <code>a[mid]</code> 并不是最后一个值等于给定值的元素。那就更新 <code>low=mid+1</code>，因为要找的元素肯定出现在 <code>[mid+1, high]</code> 之间。</p><h4 id="找第一个大于等于给定值的元素"><a href="#找第一个大于等于给定值的元素" class="headerlink" title="找第一个大于等于给定值的元素"></a>找第一个大于等于给定值的元素</h4><p>第三类变形问题。在有序数组中，查找第一个大于等于给定值的元素。<br>比如，数组中存储的这样一个序列：<code>3，4，6，7，10</code>。如果查找第一个大于等于 5 的元素，那就是 6。</p><h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><pre><code>def binary_search_variant3(arr,ele):    length = len(arr)    low = 0    high = length - 1    while low &lt;= high:        mid = low + ((high-low)&gt;&gt;1)        if arr[mid] &gt;= ele:            if mid == 0 or arr[mid-1] &lt; ele:                return mid            high = mid - 1        else:            low = mid + 1    return -1</code></pre><h5 id="分析-2"><a href="#分析-2" class="headerlink" title="分析"></a>分析</h5><p>如果 <code>a[mid]</code> 小于要查找的值 <code>ele</code>，那要查找的值肯定在 <code>[mid+1, high]</code> 之间，所以，更新 <code>low=mid+1</code>。<br>对于 <code>a[mid]</code> 大于等于给定值 <code>ele</code> 的情况，要确认这个 <code>a[mid]</code> 是不是要找的第一个值大于等于给定值的元素。如果 <code>a[mid]</code> 前面已经没有元素，或者前面一个元素小于要查找的值 <code>ele</code>，那 <code>a[mid]</code> 就是要找的元素。<br>如果 <code>a[mid-1]</code> 也大于等于要查找的值 <code>ele</code>，那说明要查找的元素在 <code>[low, mid-1]</code> 之间，所以，将 <code>high</code> 更新为 <code>mid-1</code>。</p><h4 id="查找最后一个小于等于给定值的元素"><a href="#查找最后一个小于等于给定值的元素" class="headerlink" title="查找最后一个小于等于给定值的元素"></a>查找最后一个小于等于给定值的元素</h4><p>查找最后一个小于等于给定值的元素。<br>比如，数组中存储了这样一组数据：<code>3，5，6，8，9，10</code>。最后一个小于等于 7 的元素就是 6。</p><h5 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h5><pre><code>def binary_search_variant4(arr,ele):    length = len(arr)    low = 0    high = length - 1    while low &lt;= high:        mid = low + ((high-low)&gt;&gt;1)        if arr[mid] &lt;= ele:            if mid == (length-1) or arr[mid+1] &gt; ele:                return mid            low = mid + 1        else:            high = mid - 1    return -1</code></pre><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p>如何快速定位出一个 IP 地址的归属地？</p><p>如果 IP 区间与归属地的对应关系不经常更新，就可以先预处理这 12 万条数据，让其按照起始 IP 从小到大排序。<br>IP 地址可以转化为 32 位的整型数。所以，可以将起始地址，按照对应的整型值的大小关系，从小到大进行排序。<br>然后，这个问题就可以<strong>转化为第四种变形问题</strong>“在有序数组中，查找最后一个小于等于某个给定值的元素”了。</p><p>当要查询某个 IP 归属地时，可以先通过二分查找，找到最后一个起始 IP 小于等于这个 IP 的 IP 区间，然后，检查这个 IP 是否在这个 IP 区间内，如果在，就取出对应的归属地显示；如果不在，就返回未查找到。</p><h3 id="Key"><a href="#Key" class="headerlink" title="Key"></a>Key</h3><p>凡是用二分查找能解决的问题，绝大部分更倾向于用<code>散列表</code>或者<code>二叉查找树</code>。即便是二分查找在内存使用上更节省，但是毕竟内存如此紧缺的情况并不多。</p><p>实际上，求“值等于给定值”的二分查找确实不怎么会被用到，二分查找<strong>更适合用在“近似”查找问题</strong>，在这类问题上，二分查找的优势更加明显。比如上面的几种变体问题，用其他数据结构，比如散列表、二叉树，就比较难实现了。<br>变体的二分查找算法写的时候容易因为细节处理不好而产生 Bug，这些容易出错的细节有：<strong>终止条件</strong>、<strong>区间上下界更新方法</strong>、<strong>返回值选择</strong>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h3&gt;&lt;p&gt;通过IP地址可用查找到IP归属地。在百度搜索框里，随便输入一个IP地址，就会看到它的归属地。&lt;br&gt;这个功能是通过维护一个很大的IP地址库来
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>二分查找</title>
    <link href="http://ipine.github.io/2018-11-08/"/>
    <id>http://ipine.github.io/2018-11-08/</id>
    <published>2018-11-08T07:00:00.000Z</published>
    <updated>2019-02-22T11:27:54.297Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>假设有1000万个整数数据，每个数据占8字节，<strong>如何设计数据结构和算法，快速判断某个整数是否出现在1000万数据中？（存在多次查找的情况）</strong></p><blockquote><p>前提：该功能不要太占用内存空间，最好不超过100MB</p></blockquote><h3 id="二分查找思想"><a href="#二分查找思想" class="headerlink" title="二分查找思想"></a>二分查找思想</h3><h4 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h4><p>生活中的“猜数字大小”游戏，猜的过程中，玩家每猜一次，庄家告诉你是猜大了还是猜小了，直到猜中为止。最快速猜中的方法就是用二分查找的思想。每次说猜测范围的中间数字，如果中间数有两个，则选择较小的那个。按照这个思想，这样即使猜的数字范围在0-999，最多也只要10次就能猜中。</p><p>二分查找针对的是一个<code>有序的整数集合</code>，查找思想类似于分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为0。</p><h3 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h3><p>二分查找是一种非常高效的查找算法。<br>假设数据大小是 <code>n</code>，每次查找后数据都会缩小为原来的一半，也就是会除以 2。最坏情况下，直到查找区间被缩小为空，才停止。</p><pre><code>被查找区间的大小变化：n, n/2, 2/4, n/8, ... n/2^k</code></pre><p>这是一个等比数列，其中 <code>n/2^k=1</code> 时， <code>k</code> 的值就是总共缩小的次数，每次缩小操作只涉及两个数据的大小比较，所以，经过 <code>k</code> 次区间缩小操作，时间复杂度为 <code>O(k)</code>。通过 <code>n/2^k=1</code>， 可以求得 <code>k = log2^n</code> ，所以时间复杂度就是 <code>O(logn)</code>。</p><h3 id="O-logn-对数时间复杂度"><a href="#O-logn-对数时间复杂度" class="headerlink" title="O(logn) 对数时间复杂度"></a><code>O(logn)</code> 对数时间复杂度</h3><p>这是一种极其高效的时间复杂度，有的时候甚至比时间复杂度是常量级 <code>O(1)</code> 的算法还要高效。<br>为什么这么说呢？<br>因为 <code>logn</code> 是一个非常“恐怖”的数量级，即便 <code>n</code> 非常非常大，对应的 <code>logn</code> 也很小。比如 <code>n</code> 等于 2 的 32 次方，<code>n</code> 大约是 42 亿。也就是说，如果我们在 <strong>42 亿</strong>个数据中用二分查找一个数据，最多需要比较 <strong>32</strong> 次。</p><blockquote><p>在用大 O 标记法表示时间复杂度的时候，会省略掉常数、系数和低阶。</p></blockquote><p>对于常量级时间复杂度的算法来说，<code>O(1)</code> 有可能表示的是一个非常大的常量值，比如 <code>O(1000)</code>、<code>O(10000)</code>。所以，常量级时间复杂度的算法有时候可能还没有 <code>O(logn)</code> 的算法执行效率高。<br>反过来，对数相对的就是指数。这也是为什么，指数时间复杂度的算法在大规模数据面前是无效的。</p><h3 id="简单二分查找的递归与非递归实现"><a href="#简单二分查找的递归与非递归实现" class="headerlink" title="简单二分查找的递归与非递归实现"></a>简单二分查找的递归与非递归实现</h3><p>简单二分查找，是指在<strong>不存在重复元素</strong>的<strong>有序数据</strong>中查找值等于给定值的数据。</p><h4 id="非递归代码"><a href="#非递归代码" class="headerlink" title="非递归代码"></a>非递归代码</h4><pre><code>def binary_search(arr, ele):    lenght = len(arr)    low = 0    high = length -1    while low &lt;= high:        mid = (low + high) // 2  # low + (high-low)&gt;&gt;1        if arr[mid] == ele:            return mid        elif arr[mid] &gt; ele:            high = mid - 1        else:            low = mid + 1    return -1</code></pre><h4 id="提示点"><a href="#提示点" class="headerlink" title="提示点"></a>提示点</h4><p>1 . 循环退出条件。是 <code>low &lt;= high</code>，而不是 <code>low &lt; high</code></p><p>2 . <code>mid</code> 的取值。实际上，<code>mid=(low+high)//2</code> 这种写法有问题。因为如果 <code>low</code> 和 <code>high</code> 比较大的话，两者之和就有可能会溢出。改进的方法是将 <code>mid</code> 的计算方式写成 <code>low+(high-low)//2</code>。更进一步，可以将这里的除以 2 操作转化成位运算 <code>low+(high-low) &gt;&gt;1</code>。因为相比除法运算来说，计算机处理位运算要快得多。</p><p>3 . <code>low</code> 和 <code>high</code> 的更新。 <code>low=mid+1</code>，<code>high=mid-1</code>。注意这里的 +1 和 -1，如果直接写成 <code>low=mid</code> 或者 <code>high=mid</code>，就可能会发生<strong>死循环</strong>。</p><blockquote><p>比如，当 high=3，low=3 时，如果 arr[3] 不等于 ele，就会导致一直循环不退出。</p></blockquote><h4 id="递归代码"><a href="#递归代码" class="headerlink" title="递归代码"></a>递归代码</h4><pre><code>def binary_search(arr, low, high, ele):    if low &gt; high:        return -1    mid = low + (high-low) // 2    if arr[mid] == ele:        return mid    elif arr[mid] &gt; ele:        return binary_search(arr, low, mid-1, ele)    else:        return binary_search(arr, mid+1, high, ele)</code></pre><h3 id="应用场景的局限性"><a href="#应用场景的局限性" class="headerlink" title="应用场景的局限性"></a>应用场景的局限性</h3><p>二分查找的时间复杂度是 <code>O(logn)</code>，查找数据的效率非常高。不过，并不是什么情况下都可以用二分查找，它的应用场景有很大局限性。</p><p>1 . 二分查找依赖的是<strong>顺序表结构</strong>，即<strong>数组</strong>。 二分查找不能依赖于其他数据结构，比如链表。主要原因是二分查找算法需要按照下标随机访问元素。数组按照下标随机访问数据的时间复杂度是 <code>O(1)</code>，而链表随机访问的时间复杂度是 <code>O(n)</code>。所以，如果数据使用链表存储，二分查找的时间复杂就会变得很高。</p><p>2 . 二分查找针对的是<strong>有序数据</strong>。如果数据没有序，需要先排序。排序的时间复杂度最低是 <code>O(nlogn)</code>。所以，如果针对的是一组静态的数据，没有频繁地插入、删除，就可以进行一次排序，多次二分查找。这样排序的成本可被均摊，二分查找的边际成本就会比较低。<br>针对有频繁插入、删除操作的这种动态数据集合，二分查找是不适用的。要用二分查找，要么每次插入、删除操作之后保证数据仍然有序，要么在每次二分查找之前都先进行排序。针对这种动态数据集合，无论哪种方法，维护有序的成本都很高。</p><p>3 . <strong>数据量太小</strong>不适合二分查找。如果要处理的数据量很小，完全没有必要用二分查找，顺序遍历就足够了。比如在一个大小为 10 的数组中查找一个元素，不管用二分查找还是顺序遍历，查找速度都差不多。只有数据量比较大的时候，二分查找的优势才会比较明显。</p><blockquote><p>有一个例外。如果数据之间的比较操作非常耗时，不管数据量大小，都推荐使用二分查找。比如，数组中存储的都是长度超过几百的字符串，如此长的两个字符串之间比大小，就会非常耗时。为了尽可能地减少比较次数，二分查找就比顺序遍历更有优势。</p></blockquote><p>4 . <strong>数据量太大</strong>也不适合二分查找。二分查找依赖的是数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间连续，对内存的要求比较苛刻。二分查找是作用在数组这种数据结构之上的，所以太大的数据用数组存储就比较困难，就不能用二分查找了。</p><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p>如何快速判断某个整数是否出现在在<code>1000万</code>数据中？<br>内存限制是 <code>100MB</code>，每个数据大小是 <code>8</code> 字节，最简单的办法就是将数据存储在数组中，内存占用差不多是 <code>80MB</code> ，符合内存的限制。<br>先对这 1000 万数据从小到大排序，然后再利用二分查找算法，就可以快速地查找想要的数据。</p><blockquote><p>散列表、二叉树这些支持快速查找的动态数据结构也可以解决这类问题。但因为内存的限制，使得这些方法在这里行不通。</p></blockquote><p>虽然大部分情况下，用二分查找可以解决的问题，用散列表、二叉树都可以解决。但是，不管是散列表还是二叉树，都会需要比较多的额外的内存空间。如果用散列表或者二叉树来存储这 <code>1000万</code> 的数据，用 <code>100MB</code> 的内存肯定是存不下的。而二分查找底层依赖的是数组，除了数据本身之外，不需要额外存储其他信息，是最省内存空间的存储方式，所以刚好能在限定的内存大小下解决这个问题。</p><h3 id="Key"><a href="#Key" class="headerlink" title="Key"></a>Key</h3><p>1 . 若二分查找依赖于链表结构，时间复杂度如何分析？<br>假设链表长度为 n，二分查找每次需要找到中间点，那么总共需要移动的指针次数为：</p><pre><code>n/2 + n/4 + n/8 + ... + 1</code></pre><p>这也是一个等比数列，根据等比数列求和公式 <code>(S = (a1-an*q)/1-q, q为公比, 且不为1)</code>，其和等于 <code>n-1</code> 。所有最后算法时间复杂度为 <code>O(n)</code>。<br>时间复杂度和顺序查找时间复杂度相同，但是，在二分查找的时候，由于要进行多余的运算，严格来说，会比顺序查找时间慢。</p><p>2 . 用二分查找“求一个数的平方根”，要求精确到小数点后6位（类似于LeetCode 69题）</p><pre><code>def mySqrt(self, x):        if x==0 or x==1:            return x        low = 0        high = max(x,1.0)        #high = x        mid = (low + high)/2.0        while abs(mid**2 - x) &gt; 1e-6:            if mid**2 &gt; x:                high = mid            else:                low = mid            mid = (low + high)/2.0        return mid</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题&quot;&gt;&lt;a href=&quot;#问题&quot; class=&quot;headerlink&quot; title=&quot;问题&quot;&gt;&lt;/a&gt;问题&lt;/h3&gt;&lt;p&gt;假设有1000万个整数数据，每个数据占8字节，&lt;strong&gt;如何设计数据结构和算法，快速判断某个整数是否出现在1000万数据中？（存在多次
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>排序</title>
    <link href="http://ipine.github.io/2018-11-04/"/>
    <id>http://ipine.github.io/2018-11-04/</id>
    <published>2018-11-04T12:56:00.000Z</published>
    <updated>2019-02-22T11:27:52.854Z</updated>
    
    <content type="html"><![CDATA[<p>主要内容，总结前面的几种算法在各方面的性能。</p><h3 id="如何选择合适的排序算法？"><a href="#如何选择合适的排序算法？" class="headerlink" title="如何选择合适的排序算法？"></a>如何选择合适的排序算法？</h3><p>总结前面几种主要排序算法的性能差异。一些算法在一些指标上达到最优情况，还有一些算法的复杂度虽然相同，但在实践中的表现却有差异。<br>最理想的排序算法是 <strong><code>O(n logn)</code> 时间</strong>、<strong><code>O(1)</code>空间</strong>、<strong>稳定</strong>、最好还<strong>具有适应性</strong>。当然目前，还没找到这种算法。</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">最坏时间复杂度</th><th style="text-align:center">平均时间复杂度</th><th style="text-align:center">最好时间复杂度</th><th style="text-align:center">是否稳定</th><th style="text-align:center">是否是原地排序</th><th style="text-align:center">适应性</th></tr></thead><tbody><tr><td style="text-align:center">冒泡排序</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(n)</td><td style="text-align:center">是</td><td style="text-align:center">是</td><td style="text-align:center">是</td></tr><tr><td style="text-align:center">插入排序</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(n)</td><td style="text-align:center">是</td><td style="text-align:center">是</td><td style="text-align:center">是</td></tr><tr><td style="text-align:center">选择排序</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">否</td><td style="text-align:center">是</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">快速排序</td><td style="text-align:center">O(n^2)</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">否</td><td style="text-align:center">是</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">归并排序</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">是</td><td style="text-align:center">否</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">计数排序</td><td style="text-align:center">O(n+k)</td><td style="text-align:center">O(n+k)</td><td style="text-align:center">O(n+k)</td><td style="text-align:center">是</td><td style="text-align:center">否</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">桶排序</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">O(n)</td><td style="text-align:center">O(n)</td><td style="text-align:center">是</td><td style="text-align:center">否</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">基数排序</td><td style="text-align:center">O(k*n)</td><td style="text-align:center">O(k*n)</td><td style="text-align:center">O(k*n)</td><td style="text-align:center">是</td><td style="text-align:center">否</td><td style="text-align:center">否</td></tr></tbody></table><h3 id="适用情况比较"><a href="#适用情况比较" class="headerlink" title="适用情况比较"></a>适用情况比较</h3><p>1 . 三个线性排序算法的时间复杂度低，但是适用场景特殊，所以通用的排序函数，不选择线性排序算法。<br>2 . 对小规模数据进行排序，可以选择时间复杂度是 <code>O(n2)</code> 的算法，如，<strong>冒泡排序</strong>和<strong>插入排序</strong>；<br>3 . 对大规模数据进行排序，选择时间复杂度是 <code>O(nlogn)</code> 的算法更加高效。</p><p>所以，为了兼顾任意规模数据的排序，一般都会首选时间复杂度是 <code>O(nlogn)</code> 的排序算法来实现排序函数。<br>时间复杂度为<code>O(nlogn)</code>的排序算法，目前有两个，快速排序和归并排序</p><h3 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h3><p>快速排序适合来实现通用的排序函数，但是，快速排序在最坏情况下的时间复杂度是 <code>O(n^2)</code>。</p><h4 id="为什么最坏情况下快排的时间复杂度是-O-n-2-呢？"><a href="#为什么最坏情况下快排的时间复杂度是-O-n-2-呢？" class="headerlink" title="为什么最坏情况下快排的时间复杂度是 O(n^2)呢？"></a>为什么最坏情况下快排的时间复杂度是 <code>O(n^2)</code>呢？</h4><p>如果要排序的数据原来就是有序的或者接近有序的，而每次分区点都选择最后一个数据，那快排的性能就很不好，这时时间复杂度就为 <code>O(n^2)</code>。所以，这种 <code>O(n^2)</code> 时间复杂度出现的主要原因是因为<strong>分区点选择不够合理</strong>。</p><p><strong>最理想的分区点是</strong>：被分区点分开的两个分区中，数据的数量差不多。若直接选择第一个或最后一个数据作为分区点，不考虑数据的特点，肯定就会出现最坏情况的时间复杂度。</p><h4 id="几种常用的分区算法"><a href="#几种常用的分区算法" class="headerlink" title="几种常用的分区算法"></a>几种常用的分区算法</h4><p>1 . 三数取中法<br>从区间的首、尾、中间，分别取出一个数，然后对比这三个数的大小，取3数中的中间值作为分区点。每间隔某个固定的长度，取数据出来比较，将中间值作为分区点。这种思路肯定比单纯取某一个数据更好，但是，如果要排序的数组比较大，那“三数取中”可能就不够，需要扩大范围，“五数取中”或者“十数取中”。</p><p>2 . 随机法<br>随机法是每次从要排序的区间中，随机选择一个元素作为分区点。这种方法并不能保证每次分区点都选的比较好，但是从概率的角度来看，也不大可能会出现每次分区点都选的很差的情况，所以平均情况下，这样选的分区点是比较好的。时间复杂度退化为最糟糕的 <code>O(n^2)</code> 的情况，出现的可能性不大。</p><p>快速排序用<code>递归实现</code>。递归需要警惕<code>堆栈溢出</code>。为了避免快速排序里，递归过深而堆栈过小，导致堆栈溢出，有两种解决办法：第一种是<strong>限制递归深度</strong>。一旦递归过深，超过了事先设定的阈值，就停止递归。第二种是通过在<strong>堆上模拟实现一个函数调用栈</strong>，手动模拟递归压栈、出栈的过程，这样就没有了系统栈大小的限制。</p><h3 id="举例分析排序函数"><a href="#举例分析排序函数" class="headerlink" title="举例分析排序函数"></a>举例分析排序函数</h3><p>实际排序程序会采用多种算法的组合，即<code>混成方法</code>。<br>在一些复杂排序算法里，也需要处理较短序列的排序问题。快排和归并排序就是这方面的典型：</p><ul><li><p>快速排序算法中，序列被划分为越来越短的片段。若序列已经很短，例如短于几个元素，快排还需要做几次递归调用（进栈、出栈）。这些赋值操作很耗时，<strong>表现在复杂度度描述中忽略了的常量因子</strong>。对于很短的序列，<strong>采用插入排序，效果很可能优于快速排序</strong>。</p></li><li><p>归并排序正好与快排相反，是从短的有序序列归并出越来越长的序列。从很多个各自包含一个元素的序列出发，通过几遍归并得到最终的有序序列，这其中需要做许多函数调用工作。与这几个元素做简单插入排序相比，归并排序消耗时间会更多。</p></li></ul><p>在实际程序里的排序功能，特别是各自程序库里的排序函数，通常不是纯粹第采用一种算法，而是使用两种或两种以上方法的组合。常见的是<strong>归并排序和插入排序的组合</strong>，以及<strong>快速排序和插入排序的组合</strong>。</p><h4 id="Python的内置排序算法"><a href="#Python的内置排序算法" class="headerlink" title="Python的内置排序算法"></a>Python的内置排序算法</h4><p>Python中的内置<code>排序函数 sort</code> 和<code>表list类的对象的sort方法</code>，两者共享同一个排序算法，是一种混成排序算法，叫作 <strong>Timsort(蒂姆排序)</strong>。</p><h5 id="基本情况"><a href="#基本情况" class="headerlink" title="基本情况"></a>基本情况</h5><p>蒂姆排序是一种<strong>基于归并技术</strong>的<strong>稳定</strong>排序算法，结合使用了归并排序和插入排序技术，最坏时间复杂度是<code>O(nlogn)</code>。它<strong>具有适应性</strong>，在被排序的数组元素接近排好序的情况下，它的时间复杂度可能远小于<code>O(nlogn)</code>，可能达到线性时间。在最坏情况下，它的需要<code>n/2</code>的工作空间，因此其空间复杂度是<code>O(n)</code>。</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">最坏时间复杂度</th><th style="text-align:center">平均时间复杂度</th><th style="text-align:center">最好时间复杂度</th><th style="text-align:center">是否稳定</th><th style="text-align:center">是否是原地排序</th><th style="text-align:center">适应性</th></tr></thead><tbody><tr><td style="text-align:center">蒂姆排序</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">O(nlogn)</td><td style="text-align:center">O(n)</td><td style="text-align:center">是</td><td style="text-align:center">否</td><td style="text-align:center">是</td></tr></tbody></table><p>蒂姆排序算法适合许多实际应用中常见的情况，特别是被排序的数据序列分段有序或者基本有序，但仍有些非有序元素的情况。人们通过许多试验，发现蒂姆排序在平均性能上超过快排，是目前实际表现最好的排序算法。虽然理论上，它并没有克服归并排序<code>O(n)</code>空间开销的弱点，但实际开发中经常不需要很大的额外空间，且现在计算机的内存都很大，很多时候追求的都是速度。</p><h5 id="基本工作方式"><a href="#基本工作方式" class="headerlink" title="基本工作方式"></a>基本工作方式</h5><p>蒂姆排序的优势是克服了归并排序没有适应性的缺陷，且又保持了其稳定性的特征。<br>1 . 考察待排序序列中非严格单调上升（后一个值大于等于前一个值）或严格单调下降（后一个值小于前一个值）的片段，反转其中的严格下降片段。<br>2 . 采用插入排序，对连续出现的几个短的上升排序序列，使整个序列变成一系列（非严格）单调上升的记录片段，每个片段都长于某个特定值。<br>3 . 采用归并产生更长的排序片段，控制这一归并过程，保证片段的长度尽可能均匀。归并中采用一些策略，尽可能地减少临时空间的使用。通过反复归并，最终得到排序序列</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>1 . 如果序列中的数据基本有序而且序列长度<code>n</code>比较小，直接插入排序能很快完成排序，即具有适应性。这种情况下，冒泡排序也比较快。<br>2 . 简单排序算法多是稳定的，而大部分时间性能好的排序都不稳定，如快速排序（以及堆排序）等。</p><blockquote><p>稳定性是具体算法实现的性质，采用同一种排序算法，有可能做出稳定的和不稳定的实现。但有些算法的实现可以很自然地做到稳定（如，插入排序，归并排序），另一些则需要附加的时间或空间开销（如，选择排序）</p></blockquote><p>3 . 实际应用中，数据记录通常有一个主关键码，例如各种唯一标识码，如学号、身份证号、用户账户、商品订单号等。这种关键码一般都具有<code>唯一性</code>。如果要做的是按主关键码排序，所用<strong>排序方法是否稳定就无关紧要</strong>。<br>但在另一些应用中，经常需要把记录中的其他成分作为排序码使用，例如，按学生的姓名、籍贯、年龄、成绩等排序。在做这种排序时，应该根据问题所需慎重选择排序方法，<strong>经常需要用稳定算法</strong>。若用了不稳定的排序算法，可能就还需要对具有相同关键码的数据段再次排序。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;主要内容，总结前面的几种算法在各方面的性能。&lt;/p&gt;
&lt;h3 id=&quot;如何选择合适的排序算法？&quot;&gt;&lt;a href=&quot;#如何选择合适的排序算法？&quot; class=&quot;headerlink&quot; title=&quot;如何选择合适的排序算法？&quot;&gt;&lt;/a&gt;如何选择合适的排序算法？&lt;/h3&gt;&lt;p&gt;
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>排序</title>
    <link href="http://ipine.github.io/2018-11-03/"/>
    <id>http://ipine.github.io/2018-11-03/</id>
    <published>2018-11-03T08:13:00.000Z</published>
    <updated>2019-02-22T11:27:51.587Z</updated>
    
    <content type="html"><![CDATA[<p>三种时间复杂度是 <code>O(n)</code> 的排序算法：<code>桶排序</code>、<code>计数排序</code>、<code>计数排序</code>。这些排序算法的时间复杂度是线性的，因而也叫线性排序。之所以能做到线性的复杂度，主要原因这三种算法都是<strong>非基于比较</strong>的排序算法，不涉及元素间的比较操作；但是这几种排序算法对<strong>数据的要求很苛刻</strong>，因而需要重点掌握它们的使用场景。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>如何根据年龄给100万用户排序？（时间复杂度最好要是线性的）</p><h3 id="桶排序（Bucket-sort）"><a href="#桶排序（Bucket-sort）" class="headerlink" title="桶排序（Bucket sort）"></a>桶排序（Bucket sort）</h3><h4 id="核心原理"><a href="#核心原理" class="headerlink" title="核心原理"></a>核心原理</h4><p>桶排序，顾名思义，会用到“桶”，这些“桶”，按区间划分，核心思想是将要排序的数据将其分到所属的桶里去，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就有序了。</p><h4 id="为什么时间复杂度为-O-n-？"><a href="#为什么时间复杂度为-O-n-？" class="headerlink" title="为什么时间复杂度为 O(n)？"></a>为什么时间复杂度为 <code>O(n)</code>？</h4><p>如果要排序的数据有 <code>n</code> 个，将其均匀地划分到  <code>m</code> 个桶内，每个桶里就有 <code>k = n/m</code> 个元素。每个桶内部用快速排序，时间复杂度就为 <code>O(k * logk)</code> 。 <code>m</code> 个桶排序的时间复杂度就是 <code>O(m * k * logk)</code>，又因为 <code>k = n/m</code>，所以整个桶排序的时间复杂度就是 <code>O(n* logn/m)</code>。当桶的个数 <code>m</code> 接近数据个数 <code>n</code> 时，<code>logn/m</code> 就是一个很小的常量，这个时候桶排序的时间复杂度接近 <code>O(n)</code></p><h4 id="对数据的苛刻要求"><a href="#对数据的苛刻要求" class="headerlink" title="对数据的苛刻要求"></a>对数据的苛刻要求</h4><p>1 . 首先，要排序的数据需要很容易就能划分成 <code>m</code> 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。</p><p>2 . 其次，数据在各个桶之间的<strong>分布是比较均匀的</strong>。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 <code>O(nlogn)</code> 的排序算法了。</p><h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h4><p>桶排序比较适合用在<strong>外部排序</strong>中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。</p><h4 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h4><h5 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h5><p>有 10GB 的订单数据，我们希望按订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百 MB，没办法一次性把 10GB 的数据都加载到内存中。</p><h5 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h5><p>先扫描一遍文件，看订单金额所处的数据范围。假设经过扫描之后得到，订单金额最小是 1 元，最大是 10 万元。将所有订单根据金额划分到 100 个桶里，第一个桶存储金额在 1 元到 1000 元之内的订单，第二桶存储金额在 1001 元到 2000 元之内的订单，以此类推。每一个桶对应一个文件，并且按照金额范围的大小顺序编号命名 (00，01，02…99)。</p><p>理想的情况下，如果订单金额在 1 到 10 万之间<strong>均匀分布</strong>，那订单会被均匀划分到 100 个文件中，每个小文件中存储大约 100MB 的订单数据，就可以将这 100 个小文件依次放到内存中，用快排来排序。等所有文件都排好序之后，只需要按照文件编号，从小到大依次读取每个小文件中的订单数据，并将其写入到一个文件中，那这个文件中存储的就是按照金额从小到大排序的订单数据了。</p><p>不过，订单按照金额在 1 元到 10 万元之间并不一定是均匀分布的 ，所以 10GB 订单数据是无法均匀地被划分到 100 个文件中的。有可能某个金额区间的数据特别多，划分之后对应的文件就会很大，没法一次性读入内存。</p><p>针对这些划分之后还是比较大的文件，可以继续划分，比如，订单金额在 1 元到 1000 元之间的比较多，就将这个区间继续划分为 10 个小区间，1 元到 100 元，101 元到 200 元，201 元到 300 元…901 元到 1000 元。如果划分之后，101 元到 200 元之间的订单还是太多，无法一次性读入内存，那就继续再划分，直到所有的文件都能读入内存为止。</p><h3 id="计数排序（Counting-sort）"><a href="#计数排序（Counting-sort）" class="headerlink" title="计数排序（Counting sort）"></a>计数排序（Counting sort）</h3><p><strong>计数排序其实是桶排序的一种特殊情况</strong>。当要排序的 <code>n</code> 个数据，所处的范围并不大的时候，比如最大值是 <code>k</code>，就可以把数据划分成 <code>k</code> 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。</p><h4 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h4><p>查询高考成绩，系统会显示分数和所在省的排名。如果所在的省分有50万考生，如何通过成绩快速排序得出名次呢？<br>假设考生的满分是 900 分，最小是 0 分，这个数据的范围很小，所以可以分成 901 个桶，对应分数从 0 分到 900 分。根据考生的成绩，将这 50 万考生划分到这 901 个桶里。桶内的数据都是分数相同的考生，所以并不需要再进行排序。最后只需要依次扫描每个桶，将桶内的考生依次输出到一个数组中，就实现了 50 万考生的排序。因为只涉及扫描遍历操作，所以时间复杂度是 <code>O(n)</code>。</p><blockquote><p>这就是计数排序的算法思想，跟桶排序非常类似，只是桶的大小粒度不一样。</p></blockquote><h4 id="为什么叫计数排序"><a href="#为什么叫计数排序" class="headerlink" title="为什么叫计数排序"></a>为什么叫<strong>计数</strong>排序</h4><p>要了解<code>计数</code>的含义，就需要明白计算排序算法的实现方法。</p><h5 id="还是那个栗子"><a href="#还是那个栗子" class="headerlink" title="还是那个栗子"></a>还是那个栗子</h5><p>假设只有 8 个考生了，分数在 0 到 5 分之间。将这 8 个考生的成绩放在一个数组 <code>A[8]</code> 中，它们分别是：<code>2，5，3，0，2，3，0，3</code>分。</p><pre><code>#数组A8数组 [2] [5] [3] [0] [2] [3] [0] [3]下标  0   1   2   3   4   5   6   7</code></pre><p>考生的成绩从 0 到 5 分，使用大小为 6 的数组 <code>C[6]</code> 表示桶，其中<strong>下标对应分数</strong>。 <code>C[6]</code> 中的每个<strong>元素存对应分数的考生个数</strong>。</p><pre><code>#数组C6：数组-出现次数： [2] [0] [2] [3] [0] [1]下标-对应分数：  0   1   2   3   4   5</code></pre><p>现在的问题是，如何快速计算出，每个分数的考生在有序数组 (最后排好序的结果数组) 中对应的存储位置呢？</p><p><strong>巧妙的思路</strong><br>1 . 首先对 <code>C6</code> 数组顺序求和（<code>前面一个位置的值+当前自己本身的值 = 当前的新值</code>），得到新的 <code>C6</code> 数组：</p><pre><code>#新的数组C6：数组-出现次数： [2] [2] [4] [7] [7] [8]下标-对应分数：  0   1   2   3   4   5</code></pre><p>2 . 然后<strong>从后到前</strong>依次扫描数组 <code>A</code>。<br>过程如下：扫描到第一个3时，从数组 <code>C</code> 中取出下标为3的值，即7， 7在这里的含义是，到目前位置，包括当前这个在内，小于等于3分的考生个数是7个，即3是结果数组 <code>R</code> 中的第7个元素（对应于数组下标为6的位置<code>R[6] = 3</code>）。将这个3放进 <code>R</code> 数组后，数组 <code>C</code> 中小于等于3的元素个数减一就变成6个，即 <code>C[3] = 6</code>。以此推类，扫描完整个数组A后，数组 <code>R</code> 内的数据就是按照分数从小到大有序排列。</p><h5 id="过程图："><a href="#过程图：" class="headerlink" title="过程图："></a>过程图：</h5><p><img src="http://ipineimg.lijundong.com/18-11-4/39713280.jpg" alt="计数排序"></p><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><pre><code>from typing import Listimport itertoolsdef counting_sort(a: List[int]):    if len(a) &lt;= 1:return    counts = [0] * (max(a) + 1) #创建桶，初始值为0    for num in a:  #统计数组中每个元素出现的次数        counts[num] += 1    counts = list(itertools.accumulate(counts))  #对counts数组顺序求和，得到新的counts数组    a_sorted = [0] * len(a)  #创建一个临时结果数组，存储排序后的结果    for num in reversed(a):  #从后往前扫描需要被排序的数组        index = counts[num] - 1  #找到num在临时结果数组中位置        a_sorted[index] = num    #将num放到临时结果数组中        counts[num] -= 1         #num对应的个数减1    a = a_sorted  #将临时结果数组赋给原数组</code></pre><h4 id="适用场景-1"><a href="#适用场景-1" class="headerlink" title="适用场景"></a>适用场景</h4><p>计数排序只能用在数据范围不大的场景中，如果数据范围 <code>k</code> 比要排序的数据 <code>n</code> 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。</p><h5 id="栗子说明"><a href="#栗子说明" class="headerlink" title="栗子说明"></a>栗子说明</h5><p>比如，如果考生成绩精确到小数后一位，就需要将所有的分数都先乘以 10，转化成整数，然后再放到 9010 个桶内。再比如，如果要排序的数据中有负数，数据的范围是 [-1000, 1000]，那就需要先对每个数据都加 1000，转化成非负整数。</p><h3 id="基数排序（Radix-sort）"><a href="#基数排序（Radix-sort）" class="headerlink" title="基数排序（Radix sort）"></a>基数排序（Radix sort）</h3><p>首先按照最低有效位进行排序，最低位优先 <code>(Least Significant Digit first)</code> 法，简称 <code>LSD</code> 法：先从kd开始排序，再对kd-1进行排序，依次重复，直到对k1排序后便得到一个有序序列。</p><h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><p>假设有 10 万个手机号码，希望将这 10 万个手机号码从小到大排序，什么排序方法比较快速？</p><p>手机号码有 11 位，范围太大，显然不适合用桶排序和计数排序两种算法，基数排序就很适合。</p><h5 id="处理思路"><a href="#处理思路" class="headerlink" title="处理思路"></a>处理思路</h5><p>先按照最后一位来排序手机号码，然后，再按照倒数第二位重新排序，以此类推，最后按照第一位重新排序。经过 11 次排序之后，手机号码就都有序了。<br>注意，这里按照每位来排序的排序算法要是<strong>稳定</strong>的，否则这个实现思路就是不正确的。因为如果是非稳定排序算法，那最后一次排序只会考虑最高位的大小顺序，完全不管其他位的大小关系，那么低位的排序就完全没有意义了。</p><p>根据每一位来排序，可以用桶排序或者计数排序，它们的时间复杂度可以做到 <code>O(n)</code>。如果要排序的数据有 <code>k</code> 位，那就需要 <code>k</code> 次桶排序或者计数排序，总的时间复杂度是 <code>O(k*n)</code>。当 <code>k</code> 不大的时候，比如手机号码排序，<code>k</code> 最大就是 11，所以基数排序的时间复杂度就近似于 <code>O(n)</code>。</p><blockquote><p>实际上，有时候要排序的数据并不都是等长的。</p></blockquote><h5 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h5><p>可以把所有的数字补齐到相同长度，位数不够的可以在前面补0。而对于不等长的字符串排序，位数不够的可以在后面补<code>&quot;0&quot;</code>，因为根据ASCII 值，所有字母都大于<code>&quot;0&quot;</code>，所以补<code>&quot;0&quot;</code>不会影响到原有的大小顺序。这样就可以继续用基数排序了。</p><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><pre><code>def radix_sort(lt, d): #d表示d轮排序,取决于数组元素的长度    for k in xrange(d):        s = [[] for i in xrange(10)]  #创建10个桶，因为每位数字最大的就是9        #对数组中每个元素，按照最低有效数字进行排序，然后依次到高位        for i in lt:              s[i/(10**k)%10].append(i)        lt = [j for i in s for j in i]    return lt</code></pre><blockquote><p>例如<br>对数组[321,22,890]排序，第一轮对个位排，s[0]=[890],s[1]=[321],s[2]=[22]，第一轮排序结果lt[890,321,22]<br>第二轮对十位排，s[2] =[321,22],s[9]=[890]，第二轮排序结果lt[321,22,890]<br>第三轮百位排，s[0] =[22],s[3]=[321],s[8]=[890]，第三轮排序结果lt[22,321,890]，结束。</p></blockquote><h4 id="适用场景-2"><a href="#适用场景-2" class="headerlink" title="适用场景"></a>适用场景</h4><p>基数排序对要排序的数据是有要求的，需要可以分割出独立的<code>“位”</code>来比较，而且<strong>位之间有递进的关系</strong>，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的<strong>数据范围不能太大</strong>，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 <code>O(n)</code> 了。</p><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p>实际上，根据年龄给 100 万用户排序，就类似按照成绩给 50 万考生排序。<br>假设年龄的范围最小 1 岁，最大不超过 120 岁。<br>遍历这 100 万用户，根据年龄将其划分到120 个桶里，然后依次顺序遍历这 120 个桶中的元素。<br>这样就得到了按照年龄排序的 100 万用户数据。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;三种时间复杂度是 &lt;code&gt;O(n)&lt;/code&gt; 的排序算法：&lt;code&gt;桶排序&lt;/code&gt;、&lt;code&gt;计数排序&lt;/code&gt;、&lt;code&gt;计数排序&lt;/code&gt;。这些排序算法的时间复杂度是线性的，因而也叫线性排序。之所以能做到线性的复杂度，主要原因这三种算法都是&lt;
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>排序</title>
    <link href="http://ipine.github.io/2018-11-02/"/>
    <id>http://ipine.github.io/2018-11-02/</id>
    <published>2018-11-02T08:35:00.000Z</published>
    <updated>2019-02-22T11:27:50.468Z</updated>
    
    <content type="html"><![CDATA[<p>之前说的，冒泡排序、插入排序、选择排序三种算法的时间复杂度都是<code>O(n^2)</code>，很高，适用于小规模数据的排序。<br>而，<code>归并排序</code>和<code>快速排序</code>，适用于大规模的数据排序，更为常用。</p><h3 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h3><p>归并排序和快速排序都用到了分治思想，借助这个思想可以解决非排序问题。</p><blockquote><p>如何在O(n)的时间复杂度内查找一个无序数组中的第K大元素？</p></blockquote><h3 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h3><h4 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h4><p>对于要排序的数组，先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起。<br>归并排序用到的就是分治思想，顾名思义，就是分而治之，将大问题分解为小的子问题来解决。</p><blockquote><p>分治思想跟递归很向。分治算法一般都用递归来实现的。分治是一种解决问题的处理思想，递归是一种编程技巧。</p></blockquote><h4 id="如何用递归代码实现归并排序？"><a href="#如何用递归代码实现归并排序？" class="headerlink" title="如何用递归代码实现归并排序？"></a>如何用递归代码实现归并排序？</h4><p>先写出归并排序的递推公式</p><pre><code>递推公式：merge_sort(p...q) = merge(merge_sort(p...r), merge_sort(r+1...q)) #r = (p+q)/2,即数组的中间位置终止条件：p &gt;= q #不用再继续分解的时候</code></pre><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><pre><code>def merge_sort(lt):    if len(lt) &lt;= 1:        return lt    middle = len(lt)/2    left = merge_sort(lt[:middle])    right = merge_sort(lt[middle:])    return merge(left, right)def merge(arr1, arr2):    arr_result = []    while len(arr1)&gt;0 and len(arr2)&gt;0:        if arr1[0] &lt;= arr2[0]:            arr_result.append(arr1.pop(0))        else:            arr_result.append(arr2.pop(0))    #while循环结束，说明有个条件不满足，即有个数组已经没有数据元素了，此时将另一个数组的数据加入到结果数组中    arr_result += arr1    arr_result += arr2    return arr_result</code></pre><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><p>1 . 归并排序是否是稳定排序算法？关键看<code>merge()</code>函数，即两个有序子数组合并成最终结果数组的那部分代码。在合并过程中，如果<code>arr1[p...r]</code>和<code>arr2[r+1...q]</code>之间有相同元素，那么可以先把<code>arr1[p...r]</code>中的元素放入最终结果数组。这样就保证了值相同的元素，在合并前后的先后顺序不变。所以，归并排序是<strong>稳定的</strong>排序算法。<br>2 . 时间复杂度分析。归并排序涉及递归，时间复杂度该如何分析？<br><strong>递归适用场景</strong>：一个问题A可以分解为多个子问题B、C，求解A就就分解为求解B、C。问题B、C解决后，在把这个问题的结果合成A的结果。<br>若定义求解问题A的时间为<code>T(A)</code>，求解问题B、C的时间分别为<code>T(B)</code>和<code>T(C)</code>，则有一个递推关系</p><pre><code>T(A) = T(B) + T(C) + K    其中K为两个子问题B、C的结果合成问题A的结果所花费时间</code></pre><p>套用这个公式来分析归并排序的时间复杂度：<br>假设对 <code>n</code> 个元素进行归并排序需要的时间是 <code>T(n)</code>，那分解成两个子数组排序的时间都是 <code>T(n/2)</code>。<code>merge()</code> 函数合并两个有序子数组的时间复杂度是 <code>O(n)</code>。所以，套用前面的公式，归并排序的时间复杂度的计算公式就是：</p><pre><code>T(1) = C;  n=1 时，只需要常量级的执行时间T(n) = T(n/2) *2 + n;  n&gt;1 </code></pre><p>进一步分解可知道：</p><pre><code>T(n) = 2*T(n/2) + n     = 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n     = 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n     = 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n     ......     = 2^k * T(n/2^k) + k * n     ......即 T(n) = 2^k * T(n/2^k) + k * n, 当 T(n/2^k) = 1 时，k = log2^n则  T(n) = 2^log2^n + log2^n * n = Cn + n*log2^n</code></pre><p>用大O标记法表示，<code>T(n) = O(nlogn)</code></p><p>归并排序的<strong>执行效率与要排序的原始数组的有序程度无关</strong>，所以其时间复杂度是非常稳定的，不管是最好情况、最坏情况，还是平均情况，时间复杂度都是 <code>O(nlogn)</code>。</p><p>3 . 空间复杂度分析。归并排序的时间复杂度在任何情况下都是 <code>O(nlogn)</code>，看起来非常优秀，但是它并没有像快排那样应用广泛，其原因就是因为它有一个致命<code>弱点</code>，归并排序<strong>不是原地排序算法</strong>。主要原因在于<code>merge()</code>函数，需要借助额外的存储空间。</p><p>分析递归代码的空间复杂度并不能像时间复杂度那样累加。尽管每次合并操作都需要申请额外的内存空间，但在合并完成之后，临时开辟的内存空间就被释放掉了。在任意时刻，CPU 只会有一个函数在执行，也就只会有一个临时的内存空间在使用。临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 <code>O(n)</code>。</p><h3 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h3><h4 id="核心思想-1"><a href="#核心思想-1" class="headerlink" title="核心思想"></a>核心思想</h4><p>如果要排序数组中下标从 <code>p</code> 到 <code>q</code> 之间的一组数据，我们选择 <code>p</code> 到 <code>q</code> 之间的任意一个数据作为 <code>pivot（分区点）</code>（可选择末尾数字）。</p><p>遍历 <code>p</code> 到 <code>q</code> 之间的数据，将小于 <code>pivot</code> 的放到左边，将大于 <code>pivot</code> 的放到右边，将 <code>pivot</code> 放到中间。经过这一步骤之后，数组 <code>p</code> 到 <code>q</code> 之间的数据就被分成了三个部分，前面 <code>p</code> 到 <code>r-1</code> 之间都是小于 <code>pivot</code> 的，中间是 <code>pivot</code>，后面的 <code>r+1</code> 到 <code>q</code> 之间是大于 <code>pivot</code> 的。<br>其中一次排序步骤如下：</p><p><img src="http://ipineimg.lijundong.com/18-11-2/64232703.jpg" alt="快排"></p><p>递归排序下标从 <code>p</code> 到 <code>r-1</code> 之间的数据和下标从 <code>r+1</code> 到 <code>r</code> 之间的数据，直到区间缩小为 1，就说明所有的数据都有序了。</p><pre><code>递推公式quick_sort(p...q) = quick_sort(p...r-1) + quick_sort(r+1...q)终止条件p &gt;= q</code></pre><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><p>partition() 函数不需要额外的内存空间，保证快排是<strong>原地排序算法</strong>。</p><pre><code>def quick_sort(lt, lindex, rindex):    if lindex &lt; rindex:        pivot = partition(lt, lindex, rindex)        quick_sort(lt, lindex, pivot)        quick_sort(lt, pivot+1, rindex)    else:        returndef partition(lt, lindex, rindex):    i = lindex - 1    for j in range(lindex, rindex):        if lt[j] &lt;= lt[rindex]: #最后一个数据为pivot            i += 1            lt[i],lt[j] = lt[j], lt[i]    lt[i+1], lt[rindex] = lt[rindex], lt[i+1] #将分区点交换到数组中间位置    return i</code></pre><h4 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h4><p>1 . 快速排序是<strong>原地排序算法</strong>，即空间复杂度为O(1)。但在分区的过程涉及交换操作，如果数组中有两个相同的元素，在经过一次分区操作后，元素的相对先后顺序会改变。所以，快排<strong>不是一个稳定的排序算法</strong>。<br>2 . 时间复杂度分析。快排也是基于递归思想，前面的递归公式在这里仍适用。如果每次分区操作，都能正好把数组分成大小接近相等的两个小区间，那快排的时间复杂度递推求解公式跟归并是相同的。所以，快排的时间复杂度也是 <code>O(nlogn)</code>。但是，公式成立的前提是每次分区操作，选择的 <code>pivot</code> 都很合适，正好能将大区间对等地一分为二。但实际上这种情况是很难实现的。如果以最后一个元素作为<code>pivot</code>，需要进行大约 <code>n</code> 次分区操作，才能完成快排的整个过程。每次分区平均要扫描大约 <code>n/2</code> 个元素，这种情况下，快排的时间复杂度就从 <code>O(nlogn)</code> 退化成了 <code>O(n^2)</code>。<br>以上两种情况分别对应于<strong>最好情况</strong>和<strong>最坏情况</strong>，在大部分情况下快排的时间复杂度都可以做到 <code>O(nlogn)</code>，只有在极端情况下，才会退化到 <code>O(n^2)</code>。而且，有方法将这个极端情况的概率降到很低。</p><h3 id="快速排序和归并排序的区别"><a href="#快速排序和归并排序的区别" class="headerlink" title="快速排序和归并排序的区别"></a>快速排序和归并排序的区别</h3><p>快排和归并都用到分治思想，地推公式和递归代码也相似，它们的<strong>区别</strong>在于：归并排序的处理过程是<strong>由下到上</strong>的，先处理子问题，然后再合并；而快排正好相反，它的处理过程是<strong>由上到下</strong>的，先分区，再处理子问题。<br>归并排序虽然是<code>稳定的</code>、时间复杂度为 <code>O(nlogn)</code> 的排序算法，但是它是<code>非原地排序算法</code>，主要原因是合并函数无法在原地执行。快速排序通过设计巧妙的原地分区函数，可以实现<code>原地排序</code>，解决了归并排序占用太多内存的问题。</p><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p>利用分区思想，在<code>O(n)</code>时间复杂度时间内求无序数组中的第 <code>K</code> 大元素。<br>选择数组<code>arr[0,n-1]</code>的最后一个元素作为<code>pivot</code>，对数组<code>arr[0,n-1]</code>原地分区，数组分成三部分，<code>arr[0...p-1], arr[p], arr[p+1...n-1]</code>。如果 <code>p+1=K</code>，那 <code>arr[p]</code> 就是要求解的元素；如果 <code>K&gt;p+1</code>, 说明第 <code>K</code> 大元素出现在 <code>arr[p+1…n-1]</code> 区间，再按照上面的思路递归地在 <code>arr[p+1…n-1]</code> 这个区间内查找。同理，如果 <code>K&lt;p+1</code>，那就在 <code>arr[0…p-1]</code> 区间查找。</p><h4 id="为什么上述解决思路的时间复杂度是-O-n-？"><a href="#为什么上述解决思路的时间复杂度是-O-n-？" class="headerlink" title="为什么上述解决思路的时间复杂度是 O(n)？"></a>为什么上述解决思路的时间复杂度是 O(n)？</h4><p>第一次分区查找，需要对大小为 <code>n</code> 的数组执行分区操作，需要遍历 <code>n</code> 个元素。第二次分区查找，只需要对大小为 <code>n/2</code> 的数组执行分区操作，需要遍历 <code>n/2</code> 个元素。依次类推，分区遍历元素的个数分别为、<code>n/2、n/4、n/8、n/16.……</code> 直到区间缩小为 1。<br>把每次分区遍历的元素个数加起来，就是：<code>n+n/2+n/4+n/8+…+1</code> 。这是一个等比数列求和，最后的和等于 <code>2n-1</code>。所以，上述解决思路的时间复杂度就为 <code>O(n)</code>。</p><h4 id="另一种思路"><a href="#另一种思路" class="headerlink" title="另一种思路"></a>另一种思路</h4><p>每次取数组中的最小值，将其移动到数组的最前面，然后在剩下的数组中继续找最小值，以此类推，执行 <code>K</code> 次，找到的数据就是第 <code>K</code> 大元素。<br>思路是对的，但时间复杂度就不是 <code>O(n)</code> 了，而是 <strong><code>O(K * n)</code></strong>。当 <code>K</code> 是比较小的常量时，比如 1、2，那最好时间复杂度确实是 <code>O(n)</code>；但当 <code>K</code> 等于 <code>n/2</code> 或者 <code>n</code> 时，这种最坏情况下的时间复杂度就是 <code>O(n^2)</code> 了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;之前说的，冒泡排序、插入排序、选择排序三种算法的时间复杂度都是&lt;code&gt;O(n^2)&lt;/code&gt;，很高，适用于小规模数据的排序。&lt;br&gt;而，&lt;code&gt;归并排序&lt;/code&gt;和&lt;code&gt;快速排序&lt;/code&gt;，适用于大规模的数据排序，更为常用。&lt;/p&gt;
&lt;h3 id=
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>排序</title>
    <link href="http://ipine.github.io/2018-10-30/"/>
    <id>http://ipine.github.io/2018-10-30/</id>
    <published>2018-10-30T06:27:00.000Z</published>
    <updated>2019-02-22T11:27:49.412Z</updated>
    
    <content type="html"><![CDATA[<h3 id="问题思考"><a href="#问题思考" class="headerlink" title="问题思考"></a>问题思考</h3><p>插入排序和冒泡排序的时间复杂度相同，都是O(n^2)，在实际软件开发里，为什么更倾向于使用插入排序算法而不是冒泡排序算法呢？</p><h3 id="如何分析一个排序算法"><a href="#如何分析一个排序算法" class="headerlink" title="如何分析一个排序算法"></a>如何分析一个<strong>排序算法</strong></h3><h4 id="排序算法的执行效率"><a href="#排序算法的执行效率" class="headerlink" title="排序算法的执行效率"></a>排序算法的执行效率</h4><p>1 . 最好情况、最坏情况、平均情况时间复杂度<br>分析排序算法的时间复杂度是，要分别给出最好情况、最坏情况、平均情况下的时间复杂度。除此之外，还要说出最好、最坏时间复杂度对应的要排序的原始数据长什么样。</p><p>2 . 时间复杂度的系数、常数、低阶<br>尽管表示时间复杂度时，忽略了系数、常数、低阶。但实际软件开发中，排序的数据可能是10个、100个、1000个这样的小规模数据，因而对于同一阶时间复杂度的排序算法，在比较时，应该把系数、常数和低阶考虑进来。</p><p>3 . 比较次数和交换（移动）次数<br>基于比较的排序算法在执行过程中，会涉及到两种操作，一种是比较元素大小，另一种是元素交换或移动。</p><h4 id="排序算法的内存消耗"><a href="#排序算法的内存消耗" class="headerlink" title="排序算法的内存消耗"></a>排序算法的内存消耗</h4><p>内存消耗可以通过空间复杂度来衡量。针对排序算法的空间复杂度，引入一个新概念，<code>原地排序（Sorted in place）</code>。原地排序算法，就是特指空间复杂度是<code>O(1)</code>的排序算法。</p><blockquote><p>插入排序、冒泡排序、选择排序都是原地排序算法。</p></blockquote><h4 id="排序算法的稳定性"><a href="#排序算法的稳定性" class="headerlink" title="排序算法的稳定性"></a>排序算法的稳定性</h4><p>稳定性指：如果待排序的序列中存在值相等的元素，经过排序后，相等元素之间原有的先后顺序不变。<br>相等元素之间原有的先后顺序没有变，这种排序算法叫作<strong>稳定的排序算法</strong>；否则，叫作<strong>不稳定的排序算法</strong>。</p><h5 id="为什么要考察排序算法的稳定性？"><a href="#为什么要考察排序算法的稳定性？" class="headerlink" title="为什么要考察排序算法的稳定性？"></a>为什么要考察排序算法的稳定性？</h5><p><strong>场景举栗</strong><br>比如说，我们现在要给电商交易系统中的“订单”排序。订单有两个属性，一个是下单时间，另一个是订单金额。<br>如果我们现在有 10 万条订单数据，我们希望按照金额从小到大对订单数据排序。对于金额相同的订单，我们希望按照下单时间从早到晚有序。对于这样一个排序需求，我们怎么来做呢？</p><p><strong>思路分析</strong></p><ul><li>最先想到的方法是：先按照金额对订单数据进行排序，然后，再遍历排序之后的订单数据，对于每个金额相同的小区间再按照下单时间排序。这种排序思路理解起来不难，但是实现起来会很复杂。</li><li><p>更好的方法是：借助稳定排序算法。先按照下单时间给订单排序，注意是按照下单时间，不是金额。排序完成之后，再用稳定排序算法，按照订单金额重新排序。两遍排序之后，得到的订单数据就是按照金额从小到大排序，金额相同的订单按照下单时间从早到晚排序的。</p></li><li><p>原因：稳定排序算法可以保持金额相同的两个对象，在排序之后的前后顺序不变。第一次排序之后，所有的订单按照下单时间从早到晚有序了。在第二次排序中，因为用的是稳定的排序算法，所以经过第二次排序之后，相同金额的订单仍然保持下单时间从早到晚有序。</p></li></ul><h3 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h3><h4 id="排序过程"><a href="#排序过程" class="headerlink" title="排序过程"></a>排序过程</h4><p>冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复 <code>n</code> 次，就完成了 <code>n</code> 个数据的排序工作。</p><h4 id="优化过程"><a href="#优化过程" class="headerlink" title="优化过程"></a>优化过程</h4><p>当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，就不用再继续执行后续的冒泡操作。</p><h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><pre><code>def bubble_sort(lt):    length = len(lt)    flag = False    for i in range(0,length):        for j in range(i+1,length):            if lt[i] &gt; lt[j]:                                lt[i], lt[j] = lt[j], lt[i] #数据交换                flag = True        if not flag:            break    return lt</code></pre><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><p>1 . 冒泡排序只涉及相邻数据的交换操作，只需常量级的临时空间，空间复杂度为<code>O(1)</code>，所以是一个<strong>原地排序算法</strong>。<br>2 . 冒泡排序中只有交换才改变两个元素的前后顺序。为了保证其稳定性，当相邻元素相等时，不做交换，那么相同大小的数据在排序前后不会改变顺序。所以冒泡排序是<strong>稳定</strong>的排序算法。<br>3 . 最好情况下，排序数据已经是有序的，只进行一次冒泡操作，所以时间复杂度是<code>O(n)</code>；最坏情况是，排序的数据刚好是倒序排列的，需要进行n次冒泡操作，所以时间复杂度为<code>O(n^2)</code>；<br>平均时间复杂度，采用一种不严格的方法，通过<strong>有序度</strong>和<strong>逆序度</strong>两个概念来分析。</p><blockquote><p>有序度：数组中具有有序关系的元素对的个数。（默认，从小到大是有序的）</p></blockquote><p>例：2,4,3,5这组数据的有序度为：5，分别是<code>(2,4),(2,3),(2,5),(4,5),(3,5)</code>；同理，对于一个倒序排列的数组，有序度为0；对于一个完全有序的数组，比如2,3,4,5，有序度就是<code>n*(n-1)/2</code>，也就是6。把这种完全有序的数组的有序度叫作<strong>满有序度</strong>。<br><strong>逆有序度</strong>：其定义跟有序度正好相反。</p><blockquote><p>逆有序度 = 满有序度 - 有序度 </p></blockquote><p>排序的过程就是一种增加有序度，减少逆序度的过程，最后达到满有序度，说明排序完成。<br>冒泡排序中，包含两个操作，比较和交换。每交换一次，有序度就加1。不管算法怎么改进，交换次数总是确定的，即为逆序度，也就是等于<code>n*(n-1)/2 - 初始有序度</code>。对于2,4,3,5这组数据来说，6-5=1，只需进行1次交换操作。</p><h4 id="那么对于包含n个数据的数组进行冒泡排序，平均交换次数是多少呢？"><a href="#那么对于包含n个数据的数组进行冒泡排序，平均交换次数是多少呢？" class="headerlink" title="那么对于包含n个数据的数组进行冒泡排序，平均交换次数是多少呢？"></a>那么对于包含n个数据的数组进行冒泡排序，平均交换次数是多少呢？</h4><ul><li><strong>最坏情况</strong>：初始有序度为<strong>0</strong>，需要进行<code>n*(n-1)/2</code>次交换</li><li><strong>最好情况</strong>：初始有序度为 <code>n*(n-1)/2</code>，需要进行<strong>0</strong>次交换</li><li><strong>平均情况</strong>：取一个中间值 <code>n*(n-1)/4</code>，来表示初始有序度既不是很高也不是很低的平均情况。换句话说，平均情况下，需要 <code>n*(n-1)/4</code> 次交换操作，比较操作肯定比交换操作更多，而时间复杂度的上限是 <code>O(n^2)</code>，所以平均情况下的时间复杂度就是 <code>O(n^2)</code>。</li></ul><h3 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h3><p>对于一个原本有序的数组，往里面加一个新数据后，如何继续保持数据的有序呢？很简单，只需要遍历数组，找到数据应该插入的位置将其插入即可。</p><blockquote><p>插入排序就是借助这个思想来实现排序的。</p></blockquote><h4 id="排序过程-1"><a href="#排序过程-1" class="headerlink" title="排序过程"></a>排序过程</h4><p>首先，将数组中的数据分为两个区间，已排序区间和未排序区间。初始已排序区间只有一个元素，就是数组的第一个元素。插入算法的核心思想是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序。重复这个过程，直到未排序区间中元素为空，算法结束。</p><h4 id="两种操作"><a href="#两种操作" class="headerlink" title="两种操作"></a>两种操作</h4><p>一种是元素的比较，另一种是元素的移动。对于不同的查找插入点方法（从头到尾，从尾到头），元素的比较次数是有区别的。但<strong>对于一个给定的初始序列，移动操作的次数总是固定的，即为逆序度</strong>。（为什么<code>移动次数=逆序度</code>，可以拿个实例画一个图，很容易明白）</p><h4 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h4><pre><code>def insertion_sort(lt):    length = len(lt)    for i in range(1, length):        value = lt[i]        for j in range(i-1,-1,-1):            if lt[j] &gt; value:                lt[j+1] = lt[j] #数据移动            else:                break #位置确定        lt[j+1] = value  #插入数据    return lt</code></pre><h4 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h4><p>1 . 插入排序算法的运行并不需要额外的存储空间，空间复杂度为 <code>O(1)</code>，所以是一个<strong>原地排序算法</strong>。<br>2 . 插入排序中，对于值相同的元素，可以选择将后面出现的元素，插入到前面出现元素后面，保持原有前后顺序不变。所以插入排序是<strong>稳定</strong>的排序算法。<br>3 . 时间复杂度分析。</p><ul><li><strong>最好情况</strong>：数据已经有序，不需要搬移任何数据。如果从尾到头在有序数组里查找插入位置，每次只需比较一个数据就能确定插入位置。时间复杂度为 <code>O(n)</code>；</li><li><strong>最坏情况</strong>：数组是倒序的，每次插入都相当于在数组的第一个位置插入新数据，所有需要移动大量数据。时间复杂度为 <code>O(n^2)</code>；</li><li><strong>平均情况</strong>：在数组中插入一个数据的平均时间复杂度为 <code>O(n)</code>，对于插入排序来说，每次插入操作就相当于在数组中插入一个数据，循环执行 <code>n</code> 次插入操作。所以平均时间复杂度为 <code>O(n^2)</code>。</li></ul><h3 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h3><p>思路与插入排序类似，也分已排序区间和未排序区间。但是选择排序<strong>每次会从未排序区间中找到最小的元素，将其放到已排序区间末尾</strong>。最开始没有已排好的区间，找到数组中最小元素，将其与第一个元素交换，然后再执行以上过程。</p><h4 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h4><pre><code>def selection_sort(lt):    length = len(lt)    for i in range(0,length-1):        smallest_index = i        for j in range(i+1, length):            if lt[j] &lt; lt[smallest_index]:                lt[j], lt[smallest_index] = lt[smallest_index], lt[j]    return lt</code></pre><h4 id="分析-2"><a href="#分析-2" class="headerlink" title="分析"></a>分析</h4><p>1 . 选择排序空间复杂度为O(1)，是一种<strong>原地排序算法</strong>。<br>2 . 时间复杂度分析。最好情况、最坏情况和平均时间复杂度都为 <code>O(n^2)</code>。<br>3 . 选择排序是一种<strong>不稳定</strong>的排序算法。因为其每次都要找剩余未排序元素中的最小值，并和前面的元素交换位置，这样就破坏了稳定性。也因为此，相比于冒泡排序和插入排序，选择排序没那么好。</p><h3 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h3><p>冒泡排序和插入排序的时间复杂度都是 <code>O(n2)</code>，都是原地排序算法，为什么插入排序要比冒泡排序更受欢迎呢？<br>前面说过，冒泡排序不管怎么优化，元素交换的次数是一个固定值，是原始数据的逆序度。插入排序是同样的，不管怎么优化，元素移动的次数也等于原始数据的逆序度。<br>但是，从代码实现上来看，<strong>冒泡排序的数据交换要比插入排序的数据移动更复杂</strong>，冒泡排序需要 3 个赋值操作，而插入排序只需要 1 个。所以在对相同数组进行排序时，冒泡排序的运行时间理论上要长于插入排序。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;问题思考&quot;&gt;&lt;a href=&quot;#问题思考&quot; class=&quot;headerlink&quot; title=&quot;问题思考&quot;&gt;&lt;/a&gt;问题思考&lt;/h3&gt;&lt;p&gt;插入排序和冒泡排序的时间复杂度相同，都是O(n^2)，在实际软件开发里，为什么更倾向于使用插入排序算法而不是冒泡排序算法呢？
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>递归</title>
    <link href="http://ipine.github.io/2018-10-29/"/>
    <id>http://ipine.github.io/2018-10-29/</id>
    <published>2018-10-29T07:00:00.000Z</published>
    <updated>2019-02-22T11:27:48.310Z</updated>
    
    <content type="html"><![CDATA[<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>很多APP都有推荐用户注册返佣金或奖励的功能。在这个功能中，用户A推荐用户B来注册，用户B又推荐用户C来注册。那么用户C的<code>最终推荐人</code>就为A，用户B的<code>最终推荐人</code>也为A，用户A没有最终推荐人。在数据库表中，可以记录两行数据，其中<code>user_id</code>表示用户ID，<code>referrer_id</code>表示推荐人ID。<br>那么，问题是，给定一个用户ID，如何查找这个用户的<code>最终推荐人</code>？<br>应用到的思想就是递归</p><h3 id="如何理解递归"><a href="#如何理解递归" class="headerlink" title="如何理解递归"></a>如何理解<strong>递归</strong></h3><p>很多数据结构和算法的实现都要用到递归，比如<strong>DFS深度优先搜索</strong>、<strong>前中后序二叉树遍历</strong>等。</p><p>一个生活中的例子，在电影院由于太黑，你看不清自己在第几排，但是又想知道，怎么办呢？问前一排的人，他的排数+1就是你的排数。但是前一排的人也看不清自己在第几排，他又通过问自己的前一排，就这样一直传递问下去，直到第一排的人说我是第一排，于是又一排一排把数字传回来。<br>这样一个过程就是递归求解问题的分解过程，去的过程叫<code>递</code>，回来的过程叫<code>归</code>。基本上，所有的递归问题都可以用递推公式来表示。</p><pre><code>f(n) = f(n-1) + 1, 其中，f(1) = 1</code></pre><h3 id="什么样的问题能用递归来解决？"><a href="#什么样的问题能用递归来解决？" class="headerlink" title="什么样的问题能用递归来解决？"></a>什么样的问题能用递归来解决？</h3><p>同时满足以下三个条件，就可用递归来解决。</p><ul><li><p>一个问题的解可以分解为几个子问题的解。<br>子问题是指数据规模更小的问题<br>想知道你“自己在哪一排”，可以分解为“前一排的人在哪一排”这个子问题</p></li><li><p>这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样。<br>你求解“自己在哪一排”，与前面一排求解“自己在哪一排”的思路是相同的。</p></li><li><p>存在递归终止条件<br>问题分解为子问题，子问题再一层层分解下去，但是不能无限循环，必须有终止条件。<br>电影院第一排的人知道自己在哪一排，即<code>f(1) = 1</code>,这就是递归终止条件。</p></li></ul><h3 id="编写递归代码"><a href="#编写递归代码" class="headerlink" title="编写递归代码"></a>编写递归代码</h3><p><strong>关键点：写出递归公式，找到终止条件。</strong></p><h4 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h4><p>假设有n个台阶，每次可以跨1个台阶或者2个台阶，那么请问走完这n个台阶，共有多少种走法？</p><h5 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h5><p>可以根据第一步的走法把所有走法分为两类，第一类是，第一步走1个台阶；第二类是，第一步走2个台阶。<br>所以，<code>n</code>个台阶的走法就等于，先走1阶后，<code>n-1</code>个台阶的走法，加上，先走2阶后，<code>n-2</code>个台阶的走法。<br>公式表示为：</p><pre><code>f(n) = f(n-1) + f(n-2)</code></pre><p>有了递推公式还不够，再分析终止条件：当有1个台阶时，就只有一个走法，所以<code>f(1) = 1</code>。用小规模数试验一下，该终止条件是否合理，当<code>n=2</code>时，<code>f(2) = f(1) + f(0)</code>。发现<code>f(2)</code>没法求解，因为没给<code>f(0)</code>的值。可以给定<code>f(0) = 0</code>，表示走0个台阶有1种走法，但这不符合常识，因而可以直接给定<code>f(2) = 2</code>，表示走2个台阶有2种走法，要么一步1个台阶走，要么一次跨2个台阶。<br>这样再试验<code>f(3) = f(2) + f(1)</code>，可以得出结果并正确。所以，递归终止条件就为<code>f(1)= 1, f(2) = 2</code>。<br>最终公式</p><pre><code>f(1)= 1f(2) = 2f(n) = f(n-1) + f(n-2)</code></pre><h5 id="递归代码"><a href="#递归代码" class="headerlink" title="递归代码"></a>递归代码</h5><pre><code>def climbStairs(self,n):    if n==1:        return 1    elif n==2:        return 2    else:        return self.climbStairs(n-1) + self.climbStairs(n-2)</code></pre><h3 id="Key"><a href="#Key" class="headerlink" title="Key"></a>Key</h3><p>对于递归代码，试图想清楚整个递和归过程的做法，实际上是进入了一个思维误区。很多时候，理解起来比较吃力，主要原因就是自己给自己制造了这种理解障碍。</p><p><strong>正确的思维方式</strong>应该是:<br>如果一个问题 A 可以分解为若干子问题 B、C、D，就假设子问题 B、C、D 已经解决，在此基础上思考如何解决问题 A。而且，只需要思考问题 A 与子问题 B、C、D 两层之间的关系即可，不需要一层一层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样子理解起来就简单多了。<br>因此，编写递归代码的关键是，只要遇到递归，就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。</p><h3 id="注意问题"><a href="#注意问题" class="headerlink" title="注意问题"></a>注意问题</h3><p>1 . 递归代码要警惕堆栈溢出。函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完成返回时，才出栈。系统栈或者虚拟机栈空间一般都不大。如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。</p><p><strong>解决思路</strong>：可以通过在代码中限制递归调用的最大深度的方式来解决这个问题。递归调用超过一定深度（比如 1000）之后，我们就不继续往下再递归了，直接返回报错。</p><p>2 . 递归代码要警惕重复计算。刚刚的例子中，就存在这个问题，比如要计算<code>f(5)</code>，就需要计算<code>f(4)</code>和<code>f(3)</code>，而计算<code>f(4)</code>，需要计算<code>f(3)</code>和<code>f(2)</code>，这个过程中<strong>f(3)就被计算了多次</strong>。</p><p><strong>解决思路</strong>：通过一个数据结构（散列表）来保存已经求解过的f(i)。当递归调用到f(i)时，先查找这个值是否已经求解。若是，则直接从散列表中取值返回，避免重复计算。</p><h4 id="修改栗子中的代码"><a href="#修改栗子中的代码" class="headerlink" title="修改栗子中的代码"></a>修改栗子中的代码</h4><pre><code>def climbStairs(self,n):    hash_list = [0,1,2]    if n==1:        return hash_list[1]    elif n==2:        return hash_list[2]    else:        for i in range(3, n+1):            hash_list.append(hash_list[i-1] + hash_list[i-2])        return  hash_list[n]</code></pre><p>3 . 时间和空间成本很高。在时间效率上，递归代码里多了很多函数调用，当这些函数调用的数量较大时，就会积聚成一个可观的时间成本。在空间复杂度上，因为递归调用一次就会在内存栈中保存一次现场数据，所以在分析递归代码空间复杂度时，需要额外考虑这部分的开销，比如前面的电影院递归代码，空间复杂度并不是 <code>O(1)</code>，而是 <code>O(n)</code>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;应用场景&quot;&gt;&lt;a href=&quot;#应用场景&quot; class=&quot;headerlink&quot; title=&quot;应用场景&quot;&gt;&lt;/a&gt;应用场景&lt;/h3&gt;&lt;p&gt;很多APP都有推荐用户注册返佣金或奖励的功能。在这个功能中，用户A推荐用户B来注册，用户B又推荐用户C来注册。那么用户C的&lt;
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>队列</title>
    <link href="http://ipine.github.io/2018-10-16/"/>
    <id>http://ipine.github.io/2018-10-16/</id>
    <published>2018-10-16T11:58:00.000Z</published>
    <updated>2019-02-22T11:27:46.805Z</updated>
    
    <content type="html"><![CDATA[<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>CPU资源有限，任务的处理速度与线程个数并不是线性正相关。过多的线程会导致CPU频繁切换，处理性能下降。<br>当我们向固定大小的线程池中请求一个线程时，如果线程池中没有空闲资源了，这个时候线程池如何处理这个请求？是拒绝请求还是排队请求？各种处理策略又是怎么实现的呢？<br>这就需要用到<code>队列</code>这个数据结构</p><h3 id="如何理解队列"><a href="#如何理解队列" class="headerlink" title="如何理解队列"></a>如何理解<code>队列</code></h3><p>理解成，排队购票，排在前面的先买，排在后面的后买。即<code>先进者先出</code>（FIFO）。<br>队列跟栈非常相似，支持的操作也有限，最基本的也是两个：<strong>入队和出队，一端出队，另一端入队</strong>；所以队列也是一种操作受限的<code>线性表</code>数据结构。</p><h3 id="顺序队列和链式队列"><a href="#顺序队列和链式队列" class="headerlink" title="顺序队列和链式队列"></a>顺序队列和链式队列</h3><p>用数组实现的队列叫作顺序队列，用链表实现的队列叫作链式队列。</p><h4 id="顺序队列"><a href="#顺序队列" class="headerlink" title="顺序队列"></a>顺序队列</h4><p>不理想的设计：<br>1 . 若使用顺序表的尾端插入实现<code>enqueue</code>操作，根据队列性质，出队操作应该在表的首端进行。为了维护顺序表的完整性（表元素在表前端连续存放），出队操作取出当时的首元素后，就需要把表中其余元素全部前移，这样就会是一个 <code>O(n)</code> 时间的操作。<br>2 . 反过来：从尾端出队是 <code>O(1)</code> 操作，但从首端入队就是 <code>O(n)</code> 时间操作，这种设计也不理想。<br>3 . 另一种是在队首元素出队后表中的元素不前移，但记住新队头位置。如果队列中没有空闲了，只需要在入队时，再集中触发一次数据的搬移操作。</p><h4 id="链式队列"><a href="#链式队列" class="headerlink" title="链式队列"></a>链式队列</h4><p>最简单的单链表只支持首端 <code>O(1)</code> 的操作，在另一端操作需要 <code>O(n)</code> 时间。不适合作为队列的实现基础。<br>考虑<code>带表尾指针</code>的单链表，它支持 <code>O(1)</code> 时间的尾端插入操作；再加上表首端的高效访问和删除，基于单链表实现队列就很容易。</p><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><pre><code>class LNode:    def __init__(self, elem, next_=None):        self.data = elem        self.next = next_class QueueUnderflow(ValueError):    passclass LQueue:    def __init__(self):        self._head = None        self._rear = None    def is_empty(self):        return self._head is None    def peek(self):        &quot;&quot;&quot;查看队列最早元素，不删除&quot;&quot;&quot;        if self._head is None: #是空队列            raise QueueUnderflow(&apos;in peek of Queue&apos;)        else:            return self._head.data    def dequeue(self):        &quot;&quot;&quot;删除队列头结点，并返回这个结点里的数据&quot;&quot;&quot;        if self._head == None:            raise QueueUnderflow(&quot;in dequeue&quot;)        e = self._head.data        self._head = self._head.next        return e    def enqueue(self, elem):        if self._head is None:#空表            self._head = LNode(elem, self._head)            self._rear = self._head        else:            self._rear.next = LNode(elem)            self._rear = self._rear.next</code></pre><h3 id="循环队列"><a href="#循环队列" class="headerlink" title="循环队列"></a>循环队列</h3><p>一个具体的实现示例：基于Python的list实现顺序表示的循环队列。<br>考虑定义一个可以自定扩充存储结构的队列类。</p><blockquote><p>注：不能直接利用list的自动存储扩充机制。两个原因：<br> 1 . 队列元素的存储方式与list元素的默认存储方式不一致；list元素总在其存储器的最前面一段，而队列的元素可能是表里的任意一段，有时还分为头尾两段。<br> 2 . list没有提供检测元素存储区容量的机制，队列操作中无法判断系统何时扩容。</p></blockquote><h5 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h5><pre><code>class SQueue():    def __init__(self, init_len = 8):        self._len = init_len       #存储区长度        self._elems = [0] *init_len #元素存储        self._head = 0              #表头元素下标        self._num = 0               #元素个数    def is_empty(self):        return self._num == 0    def peek(self):        if self._num is None: #是空队列            raise QueueUnderflow(&apos;in peek of SQueue&apos;)        return self._elems[self._head]    def dequeue(self):        if self._num == 0:            raise QueueUnderflow(&apos;in dequeue of SQueue&apos;)        e = self._elems[self._head]        self._head = (self._head+1)%self._len        self._num -= 1        return e    def enqueue(self,e):        if self._num == self._len: #队满时            self._extend()        self._elems[(self._head+self._num)%self._len] = e        self._num += 1    def _extend(self):        old_len = self._len        self._len *= 2        new_elems = [0]*self._len #扩大元素存储区        for i in range(old_len):  #将原有元素搬迁到新表里（最前面的位置）            new_elems[i] = self._elems[(self._head+1)%old_len]        self._elems, self._head = new_elems, 0  </code></pre><p><strong>注解</strong></p><p>1 . 队列对象的4个属性，<code>_elems</code>，<code>_head</code>，<code>_num</code>，<code>_len</code>的作用分别是：<strong>存放队列元素</strong>，<strong>记录队列首元素所在位置的下标</strong>，<strong>记录表中元素个数</strong>，<strong>记录当存储区的有效容量（便于换存储表）</strong>。<br>2 . 在<code>_num = _len</code> 的情况下（队满）出现入队操作，就扩大存储区；队空就是 <code>_num == 0</code>。<br>3 . 队列里的元素总保存在<code>_elems</code>里，从<code>_head</code>开始的连续位置中。<br>4 . 新入队的元素存入在 <code>(_head + _num)%len</code> 算出的位置；若需要把元素存入下标<code>_len</code>的位置时，改为在<code>下标0位置</code>存入。<br>5 . 在<code>_extend</code>函数中新元素尚未入队，但<code>_extend</code>在enqueue返回后，enqueue的最后两句语句将正常完成这个工作。</p><h3 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h3><p>阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。</p><blockquote><p>注：可以用阻塞队列实现一个“生产者-消费者模型”。基于阻塞队列，可以通过协调“生产者”和“消费者”的个数，来提高数据的处理效率。</p></blockquote><h3 id="并发队列"><a href="#并发队列" class="headerlink" title="并发队列"></a>并发队列</h3><p>在多线程情况下，会有多个线程同时操作队列，这个时候就会存在线程安全问题。<br>要实现一个线程安全的队列就需要<code>并发队列</code>。<br>最简单直接的实现方式是直接在 <code>enqueue()</code>、<code>dequeue()</code> 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。</p><h3 id="解答引言"><a href="#解答引言" class="headerlink" title="解答引言"></a>解答引言</h3><p>一般有两种处理策略。</p><ul><li>第一种是非阻塞的处理方式，直接拒绝任务请求；</li><li>另一种是阻塞的处理方式，将请求排队，等到有空闲线程时，取出排队的请求继续处理。</li></ul><p><strong>那如何存储排队的请求呢？</strong><br>公平地处理每个排队的请求，先进者先服务，所以队列这种数据结构很适合来存储排队请求。</p><p>队列有基于链表和基于数组这两种实现方式。<strong>两种实现方式对于排队请求又有什么区别呢？</strong></p><h4 id="基于链表的实现方式"><a href="#基于链表的实现方式" class="headerlink" title="基于链表的实现方式"></a>基于链表的实现方式</h4><p>可以实现一个支持无限排队的<code>无界队列（unbounded queue）</code>，但是可能会导致过多的请求排队等待，请求处理的响应时间过长。<br>所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。</p><h4 id="基于数组的实现方式"><a href="#基于数组的实现方式" class="headerlink" title="基于数组的实现方式"></a>基于数组的实现方式</h4><p>可以实现的是<code>有界队列（bounded queue）</code>，队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。<br>这时，设置一个合理的队列大小，就非常重要。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。</p><blockquote><p>注：对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过<code>队列</code>这种数据结构来实现请求排队。</p></blockquote><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>队列的其他应用<br>1 . 文件打印<br>2 . 万维网服务器<br>3 . Windows系统和消息队列<br>4 . 离散事件系统模拟</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h3&gt;&lt;p&gt;CPU资源有限，任务的处理速度与线程个数并不是线性正相关。过多的线程会导致CPU频繁切换，处理性能下降。&lt;br&gt;当我们向固定大小的线程池中请
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>栈</title>
    <link href="http://ipine.github.io/2018-10-13/"/>
    <id>http://ipine.github.io/2018-10-13/</id>
    <published>2018-10-13T11:58:00.000Z</published>
    <updated>2019-02-22T11:27:45.130Z</updated>
    
    <content type="html"><![CDATA[<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>首先思考一个问题，浏览器的前进、后退功能是如何实现的呢？</p><h3 id="理解栈"><a href="#理解栈" class="headerlink" title="理解栈"></a>理解栈</h3><ul><li><code>栈</code>结构：先进的后出，后进的先出。类似于洗好的盘子，叠一摞，下次用的时候只能从最上面那个盘子开始拿。</li><li>操作特性：<code>操作受限</code>的<strong>线性表</strong></li><li>什么时候用：当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出的特性，就应该首选<code>栈</code>这种结构。</li></ul><h3 id="如何实现栈"><a href="#如何实现栈" class="headerlink" title="如何实现栈"></a>如何实现栈</h3><p>栈既可以用数组实现，也可以用链表来实现。用数组实现的栈，叫作顺序栈，用链表实现的栈，叫作链栈。</p><ul><li>示例：顺序栈</li></ul><pre><code>class Stack():    def __init__(self,size):        &quot;&quot;&quot;初始化&quot;&quot;&quot;        self.size = size        self.num = 0        self.stack = []    def getSize(self):        &quot;&quot;&quot;获取栈的长度&quot;&quot;&quot;        return self.num    def print_all(self):        &quot;&quot;&quot;输出栈元素&quot;&quot;&quot;        for s in self.stack:            print s    def append_stack(self,value):        &quot;&quot;&quot;入栈&quot;&quot;&quot;        if self.num &gt;= self.size:            print(&quot;the stack is full&quot;)            return        else:            self.stack.append(value)            self.num += 1    def pop_stack(self):        &quot;&quot;&quot; 出栈&quot;&quot;&quot;        if self.num is None:            print(&quot;the stack is empty&quot;)            return        else:            self.stack.remove(self.stack[-1])</code></pre><h3 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h3><h4 id="空间复杂度"><a href="#空间复杂度" class="headerlink" title="空间复杂度"></a>空间复杂度</h4><p>无论是顺序栈还是链栈，存储数据只需要一个大小为n的数组。在入栈和出栈过程中，只需要一两个临时变量存储空间，所以空间复杂度为<code>O(1)</code>。</p><blockquote><p>注：存储数据需要一个大小为n的数组，并不是指空间复杂度就为O(n)。因为，这 n 个空间是必须的，无法省掉。<br>我们说空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要的额外的存储空间。</p></blockquote><h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><p>不管顺序栈还是链栈，入栈、出栈只涉及栈顶个别数据的操作，所以复杂度为<code>O(1)</code>。</p><h4 id="支持动态扩容的顺序栈的入栈、出栈时间复杂度分析"><a href="#支持动态扩容的顺序栈的入栈、出栈时间复杂度分析" class="headerlink" title="支持动态扩容的顺序栈的入栈、出栈时间复杂度分析"></a>支持动态扩容的顺序栈的入栈、出栈时间复杂度分析</h4><p>对于出栈操作来说，不会涉及内存的重新申请和数据的搬移，所以出栈的时间复杂度仍然是 <code>O(1)</code>。但是，对于入栈操作来说，情况就不一样了。当栈中有空闲空间时，入栈操作的时间复杂度为 <code>O(1)</code>。但当空间不够时，就需要重新申请内存和数据搬移，所以时间复杂度就变成了 <code>O(n)</code>。</p><p>也就是说，对于入栈操作来说，最好情况时间复杂度是 <code>O(1)</code>，最坏情况时间复杂度是 <code>O(n)</code>。而平均时间复杂度，由摊还分析法分析可知为 <code>O(1)</code>。</p><h3 id="栈的应用"><a href="#栈的应用" class="headerlink" title="栈的应用"></a>栈的应用</h3><h4 id="在函数调用中的应用"><a href="#在函数调用中的应用" class="headerlink" title="在函数调用中的应用"></a>在函数调用中的应用</h4><p>操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。</p><h4 id="栈在表达式求值中的应用"><a href="#栈在表达式求值中的应用" class="headerlink" title="栈在表达式求值中的应用"></a>栈在表达式求值中的应用</h4><p>实现一个表达式求值的功能，编译器就是通过两个栈来实现的。<br>其中一个保存操作数的栈，另一个是保存运算符的栈。<br>从左向右遍历表达式，当遇到数字，就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。<br>如果当前运算符优先级高，就将当前运算符压入栈；如果运算符栈顶元素优先级高，就从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。</p><h5 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h5><p><code>3+5*8-6</code>表达式的计算过程如下：</p><p><img src="http://ipineimg.lijundong.com/18-10-16/98172578.jpg" alt="表达式"></p><h4 id="栈在括号匹配中的应用"><a href="#栈在括号匹配中的应用" class="headerlink" title="栈在括号匹配中的应用"></a>栈在括号匹配中的应用</h4><p>假设表达式中只包含三种括号，<code>圆括号 ()</code>、<code>方括号 []</code> 和<code>花括号{}</code>，并且它们可以任意嵌套。比如，<code>{[{}]}</code>或 <code>[{()}([])]</code> 等都为合法格式，而<code>{[}()]</code> 或 <code>[({)]</code> 为不合法的格式。</p><h5 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h5><p>给定一个包含三种括号的表达式字符串，如何检查它是否合法呢？</p><h5 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h5><p>用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，比如<code>(</code>跟<code>)</code>匹配，<code>[</code>跟<code>]</code>匹配，<code>{</code>跟<code>}</code>匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。<br>当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。</p><h5 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h5><pre><code>left_brackets = &apos;{[(&lt;&apos;right_brackets = &apos;}])&gt;&apos;matching_brackets = {&apos;}&apos;: &apos;{&apos;, &apos;]&apos;: &apos;[&apos;, &apos;)&apos;: &apos;(&apos;, &apos;&gt;&apos;: &apos;&lt;&apos;}def judgment_brackets_matching(rows):    stack = []    label = True    for row in rows:        if row in left_brackets:            stack.append(row)        elif row in right_brackets:            if len(stack) &lt; 1:                label = False                break            elif matching_brackets[row] == stack[-1]:                stack.pop()            else:                label = False                break        else:            continue    if stack:        label = False    return label</code></pre><h2 id="解答开篇"><a href="#解答开篇" class="headerlink" title="解答开篇"></a>解答开篇</h2><p>用栈实现浏览器的前进、后退功能</p><h3 id="方法-1"><a href="#方法-1" class="headerlink" title="方法"></a>方法</h3><p>使用两个栈，<code>X</code> 和 <code>Y</code>，把首次浏览的页面依次压入栈 <code>X</code>，当点击后退按钮时，再依次从栈 <code>X</code> 中出栈，并将出栈的数据依次放入栈 <code>Y</code>。当我们点击前进按钮时，我们依次从栈 <code>Y</code> 中取出数据，放入栈 <code>X</code> 中。当栈 <code>X</code> 中没有数据时，那就说明没有页面可以继续后退浏览了。当栈 <code>Y</code> 中没有数据，那就说明没有页面可以点击前进按钮浏览了。</p><h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>顺序查看了a,b,c三个页面，将其依次压入栈，栈中数据情况为：</p><pre><code>X: a-&gt;b-&gt;cY: None</code></pre><p>点击后退按钮，从c页面推到a页面，栈中数据情况为：</p><pre><code>X: NoneY: c-&gt;b-&gt;a</code></pre><p>想再次查看b页面，点击前进按钮到b页面，此时栈中数据情况为：</p><pre><code>X: a-&gt;bY: c</code></pre><p>假设，此时在b页面跳转到新页面d，页面c就无法通过前进或后退按钮重复查看了，因而需要清空Y栈：</p><pre><code>X: a-&gt;b-&gt;dY: None</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;思考&quot;&gt;&lt;a href=&quot;#思考&quot; class=&quot;headerlink&quot; title=&quot;思考&quot;&gt;&lt;/a&gt;思考&lt;/h2&gt;&lt;p&gt;首先思考一个问题，浏览器的前进、后退功能是如何实现的呢？&lt;/p&gt;
&lt;h3 id=&quot;理解栈&quot;&gt;&lt;a href=&quot;#理解栈&quot; class=&quot;he
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>链表</title>
    <link href="http://ipine.github.io/2018-10-11/"/>
    <id>http://ipine.github.io/2018-10-11/</id>
    <published>2018-10-11T11:58:00.000Z</published>
    <updated>2019-02-22T11:27:44.169Z</updated>
    
    <content type="html"><![CDATA[<p>主要学习几个写链表代码的技巧</p><h3 id="理解指针或引用的含义"><a href="#理解指针或引用的含义" class="headerlink" title="理解指针或引用的含义"></a>理解指针或引用的含义</h3><p>有些语言有<code>指针</code>概念，比如C语言；有些语言没有指针，取而代之的是<code>引用</code>，比如Java、Python。不管“指针”还是“引用”，都是一个意思，<code>指存储所指对象的内存地址</code>。</p><blockquote><p>指针含义：将某个变量（对象）赋值给指针（引用），实际上就是就是将这个变量（对象）的地址赋值给指针（引用）</p></blockquote><h4 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h4><pre><code>p—&gt;next = q; </code></pre><p>表示<code>p</code>节点的后继<code>next</code>指针存储了<code>q</code>节点的内存地址</p><pre><code>p—&gt;next = p—&gt;next—&gt;next;</code></pre><p>表示<code>p</code>节点的后继<code>next</code>指针存储了<code>p</code>节点的下下个节点的内存地址。</p><h3 id="警惕指针丢失和内存泄漏"><a href="#警惕指针丢失和内存泄漏" class="headerlink" title="警惕指针丢失和内存泄漏"></a>警惕指针丢失和内存泄漏</h3><h4 id="示例：-1"><a href="#示例：-1" class="headerlink" title="示例："></a>示例：</h4><p>单链表的插入，希望在节点a和相邻节点b之间插入节点x，假设当前指针p指向节点a，则造成指针丢失和内存泄漏的代码：</p><pre><code>p-&gt;next = x;x-&gt;next = p-&gt;next</code></pre><p>导致将<code>x</code>自身赋值给了<code>x-&gt;next</code>，自己指向自己。</p><blockquote><p>对于有些语言来说，比如 C 语言，内存管理是由程序员负责的，如果没有手动释放结点对应的内存空间，就会产生内存泄露。</p></blockquote><p>所以，插入结点时，一定要注意操作的顺序。上面代码的正确写法是：<strong>两句代码顺序调换</strong>。<br>同理，删除链表时，也一定要手动释放内存空间，否则，也会出现内存泄漏问题。</p><blockquote><p>Python语言不需手动释放，它的解释器的存储管理系统会自动回收不用的存储。</p></blockquote><h3 id="利用哨兵（头结点）简化实现难度"><a href="#利用哨兵（头结点）简化实现难度" class="headerlink" title="利用哨兵（头结点）简化实现难度"></a>利用哨兵（头结点）简化实现难度</h3><h4 id="哨兵含义："><a href="#哨兵含义：" class="headerlink" title="哨兵含义："></a><code>哨兵</code>含义：</h4><p>链表中的<code>哨兵</code>节点是解决边界问题的，不参与业务逻辑。如果我们引入<code>哨兵</code>节点，则不管链表是否为空，head指针都会指向这个“哨兵”节点。我们把这种有“哨兵”节点的链表称为<code>带头链表</code>，相反，没有<code>哨兵</code>节点的链表就称为不带头链表。</p><h4 id="示例：-2"><a href="#示例：-2" class="headerlink" title="示例："></a>示例：</h4><h5 id="不带头结点时："><a href="#不带头结点时：" class="headerlink" title="不带头结点时："></a>不带头结点时：</h5><ul><li>对于单链表的插入操作</li></ul><p>1 . 如果在p节点后插入一个新节点，只需2行代码即可搞定：</p><pre><code>new_node—&gt;next = p—&gt;next;p—&gt;next = new_node;</code></pre><p>2 . 如果向空链表中插入一个新结点，则代码就不同：</p><pre><code>if(head == null){  head = new_node;}</code></pre><ul><li>对于单链表的删除操作</li></ul><p>1 . 如果要删除节点p的后继节点，只需1行代码即可搞定：</p><pre><code>p—&gt;next = p—&gt;next—&gt;next;</code></pre><p>2 . 如果删除的是链表的最后一个节点（链表中只剩下这个节点），则代码如下：</p><pre><code>if(head—&gt;next == null){  head = null;}</code></pre><blockquote><p>以上示例可以看出，不带头结点时，单链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点作特殊处理。</p></blockquote><h5 id="带头结点时："><a href="#带头结点时：" class="headerlink" title="带头结点时："></a>带头结点时：</h5><p><code>哨兵</code>节点不存储数据，无论链表是否为空，<code>head</code>指针都会指向它，作为链表的头结点始终存在。<br>这样，插入第一个节点和插入其他节点，删除最后一个节点和删除其他节点都可以统一为相同的实现逻辑。</p><h3 id="留意边界条件处理"><a href="#留意边界条件处理" class="headerlink" title="留意边界条件处理"></a>留意边界条件处理</h3><p>常用的检查链表代码是否正确的边界条件：<br>1 . 如果链表为空时，代码是否能正常工作？<br>2 . 如果链表只包含一个节点时，代码是否能正常工作？<br>3 . 如果链表只包含两个节点时，代码是否能正常工作？<br>4 . 代码逻辑在处理头尾节点时是否能正常工作？</p><h3 id="举例画图，辅助思考"><a href="#举例画图，辅助思考" class="headerlink" title="举例画图，辅助思考"></a>举例画图，辅助思考</h3><p>对于稍微复杂的链表操作，可以找一个具体例子，将它画在纸上。比如，向单链表中插入一个数据，就画出链表插入前和插入后的情况。<br>对着图写代码，写完之后，也可举列子，照着代码走一遍，很容易发现代码中的Bug。</p><h3 id="多写多练，没有捷径"><a href="#多写多练，没有捷径" class="headerlink" title="多写多练，没有捷径"></a>多写多练，没有捷径</h3><pre><code>精选的5个常见链表操作：（以及在LeetCode上对于的题目编号）1.单链表反转 ---- 2062.链表中环的检测 ---- 1413.两个有序链表合并 ---- 214.删除链表倒数第n个节点 ---- 195.求链表的中间节点 ---- 876</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;主要学习几个写链表代码的技巧&lt;/p&gt;
&lt;h3 id=&quot;理解指针或引用的含义&quot;&gt;&lt;a href=&quot;#理解指针或引用的含义&quot; class=&quot;headerlink&quot; title=&quot;理解指针或引用的含义&quot;&gt;&lt;/a&gt;理解指针或引用的含义&lt;/h3&gt;&lt;p&gt;有些语言有&lt;code&gt;指针&lt;/c
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>链表</title>
    <link href="http://ipine.github.io/2018-10-10/"/>
    <id>http://ipine.github.io/2018-10-10/</id>
    <published>2018-10-10T03:58:00.000Z</published>
    <updated>2019-02-22T11:27:42.008Z</updated>
    
    <content type="html"><![CDATA[<h2 id="如何用链表实现LRU缓存淘汰算法？"><a href="#如何用链表实现LRU缓存淘汰算法？" class="headerlink" title="如何用链表实现LRU缓存淘汰算法？"></a>如何用链表实现LRU缓存淘汰算法？</h2><h3 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h3><ul><li>缓存定义：一种高效数据读取性能的技术，比如常见的<strong>CPU缓存</strong>、<strong>数据库缓存</strong>、<strong>浏览器缓存</strong>等。缓存在计算机软件、硬件开发中应用都很广。</li><li>缓存特点：大小有限，被用满时，需要清理一部分数据，而哪些数据应该被清理哪些应该被保留，由<code>缓存淘汰策略</code>决定。</li></ul><h3 id="缓存淘汰策略"><a href="#缓存淘汰策略" class="headerlink" title="缓存淘汰策略"></a>缓存淘汰策略</h3><p>常见的缓存淘汰策略有：<code>FIFO（First in,First out）先进先出策略</code>、<code>LFU（Least Frequently Used）最少使用策略</code>、<code>LRU（Least Recently Used）最近最少使用策略</code>。</p><h3 id="三种链表"><a href="#三种链表" class="headerlink" title="三种链表"></a>三种链表</h3><p>链表通过指针将一组零散的内存块串联在一起。其中内存块叫做链表的<strong>结点</strong>，记录结点地址的叫做<strong>指针</strong>。链表的第一个结点叫头结点，最后一个结点叫尾结点。</p><h4 id="单链表"><a href="#单链表" class="headerlink" title="单链表"></a>单链表</h4><p>单链表的“尾结点”，它的指针并不指向下一个结点，而是指向一个空地址<code>NULL</code></p><p><img src="http://ipineimg.lijundong.com/18-10-10/56355664.jpg" alt="单链表"></p><p>单链表插入和删除操作，复杂度为O(1)<br><img src="http://ipineimg.lijundong.com/18-10-10/93241850.jpg" alt="操作"></p><h4 id="循环链表"><a href="#循环链表" class="headerlink" title="循环链表"></a>循环链表</h4><p>一种特殊的单链表，与单链表的区别就在于尾结点，其尾结点指向链表的头结点<br><img src="http://ipineimg.lijundong.com/18-10-10/66826587.jpg" alt="循环链表"></p><p>相比于单链表，循环链表的优势在于从链尾到链头很方便。著名的<code>约瑟夫问题</code>，就适合这种数据结构。</p><h4 id="双向链表"><a href="#双向链表" class="headerlink" title="双向链表"></a>双向链表</h4><p>单链表只有一个方向，结点只有一个后继指针next指向后面的节点。双向链表有两个方向，一个<code>后继指针next</code>和一个<code>前驱指针pre</code>。<br><img src="http://ipineimg.lijundong.com/18-10-10/80665346.jpg" alt="双向链表"></p><p>双向链表在某些情况下的插入、删除操作比单链表更高效。<br>例如删除操作，从链表中删除一个数据，有两种情况：</p><ul><li>删除链表中值等于某个给定值的结点</li><li>删除给定指针指向的结点</li></ul><p>对于第一种情况，无论单链表还是双向链表，为了查找到值等于给定值的结点，都需要从头结点开始一个一个依次遍历对比，直到找到值等于给定值的结点，然后再将其删除。<br>尽管单纯的删除操作时间复杂度是 <code>O(1)</code>，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 <code>O(n)</code>。根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为 <code>O(n)</code>。</p><p>对于第二种情况，已经找到了要删除的结点，但是删除某个结点 <code>q</code> 需要知道其前驱结点，而单链表并不支持直接获取前驱结点。这种情况下<strong>单链表</strong>删除操作需要 <code>O(n)</code> 的时间复杂度，而<strong>双向链表</strong>只需要 <code>O(1)</code> 的时间复杂度。</p><p>以上的情况涉及到一个<code>空间换时间</code>的设计思想：双向链表更费内存，但仍比单链表应用更广泛。</p><blockquote><p>缓存实际上就是利用了空间换时间的设计思想。<br> 如果我们把数据存储在硬盘上，会比较节省内存，但每次查找数据都要询问一次硬盘，会比较慢。<br> 但如果我们通过缓存技术，事先将数据加载在内存中，虽然会比较耗费内存空间，但是每次数据查询的速度就大大提高了。</p></blockquote><p>若内存空间充足，如果更加追求代码的执行速度，就选择空间复杂度相对较高，时间复杂度相对较低的算法和数据结构，例如，缓存技术。<br>若内存比较紧缺，比如代码跑在手机或者单片机上，这时，就要反过来用时间换空间。</p><h3 id="数组与链表对比"><a href="#数组与链表对比" class="headerlink" title="数组与链表对比"></a>数组与链表对比</h3><h4 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h4><p>删除、插入：<code>链表O(1)</code>、<code>数组O(n)</code></p><p>随机访问操作：<code>链表O(n)</code>、<code>数组(1)</code></p><h4 id="缓存支持"><a href="#缓存支持" class="headerlink" title="缓存支持"></a>缓存支持</h4><p>数组在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。</p><p>链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。</p><h5 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h5><p>CPU在从内存读取数据的时候，会先把读取到的数据加载到CPU的缓存中。而CPU每次从内存读取数据并不是只读取要访问的地址，而是读取一个数据块，并保存到CPU缓存中，然后下次访问内存数据的时候就会先从CPU缓存开始查找，如果找到就不需要再从内存中取。<br>这样就实现了比内存访问速度更快的机制，也是CPU缓存存在的意义：<strong>为了弥补内存访问速度过慢与CPU执行速度快之间的差异</strong>。<br>对于数组来说，存储空间是连续的，所以在加载某个下标的时候可以把以后的几个下标元素也加载到CPU缓存这样执行速度会快于存储空间不连续的链表存储。</p><h4 id="灵活性"><a href="#灵活性" class="headerlink" title="灵活性"></a>灵活性</h4><p>数组大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致<code>内存不足（out of memory）</code>。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。</p><p>链表本身没有大小的限制，天然地支持动态扩容。</p><h2 id="链表实现LRU缓存淘汰策略的思路"><a href="#链表实现LRU缓存淘汰策略的思路" class="headerlink" title="链表实现LRU缓存淘汰策略的思路"></a>链表实现LRU缓存淘汰策略的思路</h2><p>维护一个有序单链表，越靠近链表尾部的结点是越早被访问过的。当有新的数据被访问时，从链表头开始顺序遍历链表。—-缓存访问的时间复杂度为<code>O(n)</code></p><h3 id="过程："><a href="#过程：" class="headerlink" title="过程："></a>过程：</h3><p>1 . 当访问的数据存储在缓存的链表中时，遍历得到数据对应的结点，将其从原位置删除，再将其插入到链表表头；<br>2 . 当访问的数据未出现在缓存的链表中时<br>    1）若缓存有空闲，将该数据直接插入到链表表头。<br>    2）若缓存被占满，则将链表尾部的数据删除，再将新数据插入到链表表头。</p><h3 id="优化：使用散列表，记录每个数据的位置，将缓存访问的时间复杂度降到-O-1-。"><a href="#优化：使用散列表，记录每个数据的位置，将缓存访问的时间复杂度降到-O-1-。" class="headerlink" title="优化：使用散列表，记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。"></a>优化：使用散列表，记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。</h3><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><h3 id="如何用数组实现LRU缓存淘汰策略？"><a href="#如何用数组实现LRU缓存淘汰策略？" class="headerlink" title="如何用数组实现LRU缓存淘汰策略？"></a>如何用数组实现LRU缓存淘汰策略？</h3><p>方式一：首位置保存最新访问数据，末尾位置优先清理<br>当访问的数据未存在于缓存的数组中时<br>    1）缓存有空闲，将数据插入数组第一个元素位置，数组所有元素需要向后移动1个位置，新数据插入数组第一个元素位置，时间复杂度为O(n)；<br>    2）缓存无空闲，清理数组末尾位置的元素，数组所有元素需要向后移动1个位置，新数据插入数组第一个元素位置，时间复杂度为O(n)；<br>当访问的数据存在于缓存的数组中时，查找到数据，将其从原位置删除，并将其插入数组的第一个位置，此时亦需移动数组元素，时间复杂度为O(n)。</p><p>方式二：首位置优先清理，末尾位置保存最新访问数据<br>当访问的数据未存在于缓存的数组中时<br>    1）缓存有空闲，直接将数据添加进数组作为当前最后一个元素，时间复杂度为O(1)；<br>    2）缓存无空闲，清理数组首位置的元素，数组所有元素向前移动1个位置， 将新元素插入数组，时间复杂度为O(n)；<br>当访问的数据存在于缓存的数组中时，查找到数据，将其从原位置删除，并将其插入当前数组最后一个元素的位置，此时亦需移动数组元素，时间复杂度为O(n)。</p><h4 id="优化：清理的时候可以考虑一次性清理一定数量，从而降低清理次数，提高性能。"><a href="#优化：清理的时候可以考虑一次性清理一定数量，从而降低清理次数，提高性能。" class="headerlink" title="优化：清理的时候可以考虑一次性清理一定数量，从而降低清理次数，提高性能。"></a>优化：清理的时候可以考虑一次性清理一定数量，从而降低清理次数，提高性能。</h4><h3 id="如何通过单链表实现“判断某个字符串是否为回文字符串”？"><a href="#如何通过单链表实现“判断某个字符串是否为回文字符串”？" class="headerlink" title="如何通过单链表实现“判断某个字符串是否为回文字符串”？"></a>如何通过单链表实现“判断某个字符串是否为回文字符串”？</h3><p>比如 “123454321”<br>1 . 前提：字符串以单个字符的形式存储在单链表中。<br>2 . 遍历链表，判断字符个数是否为奇数，若为偶数，则不是。<br>3 . 将链表中的字符倒序存储一份在另一个链表中。<br>4 . 同步遍历2个链表，比较对应的字符是否相等，若相等，则是回文字符串，否则，不是。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;如何用链表实现LRU缓存淘汰算法？&quot;&gt;&lt;a href=&quot;#如何用链表实现LRU缓存淘汰算法？&quot; class=&quot;headerlink&quot; title=&quot;如何用链表实现LRU缓存淘汰算法？&quot;&gt;&lt;/a&gt;如何用链表实现LRU缓存淘汰算法？&lt;/h2&gt;&lt;h3 id=&quot;缓存&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>数组</title>
    <link href="http://ipine.github.io/2018-10-09/"/>
    <id>http://ipine.github.io/2018-10-09/</id>
    <published>2018-10-09T11:24:00.000Z</published>
    <updated>2019-02-22T11:27:40.744Z</updated>
    
    <content type="html"><![CDATA[<h3 id="数组定义"><a href="#数组定义" class="headerlink" title="数组定义"></a>数组定义</h3><p>一组<code>线性表</code>数据结构。它用一组<code>连续的内存空间</code>，来存储一组具有<code>相同类型的数据</code>。</p><h4 id="关键词解释"><a href="#关键词解释" class="headerlink" title="关键词解释"></a>关键词解释</h4><ul><li><p><strong>线性表</strong>：每个线性表上的数据最多只有前和后两个方向。<br>除了<code>数组</code>，<code>链表</code>、<code>队列</code>、<code>栈</code>都是线性表结构</p><p>联想到<strong>非线性表</strong>：数据之间并不是简单的前后关系。<br>如，<code>二叉树</code>、<code>堆</code>、<code>图</code>等</p></li><li><p><strong>连续的内存空间和相同类型的数据</strong><br>正因为有了这两个限制，才使得数组有了<code>随机访问</code>的特性；<br>也正是因为这两个限制，使得<code>数组的删除、插入操作效率很低</code>。</p></li></ul><h3 id="如何实现根据下标随机访问数组元素？"><a href="#如何实现根据下标随机访问数组元素？" class="headerlink" title="如何实现根据下标随机访问数组元素？"></a>如何实现根据下标随机访问数组元素？</h3><p>计算机会给每个内存单元分配一个地址，再通过地址来访问内存中的数据。<br>而计算机通过寻址公式来计算元素存储的内存地址：</p><pre><code>//a[i]的地址就是从首地址偏移i*data_type_size的位置a[i] = base_address + i * data_type_size</code></pre><blockquote><p>base_address: 内存块的首地址<br>  data_type_size：数中每个元素的大小；根据存储的数据类型而定，如int型，该值为4</p></blockquote><h3 id="为什么数组要从0开始编号，而不是从1开始呢？"><a href="#为什么数组要从0开始编号，而不是从1开始呢？" class="headerlink" title="为什么数组要从0开始编号，而不是从1开始呢？"></a>为什么数组要从0开始编号，而不是从1开始呢？</h3><p> 若数组从1开始计数，那么上面的公式就变成</p><pre><code>a[i] = base_address + (i-1) * data_type_size</code></pre><blockquote><p>修改后，每次随机访问数组元素都多了一次减法运算，对于CPU就多了一次减法指令。</p></blockquote><h3 id="两个操作"><a href="#两个操作" class="headerlink" title="两个操作"></a>两个操作</h3><h4 id="数组的插入操作"><a href="#数组的插入操作" class="headerlink" title="数组的插入操作"></a>数组的插入操作</h4><ul><li>效率低的原因：将某个数据插入到数组中的第<code>i</code>个位置。为了给新来的元素腾出这个位置，需要移动后面的<code>i~n</code>个元素，复杂度为<code>O(n)</code>;</li><li>改进方法：当数组是无序的，简单的方法就是将原来第<code>i</code>个位置上的元素放到数组最后，然后将新来的元素放到第<code>i</code>个位置。复杂度为<code>O(1)</code>;</li></ul><h4 id="数组的删除操作"><a href="#数组的删除操作" class="headerlink" title="数组的删除操作"></a>数组的删除操作</h4><p>与插入操作类似，若删除第<code>i</code>个位置的元素，需要搬移后面的<code>i~n</code>个元素，才能保证内存的连续性。</p><ul><li>复杂度：若删除开头元素，最坏复杂度为<code>O(n)</code>；若删除数组末尾元素，最好复杂度为<code>O(1)</code>；平均复杂度为<code>O(n)</code>。</li><li>改进方法：<strong>不要求数组中数据的连续性</strong>，就可将多次删除操作集中在一起执行。<br>每次删除元素时，并不真正搬移元素，而是记录下数据已被删除。当数组没有更多空间存储数据时，再执行一次真正的删除操作（做数据元素的搬移工作）</li></ul><h3 id="数组的访问越界问题"><a href="#数组的访问越界问题" class="headerlink" title="数组的访问越界问题"></a>数组的访问越界问题</h3><p>分析以下一段代码：</p><pre><code>int main(int argc, char* argv[]){    int i = 0;    int arr[3] = {0};    for(; i&lt;=3; i++){        arr[i] = 0;        printf(&quot;hello world\n&quot;);    }    return 0;}</code></pre><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>不是只打印三行“hello world”；而是无限打印</p><h4 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h4><p>数组大小为3，<code>a[0]，a[1]，a[2]</code>，而我们的代码 for 循环的结束条件错写为了<code>i&lt;=3</code> 而非 <code>i&lt;3</code>，所以当 <code>i=3</code> 时，数组 <code>a[3]</code> 访问越界。<br>根据我们前面讲的数组寻址公式，<code>a[3]</code> 也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 <code>i</code> 的内存地址，那么 <code>a[3]=0</code> 就相当于 <code>i=0</code>，所以就会导致代码无限循环。</p><blockquote><p>注：例子中死循环的问题跟编译器分配内存和字节对齐有关。数组3个元素，加上一个变量i。4个整数刚好能满足8字节对齐，所以i的地址恰好跟在a[2]后面，导致死循环。如果数组本身有4个元素，则这里不会出现死循环。因为编译器64位操作系统下，默认会进行8字节对齐，变量i的地址就不会紧跟在数组后面了。</p></blockquote><h3 id="Key"><a href="#Key" class="headerlink" title="Key"></a>Key</h3><p>1 . 常会问的一个面试题：数组和链表的区别？<br>正确表述：链表适合插入、删除操作，时间复杂度为<code>O(1)</code>；数组适合随机访问数组元素(而不应该说查找)，根据下标随机访问的时间复杂度为<code>O(1)</code>。<br>明确的点：数组是适合查找，但查找的时间复杂度不为<code>O(1)</code>。即便是<strong>排好序的数组，用二分查找，时间复杂度也是O(nlogn)</strong>。</p><p>2 . 数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。<br>在这种情况下，一般都会出现莫名其妙的逻辑错误，就像上面举的那个例子，debug的难度非常的大。而且，很多计算机病毒也正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统，所以写代码的时候一定要警惕数组越界。</p><p>3 . 二维、多维数组如何寻址？<br>行优先</p><pre><code>int a[d1][d2][d3];int *p0 = &amp;a[0][0][0];int *p = &amp;a[i][j][k];int idx = i * (d2*d3) + j * d3 + kASSERT( p0 + idx == p);</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;数组定义&quot;&gt;&lt;a href=&quot;#数组定义&quot; class=&quot;headerlink&quot; title=&quot;数组定义&quot;&gt;&lt;/a&gt;数组定义&lt;/h3&gt;&lt;p&gt;一组&lt;code&gt;线性表&lt;/code&gt;数据结构。它用一组&lt;code&gt;连续的内存空间&lt;/code&gt;，来存储一组具有&lt;code&gt;相
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>算法复杂度分析</title>
    <link href="http://ipine.github.io/2018-09-29/"/>
    <id>http://ipine.github.io/2018-09-29/</id>
    <published>2018-09-29T04:40:00.000Z</published>
    <updated>2019-02-22T11:27:39.182Z</updated>
    
    <content type="html"><![CDATA[<h3 id="先举个栗子"><a href="#先举个栗子" class="headerlink" title="先举个栗子"></a>先举个栗子</h3><p>分析以下这段代码的时间复杂度</p><pre><code>// n 表示数组 array 的长度int find(int[] array, int n, int x) {  int i = 0;  int pos = -1;  for (; i &lt; n; ++i) {    if (array[i] == x) pos = i;  }  return pos;}</code></pre><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><ul><li>功能：在一个无序数组array中，查找变量x出现的位置</li><li>时间复杂度：<code>O(n)</code>, n表示数组的长度</li></ul><p>更为优化的方式</p><pre><code>// n 表示数组 array 的长度int find(int[] array, int n, int x) {  int i = 0;  int pos = -1;  for (; i &lt; n; ++i) {    if (array[i] == x) {        pos = i;        break;    }  }  return pos;}</code></pre><blockquote><p>时间复杂度： 不一定是O(n)了，不同情况下这段代码的时间复杂度是不同的。</p></blockquote><h3 id="引入概念"><a href="#引入概念" class="headerlink" title="引入概念"></a>引入概念</h3><ul><li><p>最好情况时间复杂度：在最理想情况下，执行代码的时间复杂度</p></li><li><p>最坏情况时间复杂度：在最糟糕情况下，执行代码的时间复杂度</p></li><li><p>平均情况时间复杂度：最好情况和最坏情况都是属于极端情况，发生的概率并不大。需要表示平均情况下的复杂度</p></li></ul><h3 id="如何分析平均情况时间复杂度"><a href="#如何分析平均情况时间复杂度" class="headerlink" title="如何分析平均情况时间复杂度"></a>如何分析平均情况时间复杂度</h3><p>以上面的例子为例：查找x在数组中的位置，有<code>n+1</code>种情况，在数组<code>0~n-1</code>的位置上和不在数组中。<br>将每种情况下，查找需要遍历的元素个数相加，再除以n+1种情况，就可得到需要遍历的元素个数的平均值<br><code>(1+2+3+...+n+n)/n+1 = n (n+3) /2(n+1)</code><br>省略掉系数、低阶、常量后得到平均时间复杂度为<code>O(n)</code></p><h4 id="存在问题"><a href="#存在问题" class="headerlink" title="存在问题"></a>存在问题</h4><p>在以上的n+1种情况中，未考虑x在每种情况下出现的概率。<br>现在假设，x在数组中与x不在数组中的概率各为<code>1/2</code>；<br>要查找的x出现在<code>0~n-1</code>这n个位置的可能性是相同的，即<code>1/n</code>；<br>那么，要查找的x出现在<code>0~n-1</code>中任意位置的概率为 <code>1/2*1/n = 1/(2n)</code></p><p>将每种情况发生的概率考虑进去后，平均时间复杂度计算过程变成：</p><p><img src="http://ipineimg.lijundong.com/18-9-29/51560357.jpg" alt="平均时间复杂度"></p><p>这个值就是概率论中的加权平均值，也叫作期望值。因而平均时间复杂度的全称为<strong>加权平均时间复杂度</strong>或<strong>期望时间复杂度</strong>。</p><blockquote><p>注：很多时候，我们只使用一个复杂度就可以满足要求。只有同一块代码在不同情况下，时间复杂度有量级的差距，才会使用以上3种复杂度的表示法来区分。</p></blockquote><h3 id="均摊时间复杂度、摊还分析（平摊分析）"><a href="#均摊时间复杂度、摊还分析（平摊分析）" class="headerlink" title="均摊时间复杂度、摊还分析（平摊分析）"></a>均摊时间复杂度、摊还分析（平摊分析）</h3><p>举栗子说明：</p><pre><code>// array 表示一个长度为 n 的数组// 代码中的 array.length 就等于 nint[] array = new int[n];int count = 0;void insert(int val) {    if (count == array.length) {       int sum = 0;       for (int i = 0; i &lt; array.length; ++i) {          sum = sum + array[i];       }       array[0] = sum;       count = 1;    }    array[count] = val;    ++count;}</code></pre><h4 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h4><ul><li>功能：实现了往数组中插入数据的功能。</li><li><p>具体：<br>1 . 当数组满了<code>count == array.length</code>,就用for循环遍历求和，将求得的和放在数组的第一个位置，并清空数组其余元素；然后再插入新的元素。<br>2 . 当数组一开始就有空闲，则直接将数据插入数组。</p></li><li><p>复杂度分析：<br>1 . 最好情况：数组中有空闲，直接将数据插入到<code>count</code>的位置，为<code>O(1)</code><br>2 . 最坏情况：数组没有空闲空间，需要先做一个遍历求和，再作插入。所以复杂度为<code>O(n)</code><br>3 . 平均时间复杂度：<code>O(1)</code> </p></li></ul><h5 id="平均时间复杂度如何得到"><a href="#平均时间复杂度如何得到" class="headerlink" title="平均时间复杂度如何得到"></a>平均时间复杂度如何得到</h5><p>总共<code>n+1</code>种情况，前<code>n</code>中情况每种时间复杂度都为<code>O(1)</code>，后一种情况时间复杂度为<code>O(n)</code>；<code>n+1</code>种情况发生的概率一样，为<code>1/(n+1)</code>；根据加权平均计算方法：</p><blockquote><p><code>1*1/(n+1) + 1*1/(n+1) + ... + n*1/(n+1) = O(1)</code></p></blockquote><h4 id="均摊时间复杂度（amortized-time-complexity）"><a href="#均摊时间复杂度（amortized-time-complexity）" class="headerlink" title="均摊时间复杂度（amortized time complexity）"></a>均摊时间复杂度（amortized time complexity）</h4><p>分析发现:<br>1 . <code>insert()</code>函数在<strong>大部分情况</strong>下，时间复杂度都为<code>O(1)</code>；<strong>极个别情况</strong>下，复杂度才高，为<code>O(n)</code><br>2 . <code>insert()</code>函数中，<code>O(1)</code>时间复杂度的插入和<code>O(n)</code>时间复杂度的插入，<strong>出现频率很有规律</strong>。存在前后时序关系，一般一个<code>O(n)</code>插入之后，紧跟着<code>n-1</code>个<code>O(1)</code>的插入操作，循环往复。</p><h5 id="针对这种场景，引入均摊分析法"><a href="#针对这种场景，引入均摊分析法" class="headerlink" title="针对这种场景，引入均摊分析法"></a>针对这种场景，引入均摊分析法</h5><p>大致思路：每一次 <code>O(n)</code> 的插入操作，都会跟着 <code>n-1</code> 次 <code>O(1)</code> 的插入操作，所以把耗时多的那次操作均摊到接下来的 <code>n-1</code> 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 <code>O(1)</code>。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。<br>而且，<strong>在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度</strong>。</p><blockquote><p>均摊时间复杂度就是一种特殊的平均时间复杂度，没必要花太多精力去区分它们。</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;先举个栗子&quot;&gt;&lt;a href=&quot;#先举个栗子&quot; class=&quot;headerlink&quot; title=&quot;先举个栗子&quot;&gt;&lt;/a&gt;先举个栗子&lt;/h3&gt;&lt;p&gt;分析以下这段代码的时间复杂度&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// n 表示数组 array 的长度
int find
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>算法复杂度分析</title>
    <link href="http://ipine.github.io/2018-09-28/"/>
    <id>http://ipine.github.io/2018-09-28/</id>
    <published>2018-09-28T11:09:00.000Z</published>
    <updated>2019-02-22T11:27:37.572Z</updated>
    
    <content type="html"><![CDATA[<p><code>执行效率</code>是算法优劣的度量指标，而执行效率又是通过时间、空间复杂度分析。</p><h3 id="为什么需要复杂度分析？"><a href="#为什么需要复杂度分析？" class="headerlink" title="为什么需要复杂度分析？"></a>为什么需要复杂度分析？</h3><p>将代码跑一遍，通过统计、监控，就能得到算法执行时间和占用的内存大小。—–这叫事后统计法<br>存在局限性：<br>1 . 测试结果依赖于测试环境<br>2 . 测试结果受测试数据的规模影响</p><blockquote><p>如何能不用具体的测试数据，就可以粗略估计算法的执行效率呢？</p></blockquote><h3 id="大O复杂度表示法"><a href="#大O复杂度表示法" class="headerlink" title="大O复杂度表示法"></a>大O复杂度表示法</h3><ul><li><p>首先看个栗子：</p><pre><code>int cal(int n){   int sum = 0;   int i = 1;   for (; i &lt;= n; ++i) {     sum = sum + i;   }   return sum;}</code></pre></li></ul><h4 id="CPU角度分析"><a href="#CPU角度分析" class="headerlink" title="CPU角度分析"></a>CPU角度分析</h4><p>这段代码每一行都执行着操作：<code>读数据-运算-写数据</code>。<br>每行代码对应的CPU执行个数和执行时间不同，但假设每行代码执行时间为 <code>unit_time</code>。<br>那么上面一段代码的执行时间应为： <code>(2n+2) * unit_time</code></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><blockquote><p>所有代码的执行时间 T(n) 与每行代码的执行次数成正比。</p></blockquote><ul><li><p>按照这个思路分析下面一段代码的执行时间T(n)</p><pre><code>1 int cal(int n) {2   int sum = 0;3   int i = 1;4   int j = 1;5   for (; i &lt;= n; ++i) {6     j = 1;7     for (; j &lt;= n; ++j) {8       sum = sum +  i * j;9     }10   }11 }</code></pre></li></ul><h4 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h4><p>对于2,3,4行，执行每行需要1个unit_time；执行5,6行需要n个unit_time；执行7,8行需要<code>n * n</code>个unit_time<br>总的执行时间为  <code>T(n) = (2n * n + 2n + 3)*unit_time</code></p><h4 id="规律总结"><a href="#规律总结" class="headerlink" title="规律总结"></a>规律总结</h4><p>通过以上两段代码的执行时间推导，得到规律：</p><blockquote><p>所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比。</p></blockquote><h4 id="公式表示"><a href="#公式表示" class="headerlink" title="公式表示"></a>公式表示</h4><blockquote><p>T(n) = O(f(n))<br>  其中，T(n)表示代码执行时间；n 表示数据规模的大小；f(n) 表示每行代码执行的次数总和； O 表示代码的执行时间 T(n) 与 f(n) 表达式成正比。</p></blockquote><p>那么以上两个例子的大O表示应为：</p><blockquote><p>T(n) = O(2n + 2)   —–&gt; T(n) = O(n)<br>  T(n) = O(2n * n + 2n + 3)   —–&gt; T(n) = O(n * n)</p></blockquote><p><strong>注：公式中的低阶、常量、系数三部分并不决定增长趋势，因而可以忽略。</strong></p><blockquote><p>大O时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势。<br>因而，也叫作渐进时间复杂度，简称时间复杂度。</p></blockquote><h3 id="如何分析时间复杂度"><a href="#如何分析时间复杂度" class="headerlink" title="如何分析时间复杂度"></a>如何分析时间复杂度</h3><h4 id="1、只关注循环执行次数最多的一段代码"><a href="#1、只关注循环执行次数最多的一段代码" class="headerlink" title="1、只关注循环执行次数最多的一段代码"></a>1、只关注循环执行次数最多的一段代码</h4><h4 id="2、加法法则"><a href="#2、加法法则" class="headerlink" title="2、加法法则"></a>2、加法法则</h4><p>总复杂度等于量级最大的那段代码的复杂度</p><ul><li><p>举个栗子：分析下面这段代码的时间复杂度</p><pre><code>int cal(int n) {   int sum_1 = 0;   int p = 1;   for (; p &lt; 100; ++p) {     sum_1 = sum_1 + p;   }   int sum_2 = 0;   int q = 1;   for (; q &lt; n; ++q) {     sum_2 = sum_2 + q;   }   int sum_3 = 0;   int i = 1;   int j = 1;   for (; i &lt;= n; ++i) {     j = 1;     for (; j &lt;= n; ++j) {       sum_3 = sum_3 +  i * j;     }   }   return sum_1 + sum_2 + sum_3;}</code></pre></li></ul><h5 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h5><p>代码是要分别求sum_1、sum_2、sum_3。那么算时间复杂度就分别求每一部分的时间复杂度，再放在一起，取量级最大的那个作为整段代码的时间复杂度。</p><ul><li>sum_1处：执行100次，与n无关；是常量执行时间</li></ul><blockquote><p>注：即使循环100000次，只要是一个已知数，与n无关，那么就是一个常量执行时间。<br>  因为时间复杂度表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，都可以忽略。因为其本身对增长趋势没有影响。</p></blockquote><ul><li>sum_2处：<code>O(n)</code></li><li>sum_3处：<code>O(n*n)</code><br>根据方法2，整段代码的时间复杂度就等于 <code>O(n*n)</code></li></ul><h5 id="将规律抽象成公式"><a href="#将规律抽象成公式" class="headerlink" title="将规律抽象成公式"></a>将规律抽象成公式</h5><blockquote><p>若 T1(n)=O(f(n))，T2(n)=O(g(n))；<br>那么 T(n)=T1(n)+T2(n) = max(O(f(n)), O(g(n))) = O(max(f(n), g(n))).</p></blockquote><h4 id="3、乘法法则"><a href="#3、乘法法则" class="headerlink" title="3、乘法法则"></a>3、乘法法则</h4><p>嵌套代码的复杂度等于嵌套内外代码复杂度的乘积</p><h5 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h5><blockquote><p>若 <code>T1(n)=O(f(n))，T2(n)=O(g(n))</code>；<br>那么  <code>T(n)=T1(n)*T2(n) = O(f(n))*O(g(n)) = O(f(n)*g(n))</code>.</p></blockquote><h4 id="几种常见时间复杂度实例分析"><a href="#几种常见时间复杂度实例分析" class="headerlink" title="几种常见时间复杂度实例分析"></a>几种常见时间复杂度实例分析</h4><p><img src="http://ipineimg.lijundong.com/18-9-28/46917205.jpg" alt="常见复杂度实例"></p><blockquote><p>注 <code>O(1) &lt; O(logn) &lt; O(n) &lt; O(nlogn) &lt; O(n*n)</code></p></blockquote><p>以上罗列的复杂度量级，可以粗略分为两类：多项式量级、非多项式量级（指数阶和阶乘阶）</p><blockquote><p>将时间复杂度为非多项式量级的算法问题叫作NP问题。当数据规模增大时，非多项式时间复杂度的算法效率非常低。</p></blockquote><h5 id="重点关注常见的多项式时间复杂度"><a href="#重点关注常见的多项式时间复杂度" class="headerlink" title="重点关注常见的多项式时间复杂度"></a>重点关注常见的多项式时间复杂度</h5><p>1 . <code>O(1)</code><br>明确：O(1)是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。<br>一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)。</p><p>2 . <code>O(logn)</code>、<code>O(nlogn)</code><br>最难分析的一种时间复杂度<br>最常见的例子：</p><pre><code>1 i=1;2 while (i &lt;= n)  {3   i = i * 2;  //i = i * 3;4 }</code></pre><p>分析：变量i从1开始取，每循环一次就乘以2。变量i的取值就是一个等比数列： 2的x次方为n，求解x为多少。<code>x=logn</code>(以2为底)<br>若循环体内的代码改成 <code>i = i * 3</code>;那么时间复杂度为<code>O(logn)</code>(以3为底)</p><p>我们把所有对数阶的时间复杂度都记为<code>O(logn)</code><br>因为：<code>log3n</code> 就等于 <code>log32 * log2n</code>，所以 <code>O(log3n) = O(C * log2n)</code>，其中 <code>C=log32</code> 是一个常量。<br>基于我们前面的一个理论：在采用大 O 标记复杂度的时候，可以忽略系数，即 <code>O(C*f(n)) = O(f(n))</code>。</p><blockquote><p>如果一段代码的时间复杂度是 O(logn)，我们循环执行 n 遍，时间复杂度就是 O(nlogn) 。</p></blockquote><p><strong>O(nlogn) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)。</strong></p><p>3 . <code>O(m+n)</code>、<code>O(m*n)</code><br>代码的时间复杂度由两个数据的规模来决定。无法评估m和n谁的量级更大，所以在表示复杂度时，就不能简单利用加法法则，而忽略掉其中一个。<br>针对这种情况，原来的加法法则应改为 <code>T1(m) + T2(n) = O(f(m) + g(n))</code>；乘法法则继续有效 <code>T1(m)*T2(n) = O(f(m) * f(n))</code>。</p><h3 id="空间复杂度分析"><a href="#空间复杂度分析" class="headerlink" title="空间复杂度分析"></a>空间复杂度分析</h3><p>渐进空间复杂度，表示算法的存储空间与数据规模之间的增长关系。<br>我们常见的空间复杂度就是 <code>O(1)、 O(n)、 O(n*n )</code>，像 <code>O(logn)、 O(nlogn)</code> 这样的对数阶复杂度平时都用不到。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p><img src="http://ipineimg.lijundong.com/18-9-29/66748631.jpg" alt="常见复杂度函数变化"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;code&gt;执行效率&lt;/code&gt;是算法优劣的度量指标，而执行效率又是通过时间、空间复杂度分析。&lt;/p&gt;
&lt;h3 id=&quot;为什么需要复杂度分析？&quot;&gt;&lt;a href=&quot;#为什么需要复杂度分析？&quot; class=&quot;headerlink&quot; title=&quot;为什么需要复杂度分析？&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="data_structure" scheme="http://ipine.github.io/tags/data-structure/"/>
    
      <category term="algorithm" scheme="http://ipine.github.io/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>发表的论文</title>
    <link href="http://ipine.github.io/2018-09-26/"/>
    <id>http://ipine.github.io/2018-09-26/</id>
    <published>2018-09-26T13:59:00.000Z</published>
    <updated>2019-02-22T11:27:36.110Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Title-Evaluating-Multi-Dimensional-Visualizations-for-Understanding-Fuzzy-Clusters"><a href="#Title-Evaluating-Multi-Dimensional-Visualizations-for-Understanding-Fuzzy-Clusters" class="headerlink" title="Title: Evaluating Multi-Dimensional Visualizations for Understanding Fuzzy Clusters"></a>Title: Evaluating Multi-Dimensional Visualizations for Understanding Fuzzy Clusters</h3><h3 id="Acceptted-by-IEEE-VIS-2018"><a href="#Acceptted-by-IEEE-VIS-2018" class="headerlink" title="Acceptted by IEEE VIS 2018"></a><a href="http://ieeevis.org/year/2018/info/papers" target="_blank" rel="noopener">Acceptted by IEEE VIS 2018</a></h3><ul><li><a href="https://ieeexplore.ieee.org/abstract/document/8440829" target="_blank" rel="noopener">Paper</a></li><li><a href="https://vimeo.com/289787891" target="_blank" rel="noopener">Video</a></li><li><a href="https://1drv.ms/p/s!AlEzTfE0kEurhnFiiCJzRCRrTy0H" target="_blank" rel="noopener">Talk-PPT</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Title-Evaluating-Multi-Dimensional-Visualizations-for-Understanding-Fuzzy-Clusters&quot;&gt;&lt;a href=&quot;#Title-Evaluating-Multi-Dimensional-Vis
      
    
    </summary>
    
      <category term="可视化论文" scheme="http://ipine.github.io/categories/%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%BA%E6%96%87/"/>
    
    
      <category term="paper" scheme="http://ipine.github.io/tags/paper/"/>
    
      <category term="presentation" scheme="http://ipine.github.io/tags/presentation/"/>
    
  </entry>
  
  <entry>
    <title>Use Seaborn to Create Animated Graph</title>
    <link href="http://ipine.github.io/2018-09-15/"/>
    <id>http://ipine.github.io/2018-09-15/</id>
    <published>2018-09-15T08:18:00.000Z</published>
    <updated>2019-02-22T11:27:34.764Z</updated>
    
    <content type="html"><![CDATA[<p>今天看到一篇很好的文章，教我们如何在Python中创建动画图。很具有实践性，于是跟着码了一遍代码。</p><p><a href="https://towardsdatascience.com/how-to-create-animated-graphs-in-python-bb619cc2dec1" target="_blank" rel="noopener">附上文章链接</a></p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>这过程中遇到两个问题：<br>1 . 用<code>pip install ffmpeg</code>安装了FFmpeg之后，仍然不能正常运行<br>2 . 解决第一个问题后,又报<code>AttributeError:Seaborn Lineplot Module Object Has No Attribute &#39;Lineplot&#39;</code></p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><h3 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h3><p>在Windows上安装FFmpeg需要设置环境变量。</p><h4 id="步骤一"><a href="#步骤一" class="headerlink" title="步骤一"></a>步骤一</h4><p>从<a href="https://ffmpeg.zeranoe.com/builds/" target="_blank" rel="noopener">这里</a>下载FFmpeg包，<code>ffmpeg-20180913-1b98bfb-win64-static</code>到本地，解压后，重命名文件夹为<code>FFmpeg</code>。复制或者剪切修改好的文件夹到<code>C</code>盘。</p><h4 id="步骤二"><a href="#步骤二" class="headerlink" title="步骤二"></a>步骤二</h4><p>接下来在命令行中启用FFmpeg。右键单击<code>此电脑</code>，选择<code>属性</code>，找到<code>高级系统设置</code>，进去。点击<code>环境变量</code>，可以看到两个设置变量的框，在上面的<code>xxx的用户变量</code>框里，找到<code>Path</code>,选择新增，将<code>C:\FFmpeg\bin</code>添加进去，点击<code>确定</code>。</p><h4 id="步骤三"><a href="#步骤三" class="headerlink" title="步骤三"></a>步骤三</h4><p>测试FFmpeg是否安装成功。快捷方式<code>win+R</code>，输入<code>cmd</code>进入命令控制窗口。键入<code>ffmpeg -version</code>，回车，若出现一系列关于FFmpeg的信息，说明设置成功。</p><h3 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h3><p>对于Seaborn包没有属性<code>Lineplot</code>问题，我首先百度了下，几乎都是建议先确认自己的Python环境是否正确，是否安装了需要用的包。于是我分别执行命令<code>pip install matplotlib</code>和<code>pip install seaborn</code>后，再重新导入这些模块到代码中，运行仍然报错。</p><p>一番折腾后，发现是seaborn包版本问题。<code>Linplot</code>在0.9版本下的seaborn环境中才可以，因而需要对seaborn包进行升级，运行命令<code>pip install seaborn==0.9.0</code>之后，再次运行代码，不报错了。</p><h2 id="注"><a href="#注" class="headerlink" title="注"></a>注</h2><p>1 . 原文中使用的代码在读取excel文件的时候使用了已废弃的<code>sheetname</code>参数，正确应该修改为<code>sheet_name</code><br>2 . 若使用的是jupyter notebook，确保在代码首行加入了<code>%matplotlib notebook</code>。<code>%matplotlib notebook</code>提供了一些交互性，可能会很慢，因为渲染由服务器端完成。<br>然鹅，我加了后，在jupyter notebook中并没有看到正常的动画效果(原因未知)。程序运行是没有问题的，在本地生成了一个视频，可以正常显示动画图。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天看到一篇很好的文章，教我们如何在Python中创建动画图。很具有实践性，于是跟着码了一遍代码。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com/how-to-create-animated-graphs-in-python-
      
    
    </summary>
    
      <category term="technique summary" scheme="http://ipine.github.io/categories/technique-summary/"/>
    
    
      <category term="python" scheme="http://ipine.github.io/tags/python/"/>
    
  </entry>
  
</feed>
